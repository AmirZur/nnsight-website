
<!DOCTYPE html>


<html lang="en" data-content_root="../../../" data-theme="dark">

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

    <title>Walkthrough &#8212; nnsight</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "dark";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "dark";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../../_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../../../_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../../../_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="../../../_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../../../_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../../_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../../_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../../../_static/pygments.css?v=362ab14a" />
    <link rel="stylesheet" type="text/css" href="../../../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../../../_static/sphinx-design.min.css?v=95c83b7e" />
    <link rel="stylesheet" type="text/css" href="../../../_static/nbsphinx-code-cells.css?v=2aa19091" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="../../../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="../../../_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="../../../_static/documentation_options.js?v=187304be"></script>
    <script src="../../../_static/doctools.js?v=9a2dae69"></script>
    <script src="../../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../../../_static/copybutton.js?v=f281be69"></script>
    <script src="../../../_static/design-tabs.js?v=f930bc37"></script>
    <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="https://unpkg.com/@jupyter-widgets/html-manager@^0.20.1/dist/embed-amd.js"></script>
    <script>window.MathJax = {"tex": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true}, "options": {"ignoreHtmlClass": "tex2jax_ignore|mathjax_ignore|document", "processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'notebooks/tutorials/walkthrough';</script>
    <script src="../../../_static/js/custom.js?v=1e4be224"></script>
    <script src="../../../_static/js/code.js?v=34343d0c"></script>
    <link rel="icon" href="../../../_static/icon.ico"/>
    <link rel="author" title="About these documents" href="../../../about/" />
    <link rel="index" title="Index" href="../../../genindex/" />
    <link rel="search" title="Search" href="../../../search/" />
    <link rel="next" title="About NNsight" href="../../../about/" />
    <link rel="prev" title="Logit Lens" href="../logit_lens/" />

  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
<link href="../../../_static/css/custom.css?v=1732202432" rel="stylesheet" type="text/css" />
<link href="../../../_static/css/home.css?v=1732202432" rel="stylesheet" type="text/css" />

  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="dark">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../../../search/"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search the docs ..."
         aria-label="Search the docs ..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
<div class="bd-header__inner bd-page-width">
  <button class="pst-navbar-icon sidebar-toggle primary-toggle" aria-label="Site navigation">
    <span class="fa-solid fa-bars"></span>
  </button>
  
  
  <div class=" navbar-header-items__start">
    
      <div class="navbar-item">

  
    
  

<a class="navbar-brand logo" href="../../../">
  
  
  
  
  
    
    
    
    <img src="../../../_static/nnsight_logo.svg" class="logo__image only-dark" alt="nnsight - Home"/>
    <script>document.write(`<img src="../../../_static/nnsight_logo.svg" class="logo__image only-light" alt="nnsight - Home"/>`);</script>
  
  
</a></div>
    
  </div>
  
  <div class=" navbar-header-items">
    
    <div class="me-auto navbar-header-items__center">
      
        <div class="navbar-item">
<nav>
  <ul class="bd-navbar-elements navbar-nav">
    
<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../../start/">
    Getting Started
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../../documentation/">
    Documentation
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../../features/">
    Features
  </a>
</li>


<li class="nav-item current active">
  <a class="nav-link nav-internal" href="../../../tutorials/">
    Tutorials
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../../about/">
    About
  </a>
</li>

  </ul>
</nav></div>
      
    </div>
    
    
    <div class="navbar-header-items__end">
      
        <div class="navbar-item navbar-persistent--container">
          

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script>
        </div>
      
      
        <div class="navbar-item"><script>
    fetch("https://ndif.dev/ping")
        .then((response) => {
            if (response.status == 200) {
                Array.from(document.getElementsByClassName("ndif")).forEach((ndifElement) => {
                    Array.from(ndifElement.getElementsByTagName('span')).forEach((spanElement) => {
                        spanElement.style.setProperty('color', '#66800b', 'important');
                    });
                });
            }
            else {
                Array.from(document.getElementsByClassName("ndif")).forEach((ndifElement) => {
                    Array.from(ndifElement.getElementsByTagName('span')).forEach((spanElement) => {
                        spanElement.style.setProperty('color', '#af3029', 'important');
                    });
                });
                var statusIcon = document.querySelector('.ndif .fa-circle-check');
                if (statusIcon) {
                    // not here
                    statusIcon.classList.replace('fa-circle-check', 'fa-circle-xmark'); 
                }
            }
        })
        .catch((response) => {
            Array.from(document.getElementsByClassName("ndif")).forEach((ndifElement) => {
                Array.from(ndifElement.getElementsByTagName('span')).forEach((spanElement) => {
                    spanElement.style.setProperty('color', '#af3029', 'important');
                });
            });
            var statusIcon = document.querySelector('.ndif .fa-circle-check');
            if (statusIcon) {
                statusIcon.classList.replace('fa-circle-check', 'fa-circle-xmark');
            }
        })
</script></div>
      
        <div class="navbar-item">

<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script></div>
      
        <div class="navbar-item"><ul class="navbar-icon-links"
    aria-label="Icon Links">
        <li class="nav-item">
            
          
          
          
          
          
          
          
          
          
          <a href="/status" title="Status: Unknown" class="ndif" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-solid fa-circle-check fa-lg" aria-hidden="true"></i>
            <span class="sr-only">Status: Unknown</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://github.com/ndif-team/nnsight" title="GitHub" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-github fa-lg" aria-hidden="true"></i>
            <span class="sr-only">GitHub</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://forms.gle/1Y6myaXYzSh3oHf56" title="Discord" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-discord fa-lg" aria-hidden="true"></i>
            <span class="sr-only">Discord</span></a>
        </li>
</ul></div>
      
    </div>
    
  </div>
  
  
    <div class="navbar-persistent--mobile">

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script>
    </div>
  

  
    <button class="pst-navbar-icon sidebar-toggle secondary-toggle" aria-label="On this page">
      <span class="fa-solid fa-outdent"></span>
    </button>
  
</div>

    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
      <div class="sidebar-header-items__center">
        
          
          
            <div class="navbar-item">
<nav>
  <ul class="bd-navbar-elements navbar-nav">
    
<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../../start/">
    Getting Started
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../../documentation/">
    Documentation
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../../features/">
    Features
  </a>
</li>


<li class="nav-item current active">
  <a class="nav-link nav-internal" href="../../../tutorials/">
    Tutorials
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../../about/">
    About
  </a>
</li>

  </ul>
</nav></div>
          
        
      </div>
    
    
    
      <div class="sidebar-header-items__end">
        
          <div class="navbar-item"><script>
    fetch("https://ndif.dev/ping")
        .then((response) => {
            if (response.status == 200) {
                Array.from(document.getElementsByClassName("ndif")).forEach((ndifElement) => {
                    Array.from(ndifElement.getElementsByTagName('span')).forEach((spanElement) => {
                        spanElement.style.setProperty('color', '#66800b', 'important');
                    });
                });
            }
            else {
                Array.from(document.getElementsByClassName("ndif")).forEach((ndifElement) => {
                    Array.from(ndifElement.getElementsByTagName('span')).forEach((spanElement) => {
                        spanElement.style.setProperty('color', '#af3029', 'important');
                    });
                });
                var statusIcon = document.querySelector('.ndif .fa-circle-check');
                if (statusIcon) {
                    // not here
                    statusIcon.classList.replace('fa-circle-check', 'fa-circle-xmark'); 
                }
            }
        })
        .catch((response) => {
            Array.from(document.getElementsByClassName("ndif")).forEach((ndifElement) => {
                Array.from(ndifElement.getElementsByTagName('span')).forEach((spanElement) => {
                    spanElement.style.setProperty('color', '#af3029', 'important');
                });
            });
            var statusIcon = document.querySelector('.ndif .fa-circle-check');
            if (statusIcon) {
                statusIcon.classList.replace('fa-circle-check', 'fa-circle-xmark');
            }
        })
</script></div>
        
          <div class="navbar-item">

<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script></div>
        
          <div class="navbar-item"><ul class="navbar-icon-links"
    aria-label="Icon Links">
        <li class="nav-item">
            
          
          
          
          
          
          
          
          
          
          <a href="/status" title="Status: Unknown" class="ndif" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-solid fa-circle-check fa-lg" aria-hidden="true"></i>
            <span class="sr-only">Status: Unknown</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://github.com/ndif-team/nnsight" title="GitHub" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-github fa-lg" aria-hidden="true"></i>
            <span class="sr-only">GitHub</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://forms.gle/1Y6myaXYzSh3oHf56" title="Discord" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-discord fa-lg" aria-hidden="true"></i>
            <span class="sr-only">Discord</span></a>
        </li>
</ul></div>
        
      </div>
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">
<nav class="bd-docs-nav bd-links"
     aria-label="Section Navigation">
  <p class="bd-links__title" role="heading" aria-level="1">Section Navigation</p>
  <div class="bd-toc-item navbar-nav"><ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../LoRA_tutorial/">LoRA for Sentiment Analysis</a></li>




<li class="toctree-l1"><a class="reference internal" href="../activation_patching/">Activation Patching</a></li>




<li class="toctree-l1"><a class="reference internal" href="../attribution_patching/">Attribution Patching</a></li>
<li class="toctree-l1"><a class="reference internal" href="../boundless_DAS/">Boundless DAS</a></li>




<li class="toctree-l1"><a class="reference internal" href="../dict_learning/">Dictionary Learning</a></li>


<li class="toctree-l1"><a class="reference internal" href="../logit_lens/">Logit Lens</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">Walkthrough</a></li>





</ul>
</div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        
          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item">



<nav aria-label="Breadcrumb" class="d-print-none">
  <ul class="bd-breadcrumbs">
    
    <li class="breadcrumb-item breadcrumb-home">
      <a href="../../../" class="nav-link" aria-label="Home">
        <i class="fa-solid fa-home"></i>
      </a>
    </li>
    
    <li class="breadcrumb-item"><a href="../../../tutorials/" class="nav-link">Tutorials</a></li>
    
    <li class="breadcrumb-item active" aria-current="page">Walkthrough</li>
  </ul>
</nav>
</div>
      
    </div>
  
  
</div>
</div>
              
              
              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section id="Walkthrough">
<h1>Walkthrough<a class="headerlink" href="#Walkthrough" title="Link to this heading">#</a></h1>
<p>An interactive version of this walkthrough can be found <a class="reference external" href="https://colab.research.google.com/github/ndif-team/nnsight/blob/main/NNsight_Walkthrough.ipynb">here</a>.</p>
<p>In this era of large-scale deep learning, often the most interesting AI models are massive black boxes that are hard to run. Ordinary commercial inference APIs let us interact with huge models, but they do not let us access model internals.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">nnsight</span></code> library is different: it provides full access to all neural network internals. When used together with a remote service like the <a class="reference external" href="https://ndif.us/">National Deep Inference Fabric</a> (NDIF), it makes possible to run complex experiments on huge open models easily, with fully transparent access.</p>
<p>Our team wants to enable entire labs and independent researchers alike, as we believe a large, passionate, and collaborative community will produce the next big insights on this profoundly important field.</p>
</section>
<section id="1️⃣-First,-let's-start-small">
<h1>1️⃣ First, let’s start small<a class="headerlink" href="#1️⃣-First,-let's-start-small" title="Link to this heading">#</a></h1>
<section id="Tracing-Context">
<h2>Tracing Context<a class="headerlink" href="#Tracing-Context" title="Link to this heading">#</a></h2>
<p>To demonstrate the core functionality and syntax of nnsight, we’ll define and use a tiny two layer neural network.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[1]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Install nnsight</span>
<span class="o">!</span>pip<span class="w"> </span>install<span class="w"> </span>nnsight
<span class="o">!</span>pip<span class="w"> </span>install<span class="w"> </span>--upgrade<span class="w"> </span>transformers<span class="w"> </span>torch

<span class="kn">from</span> <span class="nn">IPython.display</span> <span class="kn">import</span> <span class="n">clear_output</span>

<span class="n">clear_output</span><span class="p">()</span>
</pre></div>
</div>
</div>
<p>Our little model here is composed of two submodules – linear layers ‘layer1’ and ‘layer2’. We specify the sizes of each of these modules, and create some complementary example input.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[2]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">OrderedDict</span>
<span class="kn">import</span> <span class="nn">torch</span>

<span class="n">input_size</span> <span class="o">=</span> <span class="mi">5</span>
<span class="n">hidden_dims</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">output_size</span> <span class="o">=</span> <span class="mi">2</span>

<span class="n">net</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
    <span class="n">OrderedDict</span><span class="p">(</span>
        <span class="p">[</span>
            <span class="p">(</span><span class="s2">&quot;layer1&quot;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">input_size</span><span class="p">,</span> <span class="n">hidden_dims</span><span class="p">)),</span>
            <span class="p">(</span><span class="s2">&quot;layer2&quot;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_dims</span><span class="p">,</span> <span class="n">output_size</span><span class="p">)),</span>
        <span class="p">]</span>
    <span class="p">)</span>
<span class="p">)</span><span class="o">.</span><span class="n">requires_grad_</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p>The core object of the nnsight package is <code class="docutils literal notranslate"><span class="pre">NNsight</span></code>. This wraps around a given pytorch model to enable the capabilities nnsight provides.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">nnsight</span>
<span class="kn">from</span> <span class="nn">nnsight</span> <span class="kn">import</span> <span class="n">NNsight</span>

<span class="n">tiny_model</span> <span class="o">=</span> <span class="n">NNsight</span><span class="p">(</span><span class="n">net</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p>Printing a Pytorch model shows a named hierarchy of modules which is very useful when accessing sub-components directly. NNsight reflect the same hierarchy and can be similarly printed.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[4]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">tiny_model</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Sequential(
  (layer1): Linear(in_features=5, out_features=10, bias=True)
  (layer2): Linear(in_features=10, out_features=2, bias=True)
)
</pre></div></div>
</div>
<p>Before we actually get to using the model we just created, let’s talk about Python contexts.</p>
<p>Python contexts define a scope using the <code class="docutils literal notranslate"><span class="pre">with</span></code> statement and are often used to create some object, or initiate some logic, that you later want to destroy or conclude.</p>
<p>The most common application is opening files like the following example:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s1">&#39;myfile.txt&#39;</span><span class="p">,</span> <span class="s1">&#39;r&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">file</span><span class="p">:</span>
  <span class="n">text</span> <span class="o">=</span> <span class="n">file</span><span class="o">.</span><span class="n">read</span><span class="p">()</span>
</pre></div>
</div>
<p>Python uses the <code class="docutils literal notranslate"><span class="pre">with</span></code> keyword to enter a context-like object. This object defines logic to be run at the start of the <code class="docutils literal notranslate"><span class="pre">with</span></code> block, as well as logic to be run when exiting. When using <code class="docutils literal notranslate"><span class="pre">with</span></code> for a file, entering the context opens the file and exiting the context closes it. Being within the context means we can read from the file. Simple enough! Now we can discuss how <code class="docutils literal notranslate"><span class="pre">nnsight</span></code> uses contexts to enable intuitive access into the internals of a neural network.</p>
<p>The main tool with <code class="docutils literal notranslate"><span class="pre">nnsight</span></code> is a context for tracing.</p>
<p>We enter the tracing context by calling <code class="docutils literal notranslate"><span class="pre">model.trace(&lt;input&gt;)</span></code> on an <code class="docutils literal notranslate"><span class="pre">NNsight</span></code> model, which defines how we want to run the model. Inside the context, we will be able to customize how the neural network runs. The model is actually run upon exiting the tracing context.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[5]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># random input</span>
<span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="n">input_size</span><span class="p">))</span>

<span class="k">with</span> <span class="n">tiny_model</span><span class="o">.</span><span class="n">trace</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span> <span class="k">as</span> <span class="n">tracer</span><span class="p">:</span>
    <span class="k">pass</span>
</pre></div>
</div>
</div>
<p>But where’s the output? To get that, we’ll have to learn how to request it from within the tracing context.</p>
</section>
<section id="Getting">
<h2>Getting<a class="headerlink" href="#Getting" title="Link to this heading">#</a></h2>
<p>Earlier, when we wrapped our little neural net with the <code class="docutils literal notranslate"><span class="pre">NNsight</span></code> class. This added a couple properties to each module in the model (including the root model itself). The two most important ones are <code class="docutils literal notranslate"><span class="pre">.input</span></code> and <code class="docutils literal notranslate"><span class="pre">.output</span></code>.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">input</span>
<span class="n">model</span><span class="o">.</span><span class="n">output</span>
</pre></div>
</div>
<p>The names are self explanatory. They correspond to the inputs and outputs of their respective modules during a forward pass of the model. We can use these attributes inside the <code class="docutils literal notranslate"><span class="pre">with</span></code> block.</p>
<p>However, it is important to understand that the model is not executed until the end of the tracing context. How can we access inputs and outputs before the model is run? The trick is deferred execution.</p>
<p><code class="docutils literal notranslate"><span class="pre">.input</span></code> and <code class="docutils literal notranslate"><span class="pre">.output</span></code> are Proxies for the eventual inputs and outputs of a module. In other words, when we access <code class="docutils literal notranslate"><span class="pre">model.output</span></code> what we are communicating to <code class="docutils literal notranslate"><span class="pre">nnsight</span></code> is, “When you compute the output of <code class="docutils literal notranslate"><span class="pre">model</span></code>, please grab it for me and put the value into its corresponding Proxy object’s <code class="docutils literal notranslate"><span class="pre">.value</span></code> attribute.” Let’s try it:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[6]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">tiny_model</span><span class="o">.</span><span class="n">trace</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span> <span class="k">as</span> <span class="n">tracer</span><span class="p">:</span>

    <span class="n">output</span> <span class="o">=</span> <span class="n">tiny_model</span><span class="o">.</span><span class="n">output</span>

<span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="o">.</span><span class="n">value</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
<span class="ansi-red-fg">---------------------------------------------------------------------------</span>
<span class="ansi-red-fg">ValueError</span>                                Traceback (most recent call last)
Cell <span class="ansi-green-fg">In[6], line 5</span>
<span class="ansi-green-intense-fg ansi-bold">      1</span> <span class="ansi-bold" style="color: rgb(0,135,0)">with</span> tiny_model<span style="color: rgb(98,98,98)">.</span>trace(<span style="color: rgb(0,135,0)">input</span>) <span class="ansi-bold" style="color: rgb(0,135,0)">as</span> tracer:
<span class="ansi-green-intense-fg ansi-bold">      3</span>     output <span style="color: rgb(98,98,98)">=</span> tiny_model<span style="color: rgb(98,98,98)">.</span>output
<span class="ansi-green-fg">----&gt; 5</span> <span style="color: rgb(0,135,0)">print</span>(<span class="ansi-yellow-bg">output</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">.</span><span class="ansi-yellow-bg">value</span>)

File <span class="ansi-green-fg">~/Projects/NDIF/nnsight/src/nnsight/tracing/Proxy.py:50</span>, in <span class="ansi-cyan-fg">Proxy.value</span><span class="ansi-blue-fg">(self)</span>
<span class="ansi-green-intense-fg ansi-bold">     42</span> <span style="color: rgb(175,0,255)">@property</span>
<span class="ansi-green-intense-fg ansi-bold">     43</span> <span class="ansi-bold" style="color: rgb(0,135,0)">def</span> <span style="color: rgb(0,0,255)">value</span>(<span style="color: rgb(0,135,0)">self</span>) <span style="color: rgb(98,98,98)">-</span><span style="color: rgb(98,98,98)">&gt;</span> Any:
<span class="ansi-green-intense-fg ansi-bold">     44</span> <span style="color: rgb(188,188,188)">    </span><span style="color: rgb(175,0,0)">&#34;&#34;&#34;Property to return the value of this proxy&#39;s node.</span>
<span class="ansi-green-intense-fg ansi-bold">     45</span>
<span class="ansi-green-intense-fg ansi-bold">     46</span> <span style="color: rgb(175,0,0)">    Returns:</span>
<span class="ansi-green-intense-fg ansi-bold">     47</span> <span style="color: rgb(175,0,0)">        Any: The stored value of the proxy, populated during execution of the model.</span>
<span class="ansi-green-intense-fg ansi-bold">     48</span> <span style="color: rgb(175,0,0)">    &#34;&#34;&#34;</span>
<span class="ansi-green-fg">---&gt; 50</span>     <span class="ansi-bold" style="color: rgb(0,135,0)">return</span> <span class="ansi-yellow-bg" style="color: rgb(0,135,0)">self</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">.</span><span class="ansi-yellow-bg">node</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">.</span><span class="ansi-yellow-bg">value</span>

File <span class="ansi-green-fg">~/Projects/NDIF/nnsight/src/nnsight/tracing/Node.py:182</span>, in <span class="ansi-cyan-fg">Node.value</span><span class="ansi-blue-fg">(self)</span>
<span class="ansi-green-intense-fg ansi-bold">    172</span> <span style="color: rgb(175,0,0)">&#34;&#34;&#34;Property to return the value of this node.</span>
<span class="ansi-green-intense-fg ansi-bold">    173</span>
<span class="ansi-green-intense-fg ansi-bold">    174</span> <span style="color: rgb(175,0,0)">Returns:</span>
<span class="ansi-green-fg">   (...)</span>
<span class="ansi-green-intense-fg ansi-bold">    178</span> <span style="color: rgb(175,0,0)">    ValueError: If the underlying ._value is inspect._empty (therefore never set or destroyed).</span>
<span class="ansi-green-intense-fg ansi-bold">    179</span> <span style="color: rgb(175,0,0)">&#34;&#34;&#34;</span>
<span class="ansi-green-intense-fg ansi-bold">    181</span> <span class="ansi-bold" style="color: rgb(0,135,0)">if</span> <span class="ansi-bold" style="color: rgb(175,0,255)">not</span> <span style="color: rgb(0,135,0)">self</span><span style="color: rgb(98,98,98)">.</span>done():
<span class="ansi-green-fg">--&gt; 182</span>     <span class="ansi-bold" style="color: rgb(0,135,0)">raise</span> <span class="ansi-bold" style="color: rgb(215,95,95)">ValueError</span>(<span style="color: rgb(175,0,0)">&#34;</span><span style="color: rgb(175,0,0)">Accessing value before it</span><span style="color: rgb(175,0,0)">&#39;</span><span style="color: rgb(175,0,0)">s been set.</span><span style="color: rgb(175,0,0)">&#34;</span>)
<span class="ansi-green-intense-fg ansi-bold">    184</span> <span class="ansi-bold" style="color: rgb(0,135,0)">return</span> <span style="color: rgb(0,135,0)">self</span><span style="color: rgb(98,98,98)">.</span>_value

<span class="ansi-red-fg">ValueError</span>: Accessing value before it&#39;s been set.
</pre></div></div>
</div>
<p>Oh no, an error! <code class="docutils literal notranslate"><span class="pre">ValueError:</span> <span class="pre">Accessing</span> <span class="pre">value</span> <span class="pre">before</span> <span class="pre">it's</span> <span class="pre">been</span> <span class="pre">set.</span></code></p>
<p>Why doesn’t our <code class="docutils literal notranslate"><span class="pre">output</span></code> have a <code class="docutils literal notranslate"><span class="pre">value</span></code>?</p>
<p>Proxy objects will only have their value at the end of a context if we call <code class="docutils literal notranslate"><span class="pre">.save()</span></code> on them. This helps to reduce memory costs. Adding <code class="docutils literal notranslate"><span class="pre">.save()</span></code> fixes the error:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[7]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">tiny_model</span><span class="o">.</span><span class="n">trace</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span> <span class="k">as</span> <span class="n">tracer</span><span class="p">:</span>

    <span class="n">output</span> <span class="o">=</span> <span class="n">tiny_model</span><span class="o">.</span><span class="n">output</span><span class="o">.</span><span class="n">save</span><span class="p">()</span>

<span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="o">.</span><span class="n">value</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
tensor([[-0.2687, -0.3314]])
</pre></div></div>
</div>
<p>Success! We now have the model output. We just completed out first intervention using <code class="docutils literal notranslate"><span class="pre">nnsight</span></code>.</p>
<p>Each time we access a module’s input or output, we create an <em>intervention</em> in the neural network’s forward pass. Collectively these requests form the <em>intervention graph</em>. We call the process of executing it alongside the model’s normal computation graph, <em>interleaving</em>.</p>
<details><summary><p>On Model output</p>
</summary><hr class="docutils" />
<p>If we don’t need to access anything other than the final model output, we can call the tracing context with <code class="docutils literal notranslate"><span class="pre">trace=False</span></code> and not use it as a context. This could be especially useful for easy remote inference.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">trace</span><span class="p">(</span><span class="o">&lt;</span><span class="n">inputs</span><span class="o">&gt;</span><span class="p">,</span> <span class="n">trace</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
<hr class="docutils" />
</details><p>Just like we saved the model’s final output, we can save the output of any of its submodules. Using normal Python attribute syntax, we can discover how to access them by name by printing out the model:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[8]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">tiny_model</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Sequential(
  (layer1): Linear(in_features=5, out_features=10, bias=True)
  (layer2): Linear(in_features=10, out_features=2, bias=True)
)
</pre></div></div>
</div>
<p>Let’s access the output of the first layer (non-coincidentally named ‘layer1’):</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[9]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">tiny_model</span><span class="o">.</span><span class="n">trace</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span> <span class="k">as</span> <span class="n">tracer</span><span class="p">:</span>

    <span class="n">l1_output</span> <span class="o">=</span> <span class="n">tiny_model</span><span class="o">.</span><span class="n">layer1</span><span class="o">.</span><span class="n">output</span><span class="o">.</span><span class="n">save</span><span class="p">()</span>

<span class="nb">print</span><span class="p">(</span><span class="n">l1_output</span><span class="o">.</span><span class="n">value</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
tensor([[ 0.2341,  0.3416, -0.8637, -0.5382, -0.3792, -0.1253,  0.4137,  0.5758,
         -0.3158, -0.1226]])
</pre></div></div>
</div>
<p>Let’s do the same for the input of layer2. While we’re at it, let’s also drop the <code class="docutils literal notranslate"><span class="pre">as</span> <span class="pre">tracer</span></code>, as we won’t be needing the <code class="docutils literal notranslate"><span class="pre">tracer</span></code> object for a few sections:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[10]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">tiny_model</span><span class="o">.</span><span class="n">trace</span><span class="p">(</span><span class="nb">input</span><span class="p">):</span>

    <span class="n">l2_input</span> <span class="o">=</span> <span class="n">tiny_model</span><span class="o">.</span><span class="n">layer2</span><span class="o">.</span><span class="n">input</span><span class="o">.</span><span class="n">save</span><span class="p">()</span>

<span class="nb">print</span><span class="p">(</span><span class="n">l2_input</span><span class="o">.</span><span class="n">value</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
tensor([[ 0.2341,  0.3416, -0.8637, -0.5382, -0.3792, -0.1253,  0.4137,  0.5758,
         -0.3158, -0.1226]])
</pre></div></div>
</div>
<details><summary><p>On module inputs</p>
</summary><hr class="docutils" />
<p>Notice how the value for <code class="docutils literal notranslate"><span class="pre">l2_input</span></code>, is just a single tensor. By default, the <code class="docutils literal notranslate"><span class="pre">.input</span></code> attribute of a module will return the <strong>first</strong> tensor input to the module.</p>
<p>We can also access the full input to a module by using the <code class="docutils literal notranslate"><span class="pre">.inputs</span></code> attribute which will return the values in the form of:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>tuple(tuple(args), dictionary(kwargs))
</pre></div>
</div>
<p>Where the first index of the tuple is itself a tuple of all positional arguments, and the second index is a dictionary of the keyword arguments.</p>
<hr class="docutils" />
</details><p>Until now we were saving the output of the model and its submodules within the <code class="docutils literal notranslate"><span class="pre">Trace</span></code> context to then print it after exiting the context. We will continuing doing this in the rest of the tutorial since it’s a good practice to save the computation results for later analysis.</p>
<p>However, we can also log the outputs of the model and its submodules within the <code class="docutils literal notranslate"><span class="pre">Trace</span></code> context. This is useful for debugging and understanding the model’s behavior while saving memory. Let’s see how to do this:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[11]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">tiny_model</span><span class="o">.</span><span class="n">trace</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span> <span class="k">as</span> <span class="n">tracer</span><span class="p">:</span>
  <span class="n">tracer</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="s2">&quot;Layer 1 - out: &quot;</span><span class="p">,</span> <span class="n">tiny_model</span><span class="o">.</span><span class="n">layer1</span><span class="o">.</span><span class="n">output</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Layer 1 - out:  tensor([[ 0.2341,  0.3416, -0.8637, -0.5382, -0.3792, -0.1253,  0.4137,  0.5758,
         -0.3158, -0.1226]])
</pre></div></div>
</div>
</section>
<section id="Functions,-Methods,-and-Operations">
<h2>Functions, Methods, and Operations<a class="headerlink" href="#Functions,-Methods,-and-Operations" title="Link to this heading">#</a></h2>
<p>Now that we can access activations, we also want to do some post-processing on it. Let’s find out which dimension of layer1’s output has the highest value.</p>
<p>We could do this by calling <code class="docutils literal notranslate"><span class="pre">torch.argmax(...)</span></code> after the tracing context or we can just leverage the fact that <code class="docutils literal notranslate"><span class="pre">nnsight</span></code> handles Pytorch functions and methods within the tracing context, by creating a Proxy request for it:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[12]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">tiny_model</span><span class="o">.</span><span class="n">trace</span><span class="p">(</span><span class="nb">input</span><span class="p">):</span>

    <span class="c1"># Note we don&#39;t need to call .save() on the output,</span>
    <span class="c1"># as we&#39;re only using its value within the tracing context.</span>
    <span class="n">l1_output</span> <span class="o">=</span> <span class="n">tiny_model</span><span class="o">.</span><span class="n">layer1</span><span class="o">.</span><span class="n">output</span>

    <span class="c1"># We do need to save the argmax tensor however,</span>
    <span class="c1"># as we&#39;re using it outside the tracing context.</span>
    <span class="n">l1_amax</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">l1_output</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">save</span><span class="p">()</span>

<span class="nb">print</span><span class="p">(</span><span class="n">l1_amax</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
tensor(7)
</pre></div></div>
</div>
<p>Nice! That worked seamlessly, but why didn’t we need to call <code class="docutils literal notranslate"><span class="pre">.value[0]</span></code> on the result? In previous sections, we were just being explicit to get an understanding of Proxies and their value. In practice, however, <code class="docutils literal notranslate"><span class="pre">nnsight</span></code> knows that when outside of the tracing context we only care about the actual value, and so printing, indexing, and applying functions all immediately return and reflect the data in <code class="docutils literal notranslate"><span class="pre">.value</span></code>. So for the rest of the tutorial we won’t use it.</p>
<p>The same principles work for Pytorch methods and all operators as well:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[13]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">tiny_model</span><span class="o">.</span><span class="n">trace</span><span class="p">(</span><span class="nb">input</span><span class="p">):</span>

    <span class="n">value</span> <span class="o">=</span> <span class="p">(</span><span class="n">tiny_model</span><span class="o">.</span><span class="n">layer1</span><span class="o">.</span><span class="n">output</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="o">+</span> <span class="n">tiny_model</span><span class="o">.</span><span class="n">layer2</span><span class="o">.</span><span class="n">output</span><span class="o">.</span><span class="n">sum</span><span class="p">())</span><span class="o">.</span><span class="n">save</span><span class="p">()</span>

<span class="nb">print</span><span class="p">(</span><span class="n">value</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
tensor(-1.3797)
</pre></div></div>
</div>
<p>The code block above is saying to <code class="docutils literal notranslate"><span class="pre">nnsight</span></code>, “Run the model with the given <code class="docutils literal notranslate"><span class="pre">input</span></code>. When the output of layer1 is computed, take its sum. Then do the same for layer2. Now that both of those are computed, add them and make sure not to delete this value as I wish to use it outside of the tracing context.”</p>
</section>
<section id="Custom-Functions">
<h2>Custom Functions<a class="headerlink" href="#Custom-Functions" title="Link to this heading">#</a></h2>
<p>Everything within the tracing context operates on the intervention graph. Therefore for <code class="docutils literal notranslate"><span class="pre">nnsight</span></code> to trace a function it must also be a part of the intervention graph.</p>
<p>Out-of-the-box <code class="docutils literal notranslate"><span class="pre">nnsight</span></code> supports Pytorch functions and methods, all operators, as well the <code class="docutils literal notranslate"><span class="pre">einops</span></code> library. We don’t need to do anything special to use them. But what do we do if we want to use custom functions? How do we add them to the intervention graph?</p>
<p>Enter <code class="docutils literal notranslate"><span class="pre">nnsight.apply()</span></code>. It allows us to add new functions to the intervention graph. Let’s see how it works:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[14]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Take a tensor and return the sum of its elements</span>
<span class="k">def</span> <span class="nf">tensor_sum</span><span class="p">(</span><span class="n">tensor</span><span class="p">):</span>
    <span class="n">flat</span> <span class="o">=</span> <span class="n">tensor</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>
    <span class="n">total</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">element</span> <span class="ow">in</span> <span class="n">flat</span><span class="p">:</span>
        <span class="n">total</span> <span class="o">+=</span> <span class="n">element</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>

    <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">total</span><span class="p">)</span>

<span class="k">with</span> <span class="n">tiny_model</span><span class="o">.</span><span class="n">trace</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span> <span class="k">as</span> <span class="n">tracer</span><span class="p">:</span>

    <span class="c1"># Specify the function name and its arguments (in a coma-separated form) to add to the intervention graph</span>
    <span class="n">custom_sum</span> <span class="o">=</span> <span class="n">nnsight</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">tensor_sum</span><span class="p">,</span> <span class="n">tiny_model</span><span class="o">.</span><span class="n">layer1</span><span class="o">.</span><span class="n">output</span><span class="p">)</span><span class="o">.</span><span class="n">save</span><span class="p">()</span>
    <span class="nb">sum</span> <span class="o">=</span> <span class="n">tiny_model</span><span class="o">.</span><span class="n">layer1</span><span class="o">.</span><span class="n">output</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
    <span class="nb">sum</span><span class="o">.</span><span class="n">save</span><span class="p">()</span>


<span class="nb">print</span><span class="p">(</span><span class="n">custom_sum</span><span class="p">,</span> <span class="nb">sum</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
tensor(-0.7796) tensor(-0.7796)
</pre></div></div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">nnsight.apply()</span></code> executes the function it wraps and returns its output as a Proxy object. We can then use this Proxy object as we would any other.</p>
<p>The applications of <code class="docutils literal notranslate"><span class="pre">nnsight.apply</span></code> are wide. It can be used to wrap any custom function or functions from libraries that <code class="docutils literal notranslate"><span class="pre">nnsight</span></code> does not support out-of-the-box.</p>
</section>
<section id="Setting">
<h2>Setting<a class="headerlink" href="#Setting" title="Link to this heading">#</a></h2>
<p>Getting and analyzing the activations from various points in a model can be really insightful, and a number of ML techniques do exactly that. However, we often not only want to view the computation of a model, but also to influence it.</p>
<p>To demonstrate the effect of editing the flow of information through the model, let’s set the first dimension of the first layer’s output to 0. <code class="docutils literal notranslate"><span class="pre">NNsight</span></code> makes this really easy using ‘=’ operator:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[15]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">tiny_model</span><span class="o">.</span><span class="n">trace</span><span class="p">(</span><span class="nb">input</span><span class="p">):</span>

    <span class="c1"># Save the output before the edit to compare.</span>
    <span class="c1"># Notice we apply .clone() before saving as the setting operation is in-place.</span>
    <span class="n">l1_output_before</span> <span class="o">=</span> <span class="n">tiny_model</span><span class="o">.</span><span class="n">layer1</span><span class="o">.</span><span class="n">output</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span><span class="o">.</span><span class="n">save</span><span class="p">()</span>

    <span class="c1"># Access the 0th index of the hidden state dimension and set it to 0.</span>
    <span class="n">tiny_model</span><span class="o">.</span><span class="n">layer1</span><span class="o">.</span><span class="n">output</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="c1"># Save the output after to see our edit.</span>
    <span class="n">l1_output_after</span> <span class="o">=</span> <span class="n">tiny_model</span><span class="o">.</span><span class="n">layer1</span><span class="o">.</span><span class="n">output</span><span class="o">.</span><span class="n">save</span><span class="p">()</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Before:&quot;</span><span class="p">,</span> <span class="n">l1_output_before</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;After:&quot;</span><span class="p">,</span> <span class="n">l1_output_after</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Before: tensor([[ 0.2341,  0.3416, -0.8637, -0.5382, -0.3792, -0.1253,  0.4137,  0.5758,
         -0.3158, -0.1226]])
After: tensor([[ 0.0000,  0.3416, -0.8637, -0.5382, -0.3792, -0.1253,  0.4137,  0.5758,
         -0.3158, -0.1226]])
</pre></div></div>
</div>
<p>Seems our change was reflected. Now the same for the last dimension:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[16]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">tiny_model</span><span class="o">.</span><span class="n">trace</span><span class="p">(</span><span class="nb">input</span><span class="p">):</span>

    <span class="c1"># Save the output before the edit to compare.</span>
    <span class="c1"># Notice we apply .clone() before saving as the setting operation is in-place.</span>
    <span class="n">l1_output_before</span> <span class="o">=</span> <span class="n">tiny_model</span><span class="o">.</span><span class="n">layer1</span><span class="o">.</span><span class="n">output</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span><span class="o">.</span><span class="n">save</span><span class="p">()</span>

    <span class="c1"># Access the last index of the hidden state dimension and set it to 0.</span>
    <span class="n">tiny_model</span><span class="o">.</span><span class="n">layer1</span><span class="o">.</span><span class="n">output</span><span class="p">[:,</span> <span class="n">hidden_dims</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="c1"># Save the output after to see our edit.</span>
    <span class="n">l1_output_after</span> <span class="o">=</span> <span class="n">tiny_model</span><span class="o">.</span><span class="n">layer1</span><span class="o">.</span><span class="n">output</span><span class="o">.</span><span class="n">save</span><span class="p">()</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Before:&quot;</span><span class="p">,</span> <span class="n">l1_output_before</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;After:&quot;</span><span class="p">,</span> <span class="n">l1_output_after</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
<span class="ansi-red-fg">---------------------------------------------------------------------------</span>
<span class="ansi-red-fg">IndexError</span>                                Traceback (most recent call last)
File <span class="ansi-green-fg">~/Projects/NDIF/nnsight/src/nnsight/tracing/Node.py:380</span>, in <span class="ansi-cyan-fg">Node.execute</span><span class="ansi-blue-fg">(self)</span>
<span class="ansi-green-intense-fg ansi-bold">    379</span> <span style="color: rgb(95,135,135)"># Call the target to get value.</span>
<span class="ansi-green-fg">--&gt; 380</span> output <span style="color: rgb(98,98,98)">=</span> <span class="ansi-yellow-bg" style="color: rgb(0,135,0)">self</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">.</span><span class="ansi-yellow-bg">target</span><span class="ansi-yellow-bg">(</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">*</span><span class="ansi-yellow-bg">args</span><span class="ansi-yellow-bg">,</span><span class="ansi-yellow-bg"> </span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">*</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">*</span><span class="ansi-yellow-bg">kwargs</span><span class="ansi-yellow-bg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    382</span> <span style="color: rgb(95,135,135)"># Set value.</span>

<span class="ansi-red-fg">IndexError</span>: index 10 is out of bounds for dimension 1 with size 10

The above exception was the direct cause of the following exception:

<span class="ansi-red-fg">IndexError</span>                                Traceback (most recent call last)
Cell <span class="ansi-green-fg">In[16], line 1</span>
<span class="ansi-green-fg">----&gt; 1</span> <span class="ansi-yellow-bg ansi-bold" style="color: rgb(0,135,0)">with</span><span class="ansi-yellow-bg"> </span><span class="ansi-yellow-bg">tiny_model</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">.</span><span class="ansi-yellow-bg">trace</span><span class="ansi-yellow-bg">(</span><span class="ansi-yellow-bg" style="color: rgb(0,135,0)">input</span><span class="ansi-yellow-bg">)</span><span class="ansi-yellow-bg">:</span>
<span class="ansi-green-intense-fg ansi-bold">      2</span>
<span class="ansi-green-intense-fg ansi-bold">      3</span> <span class="ansi-yellow-bg">    </span><span class="ansi-yellow-bg" style="color: rgb(95,135,135)"># Save the output before the edit to compare.</span>
<span class="ansi-green-intense-fg ansi-bold">      4</span> <span class="ansi-yellow-bg">    </span><span class="ansi-yellow-bg" style="color: rgb(95,135,135)"># Notice we apply .clone() before saving as the setting operation is in-place.</span>
<span class="ansi-green-intense-fg ansi-bold">      5</span> <span class="ansi-yellow-bg">    </span><span class="ansi-yellow-bg">l1_output_before</span><span class="ansi-yellow-bg"> </span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">=</span><span class="ansi-yellow-bg"> </span><span class="ansi-yellow-bg">tiny_model</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">.</span><span class="ansi-yellow-bg">layer1</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">.</span><span class="ansi-yellow-bg">output</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">.</span><span class="ansi-yellow-bg">clone</span><span class="ansi-yellow-bg">(</span><span class="ansi-yellow-bg">)</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">.</span><span class="ansi-yellow-bg">save</span><span class="ansi-yellow-bg">(</span><span class="ansi-yellow-bg">)</span>
<span class="ansi-green-intense-fg ansi-bold">      7</span> <span class="ansi-yellow-bg">    </span><span class="ansi-yellow-bg" style="color: rgb(95,135,135)"># Access the last index of the hidden state dimension and set it to 0.</span>

File <span class="ansi-green-fg">~/Projects/NDIF/nnsight/src/nnsight/contexts/Tracer.py:103</span>, in <span class="ansi-cyan-fg">Tracer.__exit__</span><span class="ansi-blue-fg">(self, exc_type, exc_val, exc_tb)</span>
<span class="ansi-green-intense-fg ansi-bold">     98</span>     <span style="color: rgb(0,135,0)">self</span><span style="color: rgb(98,98,98)">.</span>invoker<span style="color: rgb(98,98,98)">.</span><span style="color: rgb(0,0,255)">__exit__</span>(<span class="ansi-bold" style="color: rgb(0,135,0)">None</span>, <span class="ansi-bold" style="color: rgb(0,135,0)">None</span>, <span class="ansi-bold" style="color: rgb(0,135,0)">None</span>)
<span class="ansi-green-intense-fg ansi-bold">    100</span> <span style="color: rgb(0,135,0)">self</span><span style="color: rgb(98,98,98)">.</span>model<span style="color: rgb(98,98,98)">.</span>_envoy<span style="color: rgb(98,98,98)">.</span>_reset()
<span class="ansi-green-fg">--&gt; 103</span> <span class="ansi-yellow-bg" style="color: rgb(0,135,0)">super</span><span class="ansi-yellow-bg">(</span><span class="ansi-yellow-bg">)</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">.</span><span class="ansi-yellow-bg" style="color: rgb(0,0,255)">__exit__</span><span class="ansi-yellow-bg">(</span><span class="ansi-yellow-bg">exc_type</span><span class="ansi-yellow-bg">,</span><span class="ansi-yellow-bg"> </span><span class="ansi-yellow-bg">exc_val</span><span class="ansi-yellow-bg">,</span><span class="ansi-yellow-bg"> </span><span class="ansi-yellow-bg">exc_tb</span><span class="ansi-yellow-bg">)</span>

File <span class="ansi-green-fg">~/Projects/NDIF/nnsight/src/nnsight/contexts/GraphBasedContext.py:218</span>, in <span class="ansi-cyan-fg">GraphBasedContext.__exit__</span><span class="ansi-blue-fg">(self, exc_type, exc_val, exc_tb)</span>
<span class="ansi-green-intense-fg ansi-bold">    215</span>     <span style="color: rgb(0,135,0)">self</span><span style="color: rgb(98,98,98)">.</span>graph <span style="color: rgb(98,98,98)">=</span> <span class="ansi-bold" style="color: rgb(0,135,0)">None</span>
<span class="ansi-green-intense-fg ansi-bold">    216</span>     <span class="ansi-bold" style="color: rgb(0,135,0)">raise</span> exc_val
<span class="ansi-green-fg">--&gt; 218</span> <span class="ansi-yellow-bg" style="color: rgb(0,135,0)">self</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">.</span><span class="ansi-yellow-bg">backend</span><span class="ansi-yellow-bg">(</span><span class="ansi-yellow-bg" style="color: rgb(0,135,0)">self</span><span class="ansi-yellow-bg">)</span>

File <span class="ansi-green-fg">~/Projects/NDIF/nnsight/src/nnsight/contexts/backends/LocalBackend.py:27</span>, in <span class="ansi-cyan-fg">LocalBackend.__call__</span><span class="ansi-blue-fg">(self, obj)</span>
<span class="ansi-green-intense-fg ansi-bold">     25</span> <span class="ansi-bold" style="color: rgb(0,135,0)">def</span> <span style="color: rgb(0,0,255)">__call__</span>(<span style="color: rgb(0,135,0)">self</span>, obj: LocalMixin):
<span class="ansi-green-fg">---&gt; 27</span>     <span class="ansi-yellow-bg">obj</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">.</span><span class="ansi-yellow-bg">local_backend_execute</span><span class="ansi-yellow-bg">(</span><span class="ansi-yellow-bg">)</span>

File <span class="ansi-green-fg">~/Projects/NDIF/nnsight/src/nnsight/contexts/Tracer.py:147</span>, in <span class="ansi-cyan-fg">Tracer.local_backend_execute</span><span class="ansi-blue-fg">(self)</span>
<span class="ansi-green-intense-fg ansi-bold">    143</span>     invoker_inputs <span style="color: rgb(98,98,98)">=</span> resolve_dependencies(invoker_inputs)
<span class="ansi-green-intense-fg ansi-bold">    145</span> <span style="color: rgb(0,135,0)">self</span><span style="color: rgb(98,98,98)">.</span>graph<span style="color: rgb(98,98,98)">.</span>execute()
<span class="ansi-green-fg">--&gt; 147</span> <span class="ansi-yellow-bg" style="color: rgb(0,135,0)">self</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">.</span><span class="ansi-yellow-bg">model</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">.</span><span class="ansi-yellow-bg">interleave</span><span class="ansi-yellow-bg">(</span>
<span class="ansi-green-intense-fg ansi-bold">    148</span> <span class="ansi-yellow-bg">    </span><span class="ansi-yellow-bg" style="color: rgb(0,135,0)">self</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">.</span><span class="ansi-yellow-bg">model</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">.</span><span class="ansi-yellow-bg">_execute</span><span class="ansi-yellow-bg">,</span>
<span class="ansi-green-intense-fg ansi-bold">    149</span> <span class="ansi-yellow-bg">    </span><span class="ansi-yellow-bg" style="color: rgb(0,135,0)">self</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">.</span><span class="ansi-yellow-bg">graph</span><span class="ansi-yellow-bg">,</span>
<span class="ansi-green-intense-fg ansi-bold">    150</span> <span class="ansi-yellow-bg">    </span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">*</span><span class="ansi-yellow-bg">invoker_inputs</span><span class="ansi-yellow-bg">,</span>
<span class="ansi-green-intense-fg ansi-bold">    151</span> <span class="ansi-yellow-bg">    </span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">*</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">*</span><span class="ansi-yellow-bg" style="color: rgb(0,135,0)">self</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">.</span><span class="ansi-yellow-bg">_kwargs</span><span class="ansi-yellow-bg">,</span>
<span class="ansi-green-intense-fg ansi-bold">    152</span> <span class="ansi-yellow-bg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    154</span> graph <span style="color: rgb(98,98,98)">=</span> <span style="color: rgb(0,135,0)">self</span><span style="color: rgb(98,98,98)">.</span>graph
<span class="ansi-green-intense-fg ansi-bold">    155</span> graph<span style="color: rgb(98,98,98)">.</span>alive <span style="color: rgb(98,98,98)">=</span> <span class="ansi-bold" style="color: rgb(0,135,0)">False</span>

File <span class="ansi-green-fg">~/Projects/NDIF/nnsight/src/nnsight/models/NNsightModel.py:462</span>, in <span class="ansi-cyan-fg">NNsight.interleave</span><span class="ansi-blue-fg">(self, fn, intervention_graph, *inputs, **kwargs)</span>
<span class="ansi-green-intense-fg ansi-bold">    454</span> intervention_handler <span style="color: rgb(98,98,98)">=</span> InterventionHandler(
<span class="ansi-green-intense-fg ansi-bold">    455</span>     intervention_graph, batch_groups, batch_size
<span class="ansi-green-intense-fg ansi-bold">    456</span> )
<span class="ansi-green-intense-fg ansi-bold">    458</span> module_paths <span style="color: rgb(98,98,98)">=</span> InterventionProtocol<span style="color: rgb(98,98,98)">.</span>get_interventions(
<span class="ansi-green-intense-fg ansi-bold">    459</span>     intervention_graph
<span class="ansi-green-intense-fg ansi-bold">    460</span> )<span style="color: rgb(98,98,98)">.</span>keys()
<span class="ansi-green-fg">--&gt; 462</span> <span class="ansi-yellow-bg ansi-bold" style="color: rgb(0,135,0)">with</span><span class="ansi-yellow-bg"> </span><span class="ansi-yellow-bg">HookHandler</span><span class="ansi-yellow-bg">(</span>
<span class="ansi-green-intense-fg ansi-bold">    463</span> <span class="ansi-yellow-bg">    </span><span class="ansi-yellow-bg" style="color: rgb(0,135,0)">self</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">.</span><span class="ansi-yellow-bg">_model</span><span class="ansi-yellow-bg">,</span>
<span class="ansi-green-intense-fg ansi-bold">    464</span> <span class="ansi-yellow-bg">    </span><span class="ansi-yellow-bg" style="color: rgb(0,135,0)">list</span><span class="ansi-yellow-bg">(</span><span class="ansi-yellow-bg">module_paths</span><span class="ansi-yellow-bg">)</span><span class="ansi-yellow-bg">,</span>
<span class="ansi-green-intense-fg ansi-bold">    465</span> <span class="ansi-yellow-bg">    </span><span class="ansi-yellow-bg">input_hook</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">=</span><span class="ansi-yellow-bg ansi-bold" style="color: rgb(0,135,0)">lambda</span><span class="ansi-yellow-bg"> </span><span class="ansi-yellow-bg">activations</span><span class="ansi-yellow-bg">,</span><span class="ansi-yellow-bg"> </span><span class="ansi-yellow-bg">module_path</span><span class="ansi-yellow-bg">:</span><span class="ansi-yellow-bg"> </span><span class="ansi-yellow-bg">InterventionProtocol</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">.</span><span class="ansi-yellow-bg">intervene</span><span class="ansi-yellow-bg">(</span>
<span class="ansi-green-intense-fg ansi-bold">    466</span> <span class="ansi-yellow-bg">        </span><span class="ansi-yellow-bg">activations</span><span class="ansi-yellow-bg">,</span><span class="ansi-yellow-bg"> </span><span class="ansi-yellow-bg">module_path</span><span class="ansi-yellow-bg">,</span><span class="ansi-yellow-bg"> </span><span class="ansi-yellow-bg" style="color: rgb(175,0,0)">&#34;</span><span class="ansi-yellow-bg" style="color: rgb(175,0,0)">input</span><span class="ansi-yellow-bg" style="color: rgb(175,0,0)">&#34;</span><span class="ansi-yellow-bg">,</span><span class="ansi-yellow-bg"> </span><span class="ansi-yellow-bg">intervention_handler</span>
<span class="ansi-green-intense-fg ansi-bold">    467</span> <span class="ansi-yellow-bg">    </span><span class="ansi-yellow-bg">)</span><span class="ansi-yellow-bg">,</span>
<span class="ansi-green-intense-fg ansi-bold">    468</span> <span class="ansi-yellow-bg">    </span><span class="ansi-yellow-bg">output_hook</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">=</span><span class="ansi-yellow-bg ansi-bold" style="color: rgb(0,135,0)">lambda</span><span class="ansi-yellow-bg"> </span><span class="ansi-yellow-bg">activations</span><span class="ansi-yellow-bg">,</span><span class="ansi-yellow-bg"> </span><span class="ansi-yellow-bg">module_path</span><span class="ansi-yellow-bg">:</span><span class="ansi-yellow-bg"> </span><span class="ansi-yellow-bg">InterventionProtocol</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">.</span><span class="ansi-yellow-bg">intervene</span><span class="ansi-yellow-bg">(</span>
<span class="ansi-green-intense-fg ansi-bold">    469</span> <span class="ansi-yellow-bg">        </span><span class="ansi-yellow-bg">activations</span><span class="ansi-yellow-bg">,</span><span class="ansi-yellow-bg"> </span><span class="ansi-yellow-bg">module_path</span><span class="ansi-yellow-bg">,</span><span class="ansi-yellow-bg"> </span><span class="ansi-yellow-bg" style="color: rgb(175,0,0)">&#34;</span><span class="ansi-yellow-bg" style="color: rgb(175,0,0)">output</span><span class="ansi-yellow-bg" style="color: rgb(175,0,0)">&#34;</span><span class="ansi-yellow-bg">,</span><span class="ansi-yellow-bg"> </span><span class="ansi-yellow-bg">intervention_handler</span>
<span class="ansi-green-intense-fg ansi-bold">    470</span> <span class="ansi-yellow-bg">    </span><span class="ansi-yellow-bg">)</span><span class="ansi-yellow-bg">,</span>
<span class="ansi-green-intense-fg ansi-bold">    471</span> <span class="ansi-yellow-bg">)</span><span class="ansi-yellow-bg">:</span>
<span class="ansi-green-intense-fg ansi-bold">    472</span> <span class="ansi-yellow-bg">    </span><span class="ansi-yellow-bg ansi-bold" style="color: rgb(0,135,0)">try</span><span class="ansi-yellow-bg">:</span>
<span class="ansi-green-intense-fg ansi-bold">    473</span> <span class="ansi-yellow-bg">        </span><span class="ansi-yellow-bg">fn</span><span class="ansi-yellow-bg">(</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">*</span><span class="ansi-yellow-bg">inputs</span><span class="ansi-yellow-bg">,</span><span class="ansi-yellow-bg"> </span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">*</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">*</span><span class="ansi-yellow-bg">kwargs</span><span class="ansi-yellow-bg">)</span>

File <span class="ansi-green-fg">~/Projects/NDIF/nnsight/src/nnsight/intervention.py:574</span>, in <span class="ansi-cyan-fg">HookHandler.__exit__</span><span class="ansi-blue-fg">(self, exc_type, exc_val, exc_tb)</span>
<span class="ansi-green-intense-fg ansi-bold">    571</span>     handle<span style="color: rgb(98,98,98)">.</span>remove()
<span class="ansi-green-intense-fg ansi-bold">    573</span> <span class="ansi-bold" style="color: rgb(0,135,0)">if</span> <span style="color: rgb(0,135,0)">isinstance</span>(exc_val, <span class="ansi-bold" style="color: rgb(215,95,95)">Exception</span>):
<span class="ansi-green-fg">--&gt; 574</span>     <span class="ansi-bold" style="color: rgb(0,135,0)">raise</span> exc_val

File <span class="ansi-green-fg">~/Projects/NDIF/nnsight/src/nnsight/models/NNsightModel.py:473</span>, in <span class="ansi-cyan-fg">NNsight.interleave</span><span class="ansi-blue-fg">(self, fn, intervention_graph, *inputs, **kwargs)</span>
<span class="ansi-green-intense-fg ansi-bold">    462</span> <span class="ansi-bold" style="color: rgb(0,135,0)">with</span> HookHandler(
<span class="ansi-green-intense-fg ansi-bold">    463</span>     <span style="color: rgb(0,135,0)">self</span><span style="color: rgb(98,98,98)">.</span>_model,
<span class="ansi-green-intense-fg ansi-bold">    464</span>     <span style="color: rgb(0,135,0)">list</span>(module_paths),
<span class="ansi-green-fg">   (...)</span>
<span class="ansi-green-intense-fg ansi-bold">    470</span>     ),
<span class="ansi-green-intense-fg ansi-bold">    471</span> ):
<span class="ansi-green-intense-fg ansi-bold">    472</span>     <span class="ansi-bold" style="color: rgb(0,135,0)">try</span>:
<span class="ansi-green-fg">--&gt; 473</span>         <span class="ansi-yellow-bg">fn</span><span class="ansi-yellow-bg">(</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">*</span><span class="ansi-yellow-bg">inputs</span><span class="ansi-yellow-bg">,</span><span class="ansi-yellow-bg"> </span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">*</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">*</span><span class="ansi-yellow-bg">kwargs</span><span class="ansi-yellow-bg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    474</span>     <span class="ansi-bold" style="color: rgb(0,135,0)">except</span> protocols<span style="color: rgb(98,98,98)">.</span>EarlyStopProtocol<span style="color: rgb(98,98,98)">.</span>EarlyStopException:
<span class="ansi-green-intense-fg ansi-bold">    475</span>         <span style="color: rgb(95,135,135)"># TODO: Log.</span>
<span class="ansi-green-intense-fg ansi-bold">    476</span>         <span class="ansi-bold" style="color: rgb(0,135,0)">for</span> node <span class="ansi-bold" style="color: rgb(175,0,255)">in</span> intervention_graph<span style="color: rgb(98,98,98)">.</span>nodes<span style="color: rgb(98,98,98)">.</span>values():

File <span class="ansi-green-fg">~/Projects/NDIF/nnsight/src/nnsight/models/NNsightModel.py:584</span>, in <span class="ansi-cyan-fg">NNsight._execute</span><span class="ansi-blue-fg">(self, *prepared_inputs, **kwargs)</span>
<span class="ansi-green-intense-fg ansi-bold">    581</span> <span class="ansi-bold" style="color: rgb(0,135,0)">except</span>:
<span class="ansi-green-intense-fg ansi-bold">    582</span>     <span class="ansi-bold" style="color: rgb(0,135,0)">pass</span>
<span class="ansi-green-fg">--&gt; 584</span> <span class="ansi-bold" style="color: rgb(0,135,0)">return</span> <span class="ansi-yellow-bg" style="color: rgb(0,135,0)">self</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">.</span><span class="ansi-yellow-bg">_model</span><span class="ansi-yellow-bg">(</span>
<span class="ansi-green-intense-fg ansi-bold">    585</span> <span class="ansi-yellow-bg">    </span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">*</span><span class="ansi-yellow-bg">prepared_inputs</span><span class="ansi-yellow-bg">,</span>
<span class="ansi-green-intense-fg ansi-bold">    586</span> <span class="ansi-yellow-bg">    </span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">*</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">*</span><span class="ansi-yellow-bg">kwargs</span><span class="ansi-yellow-bg">,</span>
<span class="ansi-green-intense-fg ansi-bold">    587</span> <span class="ansi-yellow-bg">)</span>

File <span class="ansi-green-fg">/opt/homebrew/anaconda3/envs/nnsight_local/lib/python3.12/site-packages/torch/nn/modules/module.py:1553</span>, in <span class="ansi-cyan-fg">Module._wrapped_call_impl</span><span class="ansi-blue-fg">(self, *args, **kwargs)</span>
<span class="ansi-green-intense-fg ansi-bold">   1551</span>     <span class="ansi-bold" style="color: rgb(0,135,0)">return</span> <span style="color: rgb(0,135,0)">self</span><span style="color: rgb(98,98,98)">.</span>_compiled_call_impl(<span style="color: rgb(98,98,98)">*</span>args, <span style="color: rgb(98,98,98)">*</span><span style="color: rgb(98,98,98)">*</span>kwargs)  <span style="color: rgb(95,135,135)"># type: ignore[misc]</span>
<span class="ansi-green-intense-fg ansi-bold">   1552</span> <span class="ansi-bold" style="color: rgb(0,135,0)">else</span>:
<span class="ansi-green-fg">-&gt; 1553</span>     <span class="ansi-bold" style="color: rgb(0,135,0)">return</span> <span class="ansi-yellow-bg" style="color: rgb(0,135,0)">self</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">.</span><span class="ansi-yellow-bg">_call_impl</span><span class="ansi-yellow-bg">(</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">*</span><span class="ansi-yellow-bg">args</span><span class="ansi-yellow-bg">,</span><span class="ansi-yellow-bg"> </span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">*</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">*</span><span class="ansi-yellow-bg">kwargs</span><span class="ansi-yellow-bg">)</span>

File <span class="ansi-green-fg">/opt/homebrew/anaconda3/envs/nnsight_local/lib/python3.12/site-packages/torch/nn/modules/module.py:1603</span>, in <span class="ansi-cyan-fg">Module._call_impl</span><span class="ansi-blue-fg">(self, *args, **kwargs)</span>
<span class="ansi-green-intense-fg ansi-bold">   1600</span>     bw_hook <span style="color: rgb(98,98,98)">=</span> hooks<span style="color: rgb(98,98,98)">.</span>BackwardHook(<span style="color: rgb(0,135,0)">self</span>, full_backward_hooks, backward_pre_hooks)
<span class="ansi-green-intense-fg ansi-bold">   1601</span>     args <span style="color: rgb(98,98,98)">=</span> bw_hook<span style="color: rgb(98,98,98)">.</span>setup_input_hook(args)
<span class="ansi-green-fg">-&gt; 1603</span> result <span style="color: rgb(98,98,98)">=</span> <span class="ansi-yellow-bg">forward_call</span><span class="ansi-yellow-bg">(</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">*</span><span class="ansi-yellow-bg">args</span><span class="ansi-yellow-bg">,</span><span class="ansi-yellow-bg"> </span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">*</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">*</span><span class="ansi-yellow-bg">kwargs</span><span class="ansi-yellow-bg">)</span>
<span class="ansi-green-intense-fg ansi-bold">   1604</span> <span class="ansi-bold" style="color: rgb(0,135,0)">if</span> _global_forward_hooks <span class="ansi-bold" style="color: rgb(175,0,255)">or</span> <span style="color: rgb(0,135,0)">self</span><span style="color: rgb(98,98,98)">.</span>_forward_hooks:
<span class="ansi-green-intense-fg ansi-bold">   1605</span>     <span class="ansi-bold" style="color: rgb(0,135,0)">for</span> hook_id, hook <span class="ansi-bold" style="color: rgb(175,0,255)">in</span> (
<span class="ansi-green-intense-fg ansi-bold">   1606</span>         <span style="color: rgb(98,98,98)">*</span>_global_forward_hooks<span style="color: rgb(98,98,98)">.</span>items(),
<span class="ansi-green-intense-fg ansi-bold">   1607</span>         <span style="color: rgb(98,98,98)">*</span><span style="color: rgb(0,135,0)">self</span><span style="color: rgb(98,98,98)">.</span>_forward_hooks<span style="color: rgb(98,98,98)">.</span>items(),
<span class="ansi-green-intense-fg ansi-bold">   1608</span>     ):
<span class="ansi-green-intense-fg ansi-bold">   1609</span>         <span style="color: rgb(95,135,135)"># mark that always called hook is run</span>

File <span class="ansi-green-fg">/opt/homebrew/anaconda3/envs/nnsight_local/lib/python3.12/site-packages/torch/nn/modules/container.py:219</span>, in <span class="ansi-cyan-fg">Sequential.forward</span><span class="ansi-blue-fg">(self, input)</span>
<span class="ansi-green-intense-fg ansi-bold">    217</span> <span class="ansi-bold" style="color: rgb(0,135,0)">def</span> <span style="color: rgb(0,0,255)">forward</span>(<span style="color: rgb(0,135,0)">self</span>, <span style="color: rgb(0,135,0)">input</span>):
<span class="ansi-green-intense-fg ansi-bold">    218</span>     <span class="ansi-bold" style="color: rgb(0,135,0)">for</span> module <span class="ansi-bold" style="color: rgb(175,0,255)">in</span> <span style="color: rgb(0,135,0)">self</span>:
<span class="ansi-green-fg">--&gt; 219</span>         <span style="color: rgb(0,135,0)">input</span> <span style="color: rgb(98,98,98)">=</span> <span class="ansi-yellow-bg">module</span><span class="ansi-yellow-bg">(</span><span class="ansi-yellow-bg" style="color: rgb(0,135,0)">input</span><span class="ansi-yellow-bg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    220</span>     <span class="ansi-bold" style="color: rgb(0,135,0)">return</span> <span style="color: rgb(0,135,0)">input</span>

File <span class="ansi-green-fg">/opt/homebrew/anaconda3/envs/nnsight_local/lib/python3.12/site-packages/torch/nn/modules/module.py:1553</span>, in <span class="ansi-cyan-fg">Module._wrapped_call_impl</span><span class="ansi-blue-fg">(self, *args, **kwargs)</span>
<span class="ansi-green-intense-fg ansi-bold">   1551</span>     <span class="ansi-bold" style="color: rgb(0,135,0)">return</span> <span style="color: rgb(0,135,0)">self</span><span style="color: rgb(98,98,98)">.</span>_compiled_call_impl(<span style="color: rgb(98,98,98)">*</span>args, <span style="color: rgb(98,98,98)">*</span><span style="color: rgb(98,98,98)">*</span>kwargs)  <span style="color: rgb(95,135,135)"># type: ignore[misc]</span>
<span class="ansi-green-intense-fg ansi-bold">   1552</span> <span class="ansi-bold" style="color: rgb(0,135,0)">else</span>:
<span class="ansi-green-fg">-&gt; 1553</span>     <span class="ansi-bold" style="color: rgb(0,135,0)">return</span> <span class="ansi-yellow-bg" style="color: rgb(0,135,0)">self</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">.</span><span class="ansi-yellow-bg">_call_impl</span><span class="ansi-yellow-bg">(</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">*</span><span class="ansi-yellow-bg">args</span><span class="ansi-yellow-bg">,</span><span class="ansi-yellow-bg"> </span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">*</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">*</span><span class="ansi-yellow-bg">kwargs</span><span class="ansi-yellow-bg">)</span>

File <span class="ansi-green-fg">/opt/homebrew/anaconda3/envs/nnsight_local/lib/python3.12/site-packages/torch/nn/modules/module.py:1616</span>, in <span class="ansi-cyan-fg">Module._call_impl</span><span class="ansi-blue-fg">(self, *args, **kwargs)</span>
<span class="ansi-green-intense-fg ansi-bold">   1614</span>     hook_result <span style="color: rgb(98,98,98)">=</span> hook(<span style="color: rgb(0,135,0)">self</span>, args, kwargs, result)
<span class="ansi-green-intense-fg ansi-bold">   1615</span> <span class="ansi-bold" style="color: rgb(0,135,0)">else</span>:
<span class="ansi-green-fg">-&gt; 1616</span>     hook_result <span style="color: rgb(98,98,98)">=</span> <span class="ansi-yellow-bg">hook</span><span class="ansi-yellow-bg">(</span><span class="ansi-yellow-bg" style="color: rgb(0,135,0)">self</span><span class="ansi-yellow-bg">,</span><span class="ansi-yellow-bg"> </span><span class="ansi-yellow-bg">args</span><span class="ansi-yellow-bg">,</span><span class="ansi-yellow-bg"> </span><span class="ansi-yellow-bg">result</span><span class="ansi-yellow-bg">)</span>
<span class="ansi-green-intense-fg ansi-bold">   1618</span> <span class="ansi-bold" style="color: rgb(0,135,0)">if</span> hook_result <span class="ansi-bold" style="color: rgb(175,0,255)">is</span> <span class="ansi-bold" style="color: rgb(175,0,255)">not</span> <span class="ansi-bold" style="color: rgb(0,135,0)">None</span>:
<span class="ansi-green-intense-fg ansi-bold">   1619</span>     result <span style="color: rgb(98,98,98)">=</span> hook_result

File <span class="ansi-green-fg">~/Projects/NDIF/nnsight/src/nnsight/intervention.py:559</span>, in <span class="ansi-cyan-fg">HookHandler.__enter__.&lt;locals&gt;.output_hook</span><span class="ansi-blue-fg">(module, input, output, module_path)</span>
<span class="ansi-green-intense-fg ansi-bold">    558</span> <span class="ansi-bold" style="color: rgb(0,135,0)">def</span> <span style="color: rgb(0,0,255)">output_hook</span>(module, <span style="color: rgb(0,135,0)">input</span>, output, module_path<span style="color: rgb(98,98,98)">=</span>module_path):
<span class="ansi-green-fg">--&gt; 559</span>     <span class="ansi-bold" style="color: rgb(0,135,0)">return</span> <span class="ansi-yellow-bg" style="color: rgb(0,135,0)">self</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">.</span><span class="ansi-yellow-bg">output_hook</span><span class="ansi-yellow-bg">(</span><span class="ansi-yellow-bg">output</span><span class="ansi-yellow-bg">,</span><span class="ansi-yellow-bg"> </span><span class="ansi-yellow-bg">module_path</span><span class="ansi-yellow-bg">)</span>

File <span class="ansi-green-fg">~/Projects/NDIF/nnsight/src/nnsight/models/NNsightModel.py:468</span>, in <span class="ansi-cyan-fg">NNsight.interleave.&lt;locals&gt;.&lt;lambda&gt;</span><span class="ansi-blue-fg">(activations, module_path)</span>
<span class="ansi-green-intense-fg ansi-bold">    454</span> intervention_handler <span style="color: rgb(98,98,98)">=</span> InterventionHandler(
<span class="ansi-green-intense-fg ansi-bold">    455</span>     intervention_graph, batch_groups, batch_size
<span class="ansi-green-intense-fg ansi-bold">    456</span> )
<span class="ansi-green-intense-fg ansi-bold">    458</span> module_paths <span style="color: rgb(98,98,98)">=</span> InterventionProtocol<span style="color: rgb(98,98,98)">.</span>get_interventions(
<span class="ansi-green-intense-fg ansi-bold">    459</span>     intervention_graph
<span class="ansi-green-intense-fg ansi-bold">    460</span> )<span style="color: rgb(98,98,98)">.</span>keys()
<span class="ansi-green-intense-fg ansi-bold">    462</span> <span class="ansi-bold" style="color: rgb(0,135,0)">with</span> HookHandler(
<span class="ansi-green-intense-fg ansi-bold">    463</span>     <span style="color: rgb(0,135,0)">self</span><span style="color: rgb(98,98,98)">.</span>_model,
<span class="ansi-green-intense-fg ansi-bold">    464</span>     <span style="color: rgb(0,135,0)">list</span>(module_paths),
<span class="ansi-green-intense-fg ansi-bold">    465</span>     input_hook<span style="color: rgb(98,98,98)">=</span><span class="ansi-bold" style="color: rgb(0,135,0)">lambda</span> activations, module_path: InterventionProtocol<span style="color: rgb(98,98,98)">.</span>intervene(
<span class="ansi-green-intense-fg ansi-bold">    466</span>         activations, module_path, <span style="color: rgb(175,0,0)">&#34;</span><span style="color: rgb(175,0,0)">input</span><span style="color: rgb(175,0,0)">&#34;</span>, intervention_handler
<span class="ansi-green-intense-fg ansi-bold">    467</span>     ),
<span class="ansi-green-fg">--&gt; 468</span>     output_hook<span style="color: rgb(98,98,98)">=</span><span class="ansi-bold" style="color: rgb(0,135,0)">lambda</span> activations, module_path: <span class="ansi-yellow-bg">InterventionProtocol</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">.</span><span class="ansi-yellow-bg">intervene</span><span class="ansi-yellow-bg">(</span>
<span class="ansi-green-intense-fg ansi-bold">    469</span> <span class="ansi-yellow-bg">        </span><span class="ansi-yellow-bg">activations</span><span class="ansi-yellow-bg">,</span><span class="ansi-yellow-bg"> </span><span class="ansi-yellow-bg">module_path</span><span class="ansi-yellow-bg">,</span><span class="ansi-yellow-bg"> </span><span class="ansi-yellow-bg" style="color: rgb(175,0,0)">&#34;</span><span class="ansi-yellow-bg" style="color: rgb(175,0,0)">output</span><span class="ansi-yellow-bg" style="color: rgb(175,0,0)">&#34;</span><span class="ansi-yellow-bg">,</span><span class="ansi-yellow-bg"> </span><span class="ansi-yellow-bg">intervention_handler</span>
<span class="ansi-green-intense-fg ansi-bold">    470</span> <span class="ansi-yellow-bg">    </span><span class="ansi-yellow-bg">)</span>,
<span class="ansi-green-intense-fg ansi-bold">    471</span> ):
<span class="ansi-green-intense-fg ansi-bold">    472</span>     <span class="ansi-bold" style="color: rgb(0,135,0)">try</span>:
<span class="ansi-green-intense-fg ansi-bold">    473</span>         fn(<span style="color: rgb(98,98,98)">*</span>inputs, <span style="color: rgb(98,98,98)">*</span><span style="color: rgb(98,98,98)">*</span>kwargs)

File <span class="ansi-green-fg">~/Projects/NDIF/nnsight/src/nnsight/intervention.py:449</span>, in <span class="ansi-cyan-fg">InterventionProtocol.intervene</span><span class="ansi-blue-fg">(cls, activations, module_path, key, intervention_handler)</span>
<span class="ansi-green-intense-fg ansi-bold">    442</span>     value <span style="color: rgb(98,98,98)">=</span> util<span style="color: rgb(98,98,98)">.</span>apply(
<span class="ansi-green-intense-fg ansi-bold">    443</span>         activations,
<span class="ansi-green-intense-fg ansi-bold">    444</span>         narrow,
<span class="ansi-green-intense-fg ansi-bold">    445</span>         torch<span style="color: rgb(98,98,98)">.</span>Tensor,
<span class="ansi-green-intense-fg ansi-bold">    446</span>     )
<span class="ansi-green-intense-fg ansi-bold">    448</span> <span style="color: rgb(95,135,135)"># Value injection.</span>
<span class="ansi-green-fg">--&gt; 449</span> <span class="ansi-yellow-bg">node</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">.</span><span class="ansi-yellow-bg">set_value</span><span class="ansi-yellow-bg">(</span><span class="ansi-yellow-bg">value</span><span class="ansi-yellow-bg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    451</span> <span style="color: rgb(95,135,135)"># Check if through the previous value injection, there was a &#39;swap&#39; intervention.</span>
<span class="ansi-green-intense-fg ansi-bold">    452</span> <span style="color: rgb(95,135,135)"># This would mean we want to replace activations for this batch with some other ones.</span>
<span class="ansi-green-intense-fg ansi-bold">    453</span> value <span style="color: rgb(98,98,98)">=</span> protocols<span style="color: rgb(98,98,98)">.</span>SwapProtocol<span style="color: rgb(98,98,98)">.</span>get_swap(
<span class="ansi-green-intense-fg ansi-bold">    454</span>     intervention_handler<span style="color: rgb(98,98,98)">.</span>graph, value
<span class="ansi-green-intense-fg ansi-bold">    455</span> )

File <span class="ansi-green-fg">~/Projects/NDIF/nnsight/src/nnsight/tracing/Node.py:410</span>, in <span class="ansi-cyan-fg">Node.set_value</span><span class="ansi-blue-fg">(self, value)</span>
<span class="ansi-green-intense-fg ansi-bold">    407</span>     listener<span style="color: rgb(98,98,98)">.</span>remaining_dependencies <span style="color: rgb(98,98,98)">-</span><span style="color: rgb(98,98,98)">=</span> <span style="color: rgb(98,98,98)">1</span>
<span class="ansi-green-intense-fg ansi-bold">    409</span>     <span class="ansi-bold" style="color: rgb(0,135,0)">if</span> listener<span style="color: rgb(98,98,98)">.</span>fulfilled() <span class="ansi-bold" style="color: rgb(175,0,255)">and</span> <span class="ansi-bold" style="color: rgb(175,0,255)">not</span> <span style="color: rgb(0,135,0)">self</span><span style="color: rgb(98,98,98)">.</span>graph<span style="color: rgb(98,98,98)">.</span>sequential:
<span class="ansi-green-fg">--&gt; 410</span>         <span class="ansi-yellow-bg">listener</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">.</span><span class="ansi-yellow-bg">execute</span><span class="ansi-yellow-bg">(</span><span class="ansi-yellow-bg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    412</span> <span class="ansi-bold" style="color: rgb(0,135,0)">for</span> dependency <span class="ansi-bold" style="color: rgb(175,0,255)">in</span> <span style="color: rgb(0,135,0)">self</span><span style="color: rgb(98,98,98)">.</span>arg_dependencies:
<span class="ansi-green-intense-fg ansi-bold">    413</span>     dependency<span style="color: rgb(98,98,98)">.</span>remaining_listeners <span style="color: rgb(98,98,98)">-</span><span style="color: rgb(98,98,98)">=</span> <span style="color: rgb(98,98,98)">1</span>

File <span class="ansi-green-fg">~/Projects/NDIF/nnsight/src/nnsight/tracing/Node.py:387</span>, in <span class="ansi-cyan-fg">Node.execute</span><span class="ansi-blue-fg">(self)</span>
<span class="ansi-green-intense-fg ansi-bold">    383</span>         <span style="color: rgb(0,135,0)">self</span><span style="color: rgb(98,98,98)">.</span>set_value(output)
<span class="ansi-green-intense-fg ansi-bold">    385</span> <span class="ansi-bold" style="color: rgb(0,135,0)">except</span> <span class="ansi-bold" style="color: rgb(215,95,95)">Exception</span> <span class="ansi-bold" style="color: rgb(0,135,0)">as</span> e:
<span class="ansi-green-fg">--&gt; 387</span>     <span class="ansi-bold" style="color: rgb(0,135,0)">raise</span> <span style="color: rgb(0,135,0)">type</span>(e)(
<span class="ansi-green-intense-fg ansi-bold">    388</span>         <span style="color: rgb(175,0,0)">f</span><span style="color: rgb(175,0,0)">&#34;</span><span style="color: rgb(175,0,0)">Above exception when execution Node: </span><span style="color: rgb(175,0,0)">&#39;</span><span class="ansi-bold" style="color: rgb(175,95,135)">{</span><span style="color: rgb(0,135,0)">self</span><span style="color: rgb(98,98,98)">.</span>name<span class="ansi-bold" style="color: rgb(175,95,135)">}</span><span style="color: rgb(175,0,0)">&#39;</span><span style="color: rgb(175,0,0)"> in Graph: </span><span style="color: rgb(175,0,0)">&#39;</span><span class="ansi-bold" style="color: rgb(175,95,135)">{</span><span style="color: rgb(0,135,0)">self</span><span style="color: rgb(98,98,98)">.</span>graph<span style="color: rgb(98,98,98)">.</span>id<span class="ansi-bold" style="color: rgb(175,95,135)">}</span><span style="color: rgb(175,0,0)">&#39;</span><span style="color: rgb(175,0,0)">&#34;</span>
<span class="ansi-green-intense-fg ansi-bold">    389</span>     ) <span class="ansi-bold" style="color: rgb(0,135,0)">from</span> <span class="ansi-bold" style="color: rgb(0,0,255)">e</span>
<span class="ansi-green-intense-fg ansi-bold">    391</span> <span class="ansi-bold" style="color: rgb(0,135,0)">finally</span>:
<span class="ansi-green-intense-fg ansi-bold">    392</span>     <span style="color: rgb(0,135,0)">self</span><span style="color: rgb(98,98,98)">.</span>remaining_dependencies <span style="color: rgb(98,98,98)">-</span><span style="color: rgb(98,98,98)">=</span> <span style="color: rgb(98,98,98)">1</span>

<span class="ansi-red-fg">IndexError</span>: Above exception when execution Node: &#39;setitem_0&#39; in Graph: &#39;6063279136&#39;
</pre></div></div>
</div>
<p>Oh no, we are getting an error. Looks like it’s happening when we are setting the output.</p>
<p>How can we find what went wrong? Is there an easy way to debug this?</p>
<p>Enter “Scanning” and “Validating”! We can enable these features by setting the <code class="docutils literal notranslate"><span class="pre">scan=True</span></code> and <code class="docutils literal notranslate"><span class="pre">validate=True</span></code> flags in the <code class="docutils literal notranslate"><span class="pre">trace</span></code> method.</p>
<p>Let’s run this again and see what it can do for us:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[17]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># turn on scan and validate</span>
<span class="k">with</span> <span class="n">tiny_model</span><span class="o">.</span><span class="n">trace</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">scan</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">validate</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>

    <span class="n">l1_output_before</span> <span class="o">=</span> <span class="n">tiny_model</span><span class="o">.</span><span class="n">layer1</span><span class="o">.</span><span class="n">output</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span><span class="o">.</span><span class="n">save</span><span class="p">()</span>

    <span class="c1"># the error is happening here</span>
    <span class="n">tiny_model</span><span class="o">.</span><span class="n">layer1</span><span class="o">.</span><span class="n">output</span><span class="p">[:,</span> <span class="n">hidden_dims</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="n">l1_output_after</span> <span class="o">=</span> <span class="n">tiny_model</span><span class="o">.</span><span class="n">layer1</span><span class="o">.</span><span class="n">output</span><span class="o">.</span><span class="n">save</span><span class="p">()</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Before:&quot;</span><span class="p">,</span> <span class="n">l1_output_before</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;After:&quot;</span><span class="p">,</span> <span class="n">l1_output_after</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
<span class="ansi-red-fg">---------------------------------------------------------------------------</span>
<span class="ansi-red-fg">IndexError</span>                                Traceback (most recent call last)
Cell <span class="ansi-green-fg">In[17], line 2</span>
<span class="ansi-green-intense-fg ansi-bold">      1</span> <span style="color: rgb(95,135,135)"># turn on scan and validate</span>
<span class="ansi-green-fg">----&gt; 2</span> <span class="ansi-yellow-bg ansi-bold" style="color: rgb(0,135,0)">with</span><span class="ansi-yellow-bg"> </span><span class="ansi-yellow-bg">tiny_model</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">.</span><span class="ansi-yellow-bg">trace</span><span class="ansi-yellow-bg">(</span><span class="ansi-yellow-bg" style="color: rgb(0,135,0)">input</span><span class="ansi-yellow-bg">,</span><span class="ansi-yellow-bg"> </span><span class="ansi-yellow-bg">scan</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">=</span><span class="ansi-yellow-bg ansi-bold" style="color: rgb(0,135,0)">True</span><span class="ansi-yellow-bg">,</span><span class="ansi-yellow-bg"> </span><span class="ansi-yellow-bg">validate</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">=</span><span class="ansi-yellow-bg ansi-bold" style="color: rgb(0,135,0)">True</span><span class="ansi-yellow-bg">)</span><span class="ansi-yellow-bg">:</span>
<span class="ansi-green-intense-fg ansi-bold">      4</span> <span class="ansi-yellow-bg">    </span><span class="ansi-yellow-bg">l1_output_before</span><span class="ansi-yellow-bg"> </span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">=</span><span class="ansi-yellow-bg"> </span><span class="ansi-yellow-bg">tiny_model</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">.</span><span class="ansi-yellow-bg">layer1</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">.</span><span class="ansi-yellow-bg">output</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">.</span><span class="ansi-yellow-bg">clone</span><span class="ansi-yellow-bg">(</span><span class="ansi-yellow-bg">)</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">.</span><span class="ansi-yellow-bg">save</span><span class="ansi-yellow-bg">(</span><span class="ansi-yellow-bg">)</span>
<span class="ansi-green-intense-fg ansi-bold">      6</span> <span class="ansi-yellow-bg">    </span><span class="ansi-yellow-bg" style="color: rgb(95,135,135)"># the error is happening here</span>

File <span class="ansi-green-fg">~/Projects/NDIF/nnsight/src/nnsight/contexts/Tracer.py:103</span>, in <span class="ansi-cyan-fg">Tracer.__exit__</span><span class="ansi-blue-fg">(self, exc_type, exc_val, exc_tb)</span>
<span class="ansi-green-intense-fg ansi-bold">     98</span>     <span style="color: rgb(0,135,0)">self</span><span style="color: rgb(98,98,98)">.</span>invoker<span style="color: rgb(98,98,98)">.</span><span style="color: rgb(0,0,255)">__exit__</span>(<span class="ansi-bold" style="color: rgb(0,135,0)">None</span>, <span class="ansi-bold" style="color: rgb(0,135,0)">None</span>, <span class="ansi-bold" style="color: rgb(0,135,0)">None</span>)
<span class="ansi-green-intense-fg ansi-bold">    100</span> <span style="color: rgb(0,135,0)">self</span><span style="color: rgb(98,98,98)">.</span>model<span style="color: rgb(98,98,98)">.</span>_envoy<span style="color: rgb(98,98,98)">.</span>_reset()
<span class="ansi-green-fg">--&gt; 103</span> <span class="ansi-yellow-bg" style="color: rgb(0,135,0)">super</span><span class="ansi-yellow-bg">(</span><span class="ansi-yellow-bg">)</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">.</span><span class="ansi-yellow-bg" style="color: rgb(0,0,255)">__exit__</span><span class="ansi-yellow-bg">(</span><span class="ansi-yellow-bg">exc_type</span><span class="ansi-yellow-bg">,</span><span class="ansi-yellow-bg"> </span><span class="ansi-yellow-bg">exc_val</span><span class="ansi-yellow-bg">,</span><span class="ansi-yellow-bg"> </span><span class="ansi-yellow-bg">exc_tb</span><span class="ansi-yellow-bg">)</span>

File <span class="ansi-green-fg">~/Projects/NDIF/nnsight/src/nnsight/contexts/GraphBasedContext.py:216</span>, in <span class="ansi-cyan-fg">GraphBasedContext.__exit__</span><span class="ansi-blue-fg">(self, exc_type, exc_val, exc_tb)</span>
<span class="ansi-green-intense-fg ansi-bold">    214</span>     <span style="color: rgb(0,135,0)">self</span><span style="color: rgb(98,98,98)">.</span>graph<span style="color: rgb(98,98,98)">.</span>alive <span style="color: rgb(98,98,98)">=</span> <span class="ansi-bold" style="color: rgb(0,135,0)">False</span>
<span class="ansi-green-intense-fg ansi-bold">    215</span>     <span style="color: rgb(0,135,0)">self</span><span style="color: rgb(98,98,98)">.</span>graph <span style="color: rgb(98,98,98)">=</span> <span class="ansi-bold" style="color: rgb(0,135,0)">None</span>
<span class="ansi-green-fg">--&gt; 216</span>     <span class="ansi-bold" style="color: rgb(0,135,0)">raise</span> exc_val
<span class="ansi-green-intense-fg ansi-bold">    218</span> <span style="color: rgb(0,135,0)">self</span><span style="color: rgb(98,98,98)">.</span>backend(<span style="color: rgb(0,135,0)">self</span>)

Cell <span class="ansi-green-fg">In[17], line 7</span>
<span class="ansi-green-intense-fg ansi-bold">      4</span>     l1_output_before <span style="color: rgb(98,98,98)">=</span> tiny_model<span style="color: rgb(98,98,98)">.</span>layer1<span style="color: rgb(98,98,98)">.</span>output<span style="color: rgb(98,98,98)">.</span>clone()<span style="color: rgb(98,98,98)">.</span>save()
<span class="ansi-green-intense-fg ansi-bold">      6</span>     <span style="color: rgb(95,135,135)"># the error is happening here</span>
<span class="ansi-green-fg">----&gt; 7</span>     <span class="ansi-yellow-bg">tiny_model</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">.</span><span class="ansi-yellow-bg">layer1</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">.</span><span class="ansi-yellow-bg">output</span><span class="ansi-yellow-bg">[</span><span class="ansi-yellow-bg">:</span><span class="ansi-yellow-bg">,</span><span class="ansi-yellow-bg"> </span><span class="ansi-yellow-bg">hidden_dims</span><span class="ansi-yellow-bg">]</span> <span style="color: rgb(98,98,98)">=</span> <span style="color: rgb(98,98,98)">0</span>
<span class="ansi-green-intense-fg ansi-bold">      9</span>     l1_output_after <span style="color: rgb(98,98,98)">=</span> tiny_model<span style="color: rgb(98,98,98)">.</span>layer1<span style="color: rgb(98,98,98)">.</span>output<span style="color: rgb(98,98,98)">.</span>save()
<span class="ansi-green-intense-fg ansi-bold">     11</span> <span style="color: rgb(0,135,0)">print</span>(<span style="color: rgb(175,0,0)">&#34;</span><span style="color: rgb(175,0,0)">Before:</span><span style="color: rgb(175,0,0)">&#34;</span>, l1_output_before)

File <span class="ansi-green-fg">~/Projects/NDIF/nnsight/src/nnsight/tracing/Proxy.py:89</span>, in <span class="ansi-cyan-fg">Proxy.__setitem__</span><span class="ansi-blue-fg">(self, key, value)</span>
<span class="ansi-green-intense-fg ansi-bold">     88</span> <span class="ansi-bold" style="color: rgb(0,135,0)">def</span> <span style="color: rgb(0,0,255)">__setitem__</span>(<span style="color: rgb(0,135,0)">self</span>, key: Union[Proxy, Any], value: Union[Self, Any]) <span style="color: rgb(98,98,98)">-</span><span style="color: rgb(98,98,98)">&gt;</span> <span class="ansi-bold" style="color: rgb(0,135,0)">None</span>:
<span class="ansi-green-fg">---&gt; 89</span>     <span class="ansi-yellow-bg" style="color: rgb(0,135,0)">self</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">.</span><span class="ansi-yellow-bg">node</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">.</span><span class="ansi-yellow-bg">create</span><span class="ansi-yellow-bg">(</span>
<span class="ansi-green-intense-fg ansi-bold">     90</span> <span class="ansi-yellow-bg">        </span><span class="ansi-yellow-bg">target</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">=</span><span class="ansi-yellow-bg">operator</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">.</span><span class="ansi-yellow-bg">setitem</span><span class="ansi-yellow-bg">,</span>
<span class="ansi-green-intense-fg ansi-bold">     91</span> <span class="ansi-yellow-bg">        </span><span class="ansi-yellow-bg">args</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">=</span><span class="ansi-yellow-bg">[</span><span class="ansi-yellow-bg" style="color: rgb(0,135,0)">self</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">.</span><span class="ansi-yellow-bg">node</span><span class="ansi-yellow-bg">,</span><span class="ansi-yellow-bg"> </span><span class="ansi-yellow-bg">key</span><span class="ansi-yellow-bg">,</span><span class="ansi-yellow-bg"> </span><span class="ansi-yellow-bg">value</span><span class="ansi-yellow-bg">]</span><span class="ansi-yellow-bg">,</span>
<span class="ansi-green-intense-fg ansi-bold">     92</span> <span class="ansi-yellow-bg">    </span><span class="ansi-yellow-bg">)</span>

File <span class="ansi-green-fg">~/Projects/NDIF/nnsight/src/nnsight/tracing/Node.py:270</span>, in <span class="ansi-cyan-fg">Node.create</span><span class="ansi-blue-fg">(self, target, proxy_value, args, kwargs, name)</span>
<span class="ansi-green-intense-fg ansi-bold">    267</span>     <span class="ansi-bold" style="color: rgb(0,135,0)">return</span> value
<span class="ansi-green-intense-fg ansi-bold">    269</span> <span style="color: rgb(95,135,135)"># Otherwise just create the Node on the Graph like normal.</span>
<span class="ansi-green-fg">--&gt; 270</span> <span class="ansi-bold" style="color: rgb(0,135,0)">return</span> <span class="ansi-yellow-bg" style="color: rgb(0,135,0)">self</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">.</span><span class="ansi-yellow-bg">graph</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">.</span><span class="ansi-yellow-bg">create</span><span class="ansi-yellow-bg">(</span>
<span class="ansi-green-intense-fg ansi-bold">    271</span> <span class="ansi-yellow-bg">    </span><span class="ansi-yellow-bg">target</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">=</span><span class="ansi-yellow-bg">target</span><span class="ansi-yellow-bg">,</span>
<span class="ansi-green-intense-fg ansi-bold">    272</span> <span class="ansi-yellow-bg">    </span><span class="ansi-yellow-bg">name</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">=</span><span class="ansi-yellow-bg">name</span><span class="ansi-yellow-bg">,</span>
<span class="ansi-green-intense-fg ansi-bold">    273</span> <span class="ansi-yellow-bg">    </span><span class="ansi-yellow-bg">proxy_value</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">=</span><span class="ansi-yellow-bg">proxy_value</span><span class="ansi-yellow-bg">,</span>
<span class="ansi-green-intense-fg ansi-bold">    274</span> <span class="ansi-yellow-bg">    </span><span class="ansi-yellow-bg">args</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">=</span><span class="ansi-yellow-bg">args</span><span class="ansi-yellow-bg">,</span>
<span class="ansi-green-intense-fg ansi-bold">    275</span> <span class="ansi-yellow-bg">    </span><span class="ansi-yellow-bg">kwargs</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">=</span><span class="ansi-yellow-bg">kwargs</span><span class="ansi-yellow-bg">,</span>
<span class="ansi-green-intense-fg ansi-bold">    276</span> <span class="ansi-yellow-bg">)</span>

File <span class="ansi-green-fg">~/Projects/NDIF/nnsight/src/nnsight/tracing/Graph.py:113</span>, in <span class="ansi-cyan-fg">Graph.create</span><span class="ansi-blue-fg">(self, *args, **kwargs)</span>
<span class="ansi-green-intense-fg ansi-bold">    106</span> <span class="ansi-bold" style="color: rgb(0,135,0)">def</span> <span style="color: rgb(0,0,255)">create</span>(<span style="color: rgb(0,135,0)">self</span>, <span style="color: rgb(98,98,98)">*</span>args, <span style="color: rgb(98,98,98)">*</span><span style="color: rgb(98,98,98)">*</span>kwargs) <span style="color: rgb(98,98,98)">-</span><span style="color: rgb(98,98,98)">&gt;</span> Proxy:
<span class="ansi-green-intense-fg ansi-bold">    107</span> <span style="color: rgb(188,188,188)">    </span><span style="color: rgb(175,0,0)">&#34;&#34;&#34;Creates a Node directly on this `Graph` and returns its `Proxy`.</span>
<span class="ansi-green-intense-fg ansi-bold">    108</span>
<span class="ansi-green-intense-fg ansi-bold">    109</span> <span style="color: rgb(175,0,0)">    Returns:</span>
<span class="ansi-green-intense-fg ansi-bold">    110</span> <span style="color: rgb(175,0,0)">        Proxy: `Proxy` for newly created `Node`.</span>
<span class="ansi-green-intense-fg ansi-bold">    111</span> <span style="color: rgb(175,0,0)">    &#34;&#34;&#34;</span>
<span class="ansi-green-fg">--&gt; 113</span>     <span class="ansi-bold" style="color: rgb(0,135,0)">return</span> <span style="color: rgb(0,135,0)">self</span><span style="color: rgb(98,98,98)">.</span>proxy_class(<span class="ansi-yellow-bg">Node</span><span class="ansi-yellow-bg">(</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">*</span><span class="ansi-yellow-bg">args</span><span class="ansi-yellow-bg">,</span><span class="ansi-yellow-bg"> </span><span class="ansi-yellow-bg">graph</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">=</span><span class="ansi-yellow-bg" style="color: rgb(0,135,0)">self</span><span class="ansi-yellow-bg">,</span><span class="ansi-yellow-bg"> </span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">*</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">*</span><span class="ansi-yellow-bg">kwargs</span><span class="ansi-yellow-bg">)</span>)

File <span class="ansi-green-fg">~/Projects/NDIF/nnsight/src/nnsight/tracing/Node.py:96</span>, in <span class="ansi-cyan-fg">Node.__init__</span><span class="ansi-blue-fg">(self, target, graph, proxy_value, args, kwargs, name)</span>
<span class="ansi-green-intense-fg ansi-bold">     93</span> <span style="color: rgb(95,135,135)"># If theres an alive Graph, add it.</span>
<span class="ansi-green-intense-fg ansi-bold">     94</span> <span class="ansi-bold" style="color: rgb(0,135,0)">if</span> <span style="color: rgb(0,135,0)">self</span><span style="color: rgb(98,98,98)">.</span>attached():
<span class="ansi-green-fg">---&gt; 96</span>     <span class="ansi-yellow-bg" style="color: rgb(0,135,0)">self</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">.</span><span class="ansi-yellow-bg">graph</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">.</span><span class="ansi-yellow-bg">add</span><span class="ansi-yellow-bg">(</span><span class="ansi-yellow-bg" style="color: rgb(0,135,0)">self</span><span class="ansi-yellow-bg">)</span>

File <span class="ansi-green-fg">~/Projects/NDIF/nnsight/src/nnsight/tracing/Graph.py:131</span>, in <span class="ansi-cyan-fg">Graph.add</span><span class="ansi-blue-fg">(self, node)</span>
<span class="ansi-green-intense-fg ansi-bold">    128</span> <span style="color: rgb(95,135,135)"># If we&#39;re validating and the user did not provide a proxy_value, execute the given target with meta proxy values to compute new proxy_value.</span>
<span class="ansi-green-intense-fg ansi-bold">    129</span> <span class="ansi-bold" style="color: rgb(0,135,0)">if</span> <span style="color: rgb(0,135,0)">self</span><span style="color: rgb(98,98,98)">.</span>validate <span class="ansi-bold" style="color: rgb(175,0,255)">and</span> node<span style="color: rgb(98,98,98)">.</span>proxy_value <span class="ansi-bold" style="color: rgb(175,0,255)">is</span> inspect<span style="color: rgb(98,98,98)">.</span>_empty:
<span class="ansi-green-fg">--&gt; 131</span>     node<span style="color: rgb(98,98,98)">.</span>proxy_value <span style="color: rgb(98,98,98)">=</span> <span class="ansi-yellow-bg">validate</span><span class="ansi-yellow-bg">(</span><span class="ansi-yellow-bg">node</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">.</span><span class="ansi-yellow-bg">target</span><span class="ansi-yellow-bg">,</span><span class="ansi-yellow-bg"> </span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">*</span><span class="ansi-yellow-bg">node</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">.</span><span class="ansi-yellow-bg">args</span><span class="ansi-yellow-bg">,</span><span class="ansi-yellow-bg"> </span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">*</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">*</span><span class="ansi-yellow-bg">node</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">.</span><span class="ansi-yellow-bg">kwargs</span><span class="ansi-yellow-bg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    133</span> <span style="color: rgb(95,135,135)"># Get name of target.</span>
<span class="ansi-green-intense-fg ansi-bold">    134</span> name <span style="color: rgb(98,98,98)">=</span> (
<span class="ansi-green-intense-fg ansi-bold">    135</span>     node<span style="color: rgb(98,98,98)">.</span>target
<span class="ansi-green-intense-fg ansi-bold">    136</span>     <span class="ansi-bold" style="color: rgb(0,135,0)">if</span> <span style="color: rgb(0,135,0)">isinstance</span>(node<span style="color: rgb(98,98,98)">.</span>target, <span style="color: rgb(0,135,0)">str</span>)
<span class="ansi-green-intense-fg ansi-bold">    137</span>     <span class="ansi-bold" style="color: rgb(0,135,0)">else</span> node<span style="color: rgb(98,98,98)">.</span>target<span style="color: rgb(98,98,98)">.</span><span style="color: rgb(0,0,135)">__name__</span>
<span class="ansi-green-intense-fg ansi-bold">    138</span> )

File <span class="ansi-green-fg">~/Projects/NDIF/nnsight/src/nnsight/tracing/util.py:20</span>, in <span class="ansi-cyan-fg">validate</span><span class="ansi-blue-fg">(target, *args, **kwargs)</span>
<span class="ansi-green-intense-fg ansi-bold">     14</span> <span class="ansi-bold" style="color: rgb(0,135,0)">with</span> FakeTensorMode(
<span class="ansi-green-intense-fg ansi-bold">     15</span>     allow_non_fake_inputs<span style="color: rgb(98,98,98)">=</span><span class="ansi-bold" style="color: rgb(0,135,0)">True</span>,
<span class="ansi-green-intense-fg ansi-bold">     16</span>     shape_env<span style="color: rgb(98,98,98)">=</span>ShapeEnv(assume_static_by_default<span style="color: rgb(98,98,98)">=</span><span class="ansi-bold" style="color: rgb(0,135,0)">True</span>),
<span class="ansi-green-intense-fg ansi-bold">     17</span> ) <span class="ansi-bold" style="color: rgb(0,135,0)">as</span> fake_mode:
<span class="ansi-green-intense-fg ansi-bold">     18</span>     <span class="ansi-bold" style="color: rgb(0,135,0)">with</span> FakeCopyMode(fake_mode):
<span class="ansi-green-fg">---&gt; 20</span> <span class="ansi-yellow-bg">        </span><span class="ansi-yellow-bg ansi-bold" style="color: rgb(0,135,0)">with</span><span class="ansi-yellow-bg"> </span><span class="ansi-yellow-bg">GlobalTracingContext</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">.</span><span class="ansi-yellow-bg">exit_global_tracing_context</span><span class="ansi-yellow-bg">(</span><span class="ansi-yellow-bg">)</span><span class="ansi-yellow-bg">:</span>
<span class="ansi-green-intense-fg ansi-bold">     22</span> <span class="ansi-yellow-bg">            </span><span class="ansi-yellow-bg">args</span><span class="ansi-yellow-bg">,</span><span class="ansi-yellow-bg"> </span><span class="ansi-yellow-bg">kwargs</span><span class="ansi-yellow-bg"> </span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">=</span><span class="ansi-yellow-bg"> </span><span class="ansi-yellow-bg">Node</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">.</span><span class="ansi-yellow-bg">prepare_inputs</span><span class="ansi-yellow-bg">(</span><span class="ansi-yellow-bg">(</span><span class="ansi-yellow-bg">args</span><span class="ansi-yellow-bg">,</span><span class="ansi-yellow-bg"> </span><span class="ansi-yellow-bg">kwargs</span><span class="ansi-yellow-bg">)</span><span class="ansi-yellow-bg">,</span><span class="ansi-yellow-bg"> </span><span class="ansi-yellow-bg">proxy</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">=</span><span class="ansi-yellow-bg ansi-bold" style="color: rgb(0,135,0)">True</span><span class="ansi-yellow-bg">)</span>
<span class="ansi-green-intense-fg ansi-bold">     24</span> <span class="ansi-yellow-bg">            </span><span class="ansi-yellow-bg ansi-bold" style="color: rgb(0,135,0)">return</span><span class="ansi-yellow-bg"> </span><span class="ansi-yellow-bg">target</span><span class="ansi-yellow-bg">(</span>
<span class="ansi-green-intense-fg ansi-bold">     25</span> <span class="ansi-yellow-bg">                </span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">*</span><span class="ansi-yellow-bg">args</span><span class="ansi-yellow-bg">,</span>
<span class="ansi-green-intense-fg ansi-bold">     26</span> <span class="ansi-yellow-bg">                </span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">*</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">*</span><span class="ansi-yellow-bg">kwargs</span><span class="ansi-yellow-bg">,</span>
<span class="ansi-green-intense-fg ansi-bold">     27</span> <span class="ansi-yellow-bg">            </span><span class="ansi-yellow-bg">)</span>

File <span class="ansi-green-fg">~/Projects/NDIF/nnsight/src/nnsight/contexts/GraphBasedContext.py:330</span>, in <span class="ansi-cyan-fg">GlobalTracingContext.GlobalTracingExit.__exit__</span><span class="ansi-blue-fg">(self, exc_type, exc_val, traceback)</span>
<span class="ansi-green-intense-fg ansi-bold">    326</span> GlobalTracingContext<span style="color: rgb(98,98,98)">.</span>PATCHER<span style="color: rgb(98,98,98)">.</span><span style="color: rgb(0,0,255)">__enter__</span>()
<span class="ansi-green-intense-fg ansi-bold">    328</span> <span class="ansi-bold" style="color: rgb(0,135,0)">if</span> <span style="color: rgb(0,135,0)">isinstance</span>(exc_val, <span class="ansi-bold" style="color: rgb(215,95,95)">BaseException</span>):
<span class="ansi-green-fg">--&gt; 330</span>     <span class="ansi-bold" style="color: rgb(0,135,0)">raise</span> exc_val

File <span class="ansi-green-fg">~/Projects/NDIF/nnsight/src/nnsight/tracing/util.py:24</span>, in <span class="ansi-cyan-fg">validate</span><span class="ansi-blue-fg">(target, *args, **kwargs)</span>
<span class="ansi-green-intense-fg ansi-bold">     20</span> <span class="ansi-bold" style="color: rgb(0,135,0)">with</span> GlobalTracingContext<span style="color: rgb(98,98,98)">.</span>exit_global_tracing_context():
<span class="ansi-green-intense-fg ansi-bold">     22</span>     args, kwargs <span style="color: rgb(98,98,98)">=</span> Node<span style="color: rgb(98,98,98)">.</span>prepare_inputs((args, kwargs), proxy<span style="color: rgb(98,98,98)">=</span><span class="ansi-bold" style="color: rgb(0,135,0)">True</span>)
<span class="ansi-green-fg">---&gt; 24</span>     <span class="ansi-bold" style="color: rgb(0,135,0)">return</span> <span class="ansi-yellow-bg">target</span><span class="ansi-yellow-bg">(</span>
<span class="ansi-green-intense-fg ansi-bold">     25</span> <span class="ansi-yellow-bg">        </span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">*</span><span class="ansi-yellow-bg">args</span><span class="ansi-yellow-bg">,</span>
<span class="ansi-green-intense-fg ansi-bold">     26</span> <span class="ansi-yellow-bg">        </span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">*</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">*</span><span class="ansi-yellow-bg">kwargs</span><span class="ansi-yellow-bg">,</span>
<span class="ansi-green-intense-fg ansi-bold">     27</span> <span class="ansi-yellow-bg">    </span><span class="ansi-yellow-bg">)</span>

File <span class="ansi-green-fg">~/Projects/NDIF/nnsight/src/nnsight/contexts/GraphBasedContext.py:312</span>, in <span class="ansi-cyan-fg">GlobalTracingContext.GlobalTracingTorchHandler.__torch_function__</span><span class="ansi-blue-fg">(self, func, types, args, kwargs)</span>
<span class="ansi-green-intense-fg ansi-bold">    305</span> <span class="ansi-bold" style="color: rgb(0,135,0)">if</span> <span style="color: rgb(175,0,0)">&#34;</span><span style="color: rgb(175,0,0)">_VariableFunctionsClass</span><span style="color: rgb(175,0,0)">&#34;</span> <span class="ansi-bold" style="color: rgb(175,0,255)">in</span> func<span style="color: rgb(98,98,98)">.</span><span style="color: rgb(0,0,135)">__qualname__</span>:
<span class="ansi-green-intense-fg ansi-bold">    306</span>     <span class="ansi-bold" style="color: rgb(0,135,0)">return</span> GlobalTracingContext<span style="color: rgb(98,98,98)">.</span>GLOBAL_TRACING_CONTEXT<span style="color: rgb(98,98,98)">.</span>apply(
<span class="ansi-green-intense-fg ansi-bold">    307</span>         func,
<span class="ansi-green-intense-fg ansi-bold">    308</span>         <span style="color: rgb(98,98,98)">*</span>args,
<span class="ansi-green-intense-fg ansi-bold">    309</span>         <span style="color: rgb(98,98,98)">*</span><span style="color: rgb(98,98,98)">*</span>kwargs
<span class="ansi-green-intense-fg ansi-bold">    310</span>     )
<span class="ansi-green-fg">--&gt; 312</span> <span class="ansi-bold" style="color: rgb(0,135,0)">return</span> <span class="ansi-yellow-bg">func</span><span class="ansi-yellow-bg">(</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">*</span><span class="ansi-yellow-bg">args</span><span class="ansi-yellow-bg">,</span><span class="ansi-yellow-bg"> </span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">*</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">*</span><span class="ansi-yellow-bg">kwargs</span><span class="ansi-yellow-bg">)</span>

<span class="ansi-red-fg">IndexError</span>: index 10 is out of bounds for dimension 1 with size 10
</pre></div></div>
</div>
<p>Ah of course, we needed to index at <code class="docutils literal notranslate"><span class="pre">hidden_dims</span> <span class="pre">-</span> <span class="pre">1</span></code> not <code class="docutils literal notranslate"><span class="pre">hidden_dims</span></code>.</p>
<p>How was <code class="docutils literal notranslate"><span class="pre">nnsight</span></code> able to catch this error?</p>
<p>Earlier when discussing contexts in Python, we learned some logic happens upon entering, and some logic happens upon exiting. We know the model is actually run on exit, but what happens on enter?</p>
<p>If <code class="docutils literal notranslate"><span class="pre">scan</span></code> and <code class="docutils literal notranslate"><span class="pre">validate</span></code> are enabled, our input is run though the model, but under its own “fake” context. This means the input makes its way through all of the model operations, allowing <code class="docutils literal notranslate"><span class="pre">nnsight</span></code> to record the shapes and data types of module inputs and outputs! The operations are never executed using tensors with real values so it doesn’t incur any memory costs. Then, when creating proxy requests like the setting one above, <code class="docutils literal notranslate"><span class="pre">nnsight</span></code> also attempts to execute the request on the “fake”
values we recorded. Hence, it lets us know if our request is feasible before even running the model.</p>
<p>“Scanning” is what we call running “fake” inputs throught the model to collect information like shapes and types. “Validating” is what we call trying to execute the intervention proxies with “fake” inputs to see if they work. “Validating” is dependent on “Scanning” to work correctly, so we need to run the scan of the model at least once to debug with validate.</p>
<details><summary><p>A word of caution</p>
</summary><hr class="docutils" />
<p>Some pytorch operations and related libraries don’t work well with fake tensors</p>
<p>If you are doing anything in a loop where efficiency is important, you should keep scanning and validating off. It’s best to use them only when debugging or when you are unsure if your intervention will work.</p>
<hr class="docutils" />
</details><p>Let’s try again with the correct indexing, and view the shape of the output before leaving the tracing context:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[18]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">tiny_model</span><span class="o">.</span><span class="n">trace</span><span class="p">(</span><span class="nb">input</span><span class="p">):</span>

    <span class="c1"># Save the output before the edit to compare.</span>
    <span class="c1"># Notice we apply .clone() before saving as the setting operation is in-place.</span>
    <span class="n">l1_output_before</span> <span class="o">=</span> <span class="n">tiny_model</span><span class="o">.</span><span class="n">layer1</span><span class="o">.</span><span class="n">output</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span><span class="o">.</span><span class="n">save</span><span class="p">()</span>

    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Layer 1 output shape: </span><span class="si">{</span><span class="n">tiny_model</span><span class="o">.</span><span class="n">layer1</span><span class="o">.</span><span class="n">output</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="c1"># Access the last index of the hidden state dimension and set it to 0.</span>
    <span class="n">tiny_model</span><span class="o">.</span><span class="n">layer1</span><span class="o">.</span><span class="n">output</span><span class="p">[:,</span> <span class="n">hidden_dims</span> <span class="o">-</span> <span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="c1"># Save the output after to see our edit.</span>
    <span class="n">l1_output_after</span> <span class="o">=</span> <span class="n">tiny_model</span><span class="o">.</span><span class="n">layer1</span><span class="o">.</span><span class="n">output</span><span class="o">.</span><span class="n">save</span><span class="p">()</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Before:&quot;</span><span class="p">,</span> <span class="n">l1_output_before</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;After:&quot;</span><span class="p">,</span> <span class="n">l1_output_after</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Layer 1 output shape: torch.Size([1, 10])
Before: tensor([[ 0.2341,  0.3416, -0.8637, -0.5382, -0.3792, -0.1253,  0.4137,  0.5758,
         -0.3158, -0.1226]])
After: tensor([[ 0.2341,  0.3416, -0.8637, -0.5382, -0.3792, -0.1253,  0.4137,  0.5758,
         -0.3158,  0.0000]])
</pre></div></div>
</div>
<p>We can also just replace proxy inputs and outputs with tensors of the same shape and type. Let’s use the shape information we have at our disposal to add noise to the output, and replace it with this new noised tensor:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[19]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">tiny_model</span><span class="o">.</span><span class="n">trace</span><span class="p">(</span><span class="nb">input</span><span class="p">):</span>

    <span class="c1"># Save the output before the edit to compare.</span>
    <span class="c1"># Notice we apply .clone() before saving as the setting operation is in-place.</span>
    <span class="n">l1_output_before</span> <span class="o">=</span> <span class="n">tiny_model</span><span class="o">.</span><span class="n">layer1</span><span class="o">.</span><span class="n">output</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span><span class="o">.</span><span class="n">save</span><span class="p">()</span>

    <span class="c1"># Create random noise with variance of .001</span>
    <span class="n">noise</span> <span class="o">=</span> <span class="p">(</span><span class="mf">0.001</span><span class="o">**</span><span class="mf">0.5</span><span class="p">)</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">l1_output_before</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

    <span class="c1"># Add to original value and replace.</span>
    <span class="n">tiny_model</span><span class="o">.</span><span class="n">layer1</span><span class="o">.</span><span class="n">output</span> <span class="o">=</span> <span class="n">l1_output_before</span> <span class="o">+</span> <span class="n">noise</span>

    <span class="c1"># Save the output after to see our edit.</span>
    <span class="n">l1_output_after</span> <span class="o">=</span> <span class="n">tiny_model</span><span class="o">.</span><span class="n">layer1</span><span class="o">.</span><span class="n">output</span><span class="o">.</span><span class="n">save</span><span class="p">()</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Before:&quot;</span><span class="p">,</span> <span class="n">l1_output_before</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;After:&quot;</span><span class="p">,</span> <span class="n">l1_output_after</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Before: tensor([[ 0.2341,  0.3416, -0.8637, -0.5382, -0.3792, -0.1253,  0.4137,  0.5758,
         -0.3158, -0.1226]])
After: tensor([[ 0.2283,  0.3262, -0.8443, -0.5498, -0.3424, -0.1178,  0.4780,  0.5522,
         -0.2394, -0.1264]])
</pre></div></div>
</div>
<p>There is also another way to check the shape of the input and outputs of model’s modules. We can run <code class="docutils literal notranslate"><span class="pre">.scan</span></code> manually to get the module’s dimensions before running the model.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[20]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">tiny_model</span><span class="o">.</span><span class="n">scan</span><span class="p">(</span><span class="nb">input</span><span class="p">):</span>

    <span class="n">dim</span> <span class="o">=</span> <span class="n">tiny_model</span><span class="o">.</span><span class="n">layer1</span><span class="o">.</span><span class="n">output</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>

<span class="nb">print</span><span class="p">(</span><span class="n">dim</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
10
</pre></div></div>
</div>
</section>
<section id="Gradients">
<h2>Gradients<a class="headerlink" href="#Gradients" title="Link to this heading">#</a></h2>
<p><code class="docutils literal notranslate"><span class="pre">NNsight</span></code> also lets us apply backpropagation and access gradients with respect to a loss. Like <code class="docutils literal notranslate"><span class="pre">.input</span></code> and <code class="docutils literal notranslate"><span class="pre">.output</span></code> on modules, <code class="docutils literal notranslate"><span class="pre">nnsight</span></code> exposes <code class="docutils literal notranslate"><span class="pre">.grad</span></code> on Proxies themselves (assuming they are proxies of tensors):</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[21]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">tiny_model</span><span class="o">.</span><span class="n">trace</span><span class="p">(</span><span class="nb">input</span><span class="p">):</span>

    <span class="c1"># We need to explicitly have the tensor require grad</span>
    <span class="c1"># as the model we defined earlier turned off requiring grad.</span>
    <span class="n">tiny_model</span><span class="o">.</span><span class="n">layer1</span><span class="o">.</span><span class="n">output</span><span class="o">.</span><span class="n">requires_grad</span> <span class="o">=</span> <span class="kc">True</span>

    <span class="c1"># We call .grad on a tensor Proxy to communicate we want to store its gradient.</span>
    <span class="c1"># We need to call .save() since .grad is its own Proxy.</span>
    <span class="n">layer1_output_grad</span> <span class="o">=</span> <span class="n">tiny_model</span><span class="o">.</span><span class="n">layer1</span><span class="o">.</span><span class="n">output</span><span class="o">.</span><span class="n">grad</span><span class="o">.</span><span class="n">save</span><span class="p">()</span>
    <span class="n">layer2_output_grad</span> <span class="o">=</span> <span class="n">tiny_model</span><span class="o">.</span><span class="n">layer2</span><span class="o">.</span><span class="n">output</span><span class="o">.</span><span class="n">grad</span><span class="o">.</span><span class="n">save</span><span class="p">()</span>

    <span class="c1"># Need a loss to propagate through the later modules in order to have a grad.</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">tiny_model</span><span class="o">.</span><span class="n">output</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
    <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Layer 1 output gradient:&quot;</span><span class="p">,</span> <span class="n">layer1_output_grad</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Layer 2 output gradient:&quot;</span><span class="p">,</span> <span class="n">layer2_output_grad</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Layer 1 output gradient: tensor([[-0.2777, -0.1917,  0.1359,  0.2426,  0.1477, -0.0748,  0.0050, -0.1204,
          0.1260,  0.2847]])
Layer 2 output gradient: tensor([[1., 1.]])
</pre></div></div>
</div>
<p>All of the features we learned previously, also apply to <code class="docutils literal notranslate"><span class="pre">.grad</span></code>. In other words, we can apply operations to and edit the gradients. Let’s zero the grad of <code class="docutils literal notranslate"><span class="pre">layer1</span></code> and double the grad of <code class="docutils literal notranslate"><span class="pre">layer2</span></code>.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[22]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">tiny_model</span><span class="o">.</span><span class="n">trace</span><span class="p">(</span><span class="nb">input</span><span class="p">):</span>

    <span class="c1"># We need to explicitly have the tensor require grad</span>
    <span class="c1"># as the model we defined earlier turned off requiring grad.</span>
    <span class="n">tiny_model</span><span class="o">.</span><span class="n">layer1</span><span class="o">.</span><span class="n">output</span><span class="o">.</span><span class="n">requires_grad</span> <span class="o">=</span> <span class="kc">True</span>

    <span class="n">tiny_model</span><span class="o">.</span><span class="n">layer1</span><span class="o">.</span><span class="n">output</span><span class="o">.</span><span class="n">grad</span><span class="p">[:]</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">tiny_model</span><span class="o">.</span><span class="n">layer2</span><span class="o">.</span><span class="n">output</span><span class="o">.</span><span class="n">grad</span> <span class="o">=</span> <span class="n">tiny_model</span><span class="o">.</span><span class="n">layer2</span><span class="o">.</span><span class="n">output</span><span class="o">.</span><span class="n">grad</span> <span class="o">*</span> <span class="mi">2</span>

    <span class="n">layer1_output_grad</span> <span class="o">=</span> <span class="n">tiny_model</span><span class="o">.</span><span class="n">layer1</span><span class="o">.</span><span class="n">output</span><span class="o">.</span><span class="n">grad</span><span class="o">.</span><span class="n">save</span><span class="p">()</span>
    <span class="n">layer2_output_grad</span> <span class="o">=</span> <span class="n">tiny_model</span><span class="o">.</span><span class="n">layer2</span><span class="o">.</span><span class="n">output</span><span class="o">.</span><span class="n">grad</span><span class="o">.</span><span class="n">save</span><span class="p">()</span>

    <span class="c1"># Need a loss to propagate through the later modules in order to have a grad.</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">tiny_model</span><span class="o">.</span><span class="n">output</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
    <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Layer 1 output gradient:&quot;</span><span class="p">,</span> <span class="n">layer1_output_grad</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Layer 2 output gradient:&quot;</span><span class="p">,</span> <span class="n">layer2_output_grad</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Layer 1 output gradient: tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])
Layer 2 output gradient: tensor([[2., 2.]])
</pre></div></div>
</div>
</section>
<section id="Early-Stopping">
<h2>Early Stopping<a class="headerlink" href="#Early-Stopping" title="Link to this heading">#</a></h2>
<p>If we are only interested in a model’s intermediate computations, we can halt a forward pass run at any module level, reducing runtime and conserving compute resources. One example where this could be particularly useful is working with SAEs - we could train an SAE on one layer and then stop model execution.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[23]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">tiny_model</span><span class="o">.</span><span class="n">trace</span><span class="p">(</span><span class="nb">input</span><span class="p">):</span>
   <span class="n">l1_out</span> <span class="o">=</span> <span class="n">tiny_model</span><span class="o">.</span><span class="n">layer1</span><span class="o">.</span><span class="n">output</span><span class="o">.</span><span class="n">save</span><span class="p">()</span>
   <span class="n">tiny_model</span><span class="o">.</span><span class="n">layer1</span><span class="o">.</span><span class="n">output</span><span class="o">.</span><span class="n">stop</span><span class="p">()</span>

<span class="c1"># get the output of the first layer and stop tracing</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;L1 - Output: &quot;</span><span class="p">,</span> <span class="n">l1_out</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
L1 - Output:  tensor([[ 0.2341,  0.3416, -0.8637, -0.5382, -0.3792, -0.1253,  0.4137,  0.5758,
         -0.3158, -0.1226]])
</pre></div></div>
</div>
<p>Interventions within the tracing context do not necessarily execute in the order they are defined. Instead, their execution is tied to the module they are associated with.</p>
<p>As a result, if the forward pass is terminated early any interventions linked to modules beyond that point will be skipped, even if they were defined earlier in the context.</p>
<p>In the example below, the output of layer 2 <strong>cannot</strong> be accessed since the model’s execution was stopped at layer 1.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[24]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">tiny_model</span><span class="o">.</span><span class="n">trace</span><span class="p">(</span><span class="nb">input</span><span class="p">):</span>
   <span class="n">l2_out</span> <span class="o">=</span> <span class="n">tiny_model</span><span class="o">.</span><span class="n">layer2</span><span class="o">.</span><span class="n">output</span><span class="o">.</span><span class="n">save</span><span class="p">()</span>
   <span class="n">tiny_model</span><span class="o">.</span><span class="n">layer1</span><span class="o">.</span><span class="n">output</span><span class="o">.</span><span class="n">stop</span><span class="p">()</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;L2 - Output: &quot;</span><span class="p">,</span> <span class="n">l2_out</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
L2 - Output:
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
<span class="ansi-red-fg">---------------------------------------------------------------------------</span>
<span class="ansi-red-fg">ValueError</span>                                Traceback (most recent call last)
Cell <span class="ansi-green-fg">In[24], line 5</span>
<span class="ansi-green-intense-fg ansi-bold">      2</span>    l2_out <span style="color: rgb(98,98,98)">=</span> tiny_model<span style="color: rgb(98,98,98)">.</span>layer2<span style="color: rgb(98,98,98)">.</span>output<span style="color: rgb(98,98,98)">.</span>save()
<span class="ansi-green-intense-fg ansi-bold">      3</span>    tiny_model<span style="color: rgb(98,98,98)">.</span>layer1<span style="color: rgb(98,98,98)">.</span>output<span style="color: rgb(98,98,98)">.</span>stop()
<span class="ansi-green-fg">----&gt; 5</span> <span class="ansi-yellow-bg" style="color: rgb(0,135,0)">print</span><span class="ansi-yellow-bg">(</span><span class="ansi-yellow-bg" style="color: rgb(175,0,0)">&#34;</span><span class="ansi-yellow-bg" style="color: rgb(175,0,0)">L2 - Output: </span><span class="ansi-yellow-bg" style="color: rgb(175,0,0)">&#34;</span><span class="ansi-yellow-bg">,</span><span class="ansi-yellow-bg"> </span><span class="ansi-yellow-bg">l2_out</span><span class="ansi-yellow-bg">)</span>

File <span class="ansi-green-fg">~/Projects/NDIF/nnsight/src/nnsight/tracing/Proxy.py:56</span>, in <span class="ansi-cyan-fg">Proxy.__str__</span><span class="ansi-blue-fg">(self)</span>
<span class="ansi-green-intense-fg ansi-bold">     52</span> <span class="ansi-bold" style="color: rgb(0,135,0)">def</span> <span style="color: rgb(0,0,255)">__str__</span>(<span style="color: rgb(0,135,0)">self</span>) <span style="color: rgb(98,98,98)">-</span><span style="color: rgb(98,98,98)">&gt;</span> <span style="color: rgb(0,135,0)">str</span>:
<span class="ansi-green-intense-fg ansi-bold">     54</span>     <span class="ansi-bold" style="color: rgb(0,135,0)">if</span> <span class="ansi-bold" style="color: rgb(175,0,255)">not</span> <span style="color: rgb(0,135,0)">self</span><span style="color: rgb(98,98,98)">.</span>node<span style="color: rgb(98,98,98)">.</span>attached():
<span class="ansi-green-fg">---&gt; 56</span>         <span class="ansi-bold" style="color: rgb(0,135,0)">return</span> <span style="color: rgb(0,135,0)">str</span>(<span class="ansi-yellow-bg" style="color: rgb(0,135,0)">self</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">.</span><span class="ansi-yellow-bg">value</span>)
<span class="ansi-green-intense-fg ansi-bold">     58</span>     <span class="ansi-bold" style="color: rgb(0,135,0)">return</span> <span style="color: rgb(175,0,0)">f</span><span style="color: rgb(175,0,0)">&#34;</span><span class="ansi-bold" style="color: rgb(175,95,135)">{</span><span style="color: rgb(0,135,0)">type</span>(<span style="color: rgb(0,135,0)">self</span>)<span style="color: rgb(98,98,98)">.</span><span style="color: rgb(0,0,135)">__name__</span><span class="ansi-bold" style="color: rgb(175,95,135)">}</span><span style="color: rgb(175,0,0)"> (</span><span class="ansi-bold" style="color: rgb(175,95,135)">{</span><span style="color: rgb(0,135,0)">self</span><span style="color: rgb(98,98,98)">.</span>node<span style="color: rgb(98,98,98)">.</span>name<span class="ansi-bold" style="color: rgb(175,95,135)">}</span><span style="color: rgb(175,0,0)">): </span><span class="ansi-bold" style="color: rgb(175,95,135)">{</span><span style="color: rgb(0,135,0)">self</span><span style="color: rgb(98,98,98)">.</span>node<span style="color: rgb(98,98,98)">.</span>proxy_value<span style="color: rgb(188,188,188)"> </span><span class="ansi-bold" style="color: rgb(0,135,0)">if</span><span style="color: rgb(188,188,188)"> </span><span style="color: rgb(0,135,0)">self</span><span style="color: rgb(98,98,98)">.</span>node<span style="color: rgb(98,98,98)">.</span>proxy_value<span style="color: rgb(188,188,188)"> </span><span class="ansi-bold" style="color: rgb(175,0,255)">is</span><span style="color: rgb(188,188,188)"> </span><span class="ansi-bold" style="color: rgb(175,0,255)">not</span><span style="color: rgb(188,188,188)"> </span>inspect<span style="color: rgb(98,98,98)">.</span>_empty<span style="color: rgb(188,188,188)"> </span><span class="ansi-bold" style="color: rgb(0,135,0)">else</span><span style="color: rgb(188,188,188)"> </span><span style="color: rgb(175,0,0)">&#39;</span><span style="color: rgb(175,0,0)">&#39;</span><span class="ansi-bold" style="color: rgb(175,95,135)">}</span><span style="color: rgb(175,0,0)">&#34;</span>

File <span class="ansi-green-fg">~/Projects/NDIF/nnsight/src/nnsight/tracing/Proxy.py:50</span>, in <span class="ansi-cyan-fg">Proxy.value</span><span class="ansi-blue-fg">(self)</span>
<span class="ansi-green-intense-fg ansi-bold">     42</span> <span style="color: rgb(175,0,255)">@property</span>
<span class="ansi-green-intense-fg ansi-bold">     43</span> <span class="ansi-bold" style="color: rgb(0,135,0)">def</span> <span style="color: rgb(0,0,255)">value</span>(<span style="color: rgb(0,135,0)">self</span>) <span style="color: rgb(98,98,98)">-</span><span style="color: rgb(98,98,98)">&gt;</span> Any:
<span class="ansi-green-intense-fg ansi-bold">     44</span> <span style="color: rgb(188,188,188)">    </span><span style="color: rgb(175,0,0)">&#34;&#34;&#34;Property to return the value of this proxy&#39;s node.</span>
<span class="ansi-green-intense-fg ansi-bold">     45</span>
<span class="ansi-green-intense-fg ansi-bold">     46</span> <span style="color: rgb(175,0,0)">    Returns:</span>
<span class="ansi-green-intense-fg ansi-bold">     47</span> <span style="color: rgb(175,0,0)">        Any: The stored value of the proxy, populated during execution of the model.</span>
<span class="ansi-green-intense-fg ansi-bold">     48</span> <span style="color: rgb(175,0,0)">    &#34;&#34;&#34;</span>
<span class="ansi-green-fg">---&gt; 50</span>     <span class="ansi-bold" style="color: rgb(0,135,0)">return</span> <span class="ansi-yellow-bg" style="color: rgb(0,135,0)">self</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">.</span><span class="ansi-yellow-bg">node</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">.</span><span class="ansi-yellow-bg">value</span>

File <span class="ansi-green-fg">~/Projects/NDIF/nnsight/src/nnsight/tracing/Node.py:182</span>, in <span class="ansi-cyan-fg">Node.value</span><span class="ansi-blue-fg">(self)</span>
<span class="ansi-green-intense-fg ansi-bold">    172</span> <span style="color: rgb(175,0,0)">&#34;&#34;&#34;Property to return the value of this node.</span>
<span class="ansi-green-intense-fg ansi-bold">    173</span>
<span class="ansi-green-intense-fg ansi-bold">    174</span> <span style="color: rgb(175,0,0)">Returns:</span>
<span class="ansi-green-fg">   (...)</span>
<span class="ansi-green-intense-fg ansi-bold">    178</span> <span style="color: rgb(175,0,0)">    ValueError: If the underlying ._value is inspect._empty (therefore never set or destroyed).</span>
<span class="ansi-green-intense-fg ansi-bold">    179</span> <span style="color: rgb(175,0,0)">&#34;&#34;&#34;</span>
<span class="ansi-green-intense-fg ansi-bold">    181</span> <span class="ansi-bold" style="color: rgb(0,135,0)">if</span> <span class="ansi-bold" style="color: rgb(175,0,255)">not</span> <span style="color: rgb(0,135,0)">self</span><span style="color: rgb(98,98,98)">.</span>done():
<span class="ansi-green-fg">--&gt; 182</span>     <span class="ansi-bold" style="color: rgb(0,135,0)">raise</span> <span class="ansi-bold" style="color: rgb(215,95,95)">ValueError</span>(<span style="color: rgb(175,0,0)">&#34;</span><span style="color: rgb(175,0,0)">Accessing value before it</span><span style="color: rgb(175,0,0)">&#39;</span><span style="color: rgb(175,0,0)">s been set.</span><span style="color: rgb(175,0,0)">&#34;</span>)
<span class="ansi-green-intense-fg ansi-bold">    184</span> <span class="ansi-bold" style="color: rgb(0,135,0)">return</span> <span style="color: rgb(0,135,0)">self</span><span style="color: rgb(98,98,98)">.</span>_value

<span class="ansi-red-fg">ValueError</span>: Accessing value before it&#39;s been set.
</pre></div></div>
</div>
</section>
<section id="Conditional-Interventions">
<h2>Conditional Interventions<a class="headerlink" href="#Conditional-Interventions" title="Link to this heading">#</a></h2>
<p>Interventions can also be made conditional.</p>
<p>Inside the tracing context we can specify a new conditional context. This context will only execute the interventions within it if the condition is met.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[25]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">tiny_model</span><span class="o">.</span><span class="n">trace</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span> <span class="k">as</span> <span class="n">tracer</span><span class="p">:</span>

  <span class="n">rand_int</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="n">low</span><span class="o">=-</span><span class="mi">10</span><span class="p">,</span> <span class="n">high</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,))</span>

  <span class="k">with</span> <span class="n">tracer</span><span class="o">.</span><span class="n">cond</span><span class="p">(</span><span class="n">rand_int</span> <span class="o">%</span> <span class="mi">2</span> <span class="o">==</span> <span class="mi">0</span><span class="p">):</span>
    <span class="n">tracer</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="s2">&quot;Random Integer &quot;</span><span class="p">,</span> <span class="n">rand_int</span><span class="p">,</span> <span class="s2">&quot; is Even&quot;</span><span class="p">)</span>

  <span class="k">with</span> <span class="n">tracer</span><span class="o">.</span><span class="n">cond</span><span class="p">(</span><span class="n">rand_int</span> <span class="o">%</span> <span class="mi">2</span> <span class="o">==</span> <span class="mi">1</span><span class="p">):</span>
    <span class="n">tracer</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="s2">&quot;Random Integer &quot;</span><span class="p">,</span> <span class="n">rand_int</span><span class="p">,</span> <span class="s2">&quot; is Odd&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Random Integer  tensor([-5])  is Odd
</pre></div></div>
</div>
<p>In the example above, we have two conditional contexts with mutually exclusive conditions, just like a usual <code class="docutils literal notranslate"><span class="pre">If</span></code>-<code class="docutils literal notranslate"><span class="pre">Else</span></code> statement.</p>
<p>Conditional contexts can also be nested, if we want our interventions to depend on more than one condition at a time.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[26]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">tiny_model</span><span class="o">.</span><span class="n">trace</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span> <span class="k">as</span> <span class="n">tracer</span><span class="p">:</span>

  <span class="n">non_rand_int</span> <span class="o">=</span> <span class="mi">8</span>

  <span class="k">with</span> <span class="n">tracer</span><span class="o">.</span><span class="n">cond</span><span class="p">(</span><span class="n">non_rand_int</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">):</span>
    <span class="k">with</span> <span class="n">tracer</span><span class="o">.</span><span class="n">cond</span><span class="p">(</span><span class="n">non_rand_int</span> <span class="o">%</span> <span class="mi">2</span> <span class="o">==</span> <span class="mi">0</span><span class="p">):</span>
      <span class="n">tracer</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="s2">&quot;Rand Int &quot;</span><span class="p">,</span> <span class="n">non_rand_int</span><span class="p">,</span> <span class="s2">&quot; is Positive and Even&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Rand Int  8  is Positive and Even
</pre></div></div>
</div>
</section>
</section>
<section id="2️⃣-Bigger">
<h1>2️⃣ Bigger<a class="headerlink" href="#2️⃣-Bigger" title="Link to this heading">#</a></h1>
<p>Now that we have the basics of <code class="docutils literal notranslate"><span class="pre">nnsight</span></code> under our belt, we can scale our model up and combine the techniques we’ve learned into more interesting experiments.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">NNsight</span></code> class is very bare bones. It wraps a pre-defined model and does no pre-processing on the inputs we enter. It’s designed to be extended with more complex and powerful types of models and we’re excited to see what can be done to leverage its features.</p>
<section id="LanguageModel">
<h2>LanguageModel<a class="headerlink" href="#LanguageModel" title="Link to this heading">#</a></h2>
<p><code class="docutils literal notranslate"><span class="pre">LanguageModel</span></code> is a subclass of <code class="docutils literal notranslate"><span class="pre">NNsight</span></code>. While we could define and create a model to pass in directly, <code class="docutils literal notranslate"><span class="pre">LanguageModel</span></code> includes special support for Huggingface language models, including automatically loading models from a Huggingface ID, and loading the model together with the appropriate tokenizer.</p>
<p>Here is how we can use <code class="docutils literal notranslate"><span class="pre">LanguageModel</span></code> to load <code class="docutils literal notranslate"><span class="pre">GPT-2</span></code>:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[27]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">nnsight</span> <span class="kn">import</span> <span class="n">LanguageModel</span>

<span class="n">llm</span> <span class="o">=</span> <span class="n">LanguageModel</span><span class="p">(</span><span class="s2">&quot;openai-community/gpt2&quot;</span><span class="p">,</span> <span class="n">device_map</span><span class="o">=</span><span class="s2">&quot;auto&quot;</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">llm</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
GPT2LMHeadModel(
  (transformer): GPT2Model(
    (wte): Embedding(50257, 768)
    (wpe): Embedding(1024, 768)
    (drop): Dropout(p=0.1, inplace=False)
    (h): ModuleList(
      (0-11): 12 x GPT2Block(
        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (attn): GPT2SdpaAttention(
          (c_attn): Conv1D()
          (c_proj): Conv1D()
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (resid_dropout): Dropout(p=0.1, inplace=False)
        )
        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (mlp): GPT2MLP(
          (c_fc): Conv1D()
          (c_proj): Conv1D()
          (act): NewGELUActivation()
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
  )
  (lm_head): Linear(in_features=768, out_features=50257, bias=False)
  (generator): WrapperModule()
)
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
/opt/homebrew/anaconda3/envs/nnsight_local/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884
  warnings.warn(
</pre></div></div>
</div>
<details><summary><p>On Model Initialization</p>
</summary><hr class="docutils" />
<p>A few important things to note:</p>
<p>Keyword arguments passed to the initialization of <code class="docutils literal notranslate"><span class="pre">LanguageModel</span></code> is forwarded to HuggingFace specific loading logic. In this case, <code class="docutils literal notranslate"><span class="pre">device_map</span></code> specifies which devices to use and its value <code class="docutils literal notranslate"><span class="pre">auto</span></code> indicates to evenly distribute it to all available GPUs (and CPU if no GPUs available). Other arguments can be found here: <a class="reference external" href="https://huggingface.co/docs/transformers/model_doc/auto#transformers.AutoModelForCausalLM">https://huggingface.co/docs/transformers/model_doc/auto#transformers.AutoModelForCausalLM</a></p>
<p>When we initialize <code class="docutils literal notranslate"><span class="pre">LanguageModel</span></code>, we aren’t yet loading the parameters of the model into memory. We are actually loading a ‘meta’ version of the model which doesn’t take up any memory, but still allows us to view and trace actions on it. After exiting the first tracing context, the model is then fully loaded into memory. To load into memory on initialization, you can pass <code class="docutils literal notranslate"><span class="pre">dispatch=True</span></code> into <code class="docutils literal notranslate"><span class="pre">LanguageModel</span></code> like
<code class="docutils literal notranslate"><span class="pre">LanguageModel('openai-community/gpt2',</span> <span class="pre">device_map=&quot;auto&quot;,</span> <span class="pre">dispatch=True)</span></code>.</p>
<hr class="docutils" />
</details><p>Let’s put together some of the features we applied to the small model, but now on <code class="docutils literal notranslate"><span class="pre">GPT-2</span></code>. Unlike <code class="docutils literal notranslate"><span class="pre">NNsight</span></code>, <code class="docutils literal notranslate"><span class="pre">LanguageModel</span></code> does define logic to pre-process inputs upon entering the tracing context. This makes interacting with the model simpler without having to directly access the tokenizer.</p>
<p>In the following example, we ablate the value coming from the last layer’s MLP module and decode the logits to see what token the model predicts without influence from that particular module:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[28]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">llm</span><span class="o">.</span><span class="n">trace</span><span class="p">(</span><span class="s2">&quot;The Eiffel Tower is in the city of&quot;</span><span class="p">):</span>

    <span class="c1"># Access the last layer using h[-1] as it&#39;s a ModuleList</span>
    <span class="c1"># Access the first index of .output as that&#39;s where the hidden states are.</span>
    <span class="n">llm</span><span class="o">.</span><span class="n">transformer</span><span class="o">.</span><span class="n">h</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">mlp</span><span class="o">.</span><span class="n">output</span><span class="p">[</span><span class="mi">0</span><span class="p">][:]</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="c1"># Logits come out of model.lm_head and we apply argmax to get the predicted token ids.</span>
    <span class="n">token_ids</span> <span class="o">=</span> <span class="n">llm</span><span class="o">.</span><span class="n">lm_head</span><span class="o">.</span><span class="n">output</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">save</span><span class="p">()</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Token IDs:&quot;</span><span class="p">,</span> <span class="n">token_ids</span><span class="p">)</span>

<span class="c1"># Apply the tokenizer to decode the ids into words after the tracing context.</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Prediction:&quot;</span><span class="p">,</span> <span class="n">llm</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">token_ids</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">]))</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
You&#39;re using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>

Token IDs: tensor([[ 262,   12,  417, 8765,   11,  257,  262, 3504,  338, 3576]],
       device=&#39;mps:0&#39;)
Prediction:  London
</pre></div></div>
</div>
<p>We just ran a little intervention on a much more complex model with a lot more parameters! An important piece of information we’re missing though is what the prediction would look like without our ablation.</p>
<p>Of course we could just run two tracing contexts and compare the outputs. This, however, would require two forward passes through the model. <code class="docutils literal notranslate"><span class="pre">NNsight</span></code> can do better than that.</p>
</section>
<section id="Batching">
<h2>Batching<a class="headerlink" href="#Batching" title="Link to this heading">#</a></h2>
<p>It’s time to bring back the <code class="docutils literal notranslate"><span class="pre">Tracer</span></code> object we dropped before.</p>
<p>See, when we call <code class="docutils literal notranslate"><span class="pre">.trace(...)</span></code>, it’s actually creating two different contexts behind the scenes. The second one is the invoker context. The invoker context defines the values of <code class="docutils literal notranslate"><span class="pre">.input</span></code> and <code class="docutils literal notranslate"><span class="pre">.output</span></code> Proxies.</p>
<p>If we call <code class="docutils literal notranslate"><span class="pre">.trace(...)</span></code> with some input, the input is passed on to the invoker. Since there is only one input – only one invoker context is created.</p>
<p>If we call <code class="docutils literal notranslate"><span class="pre">.trace()</span></code> without input then we can call <code class="docutils literal notranslate"><span class="pre">tracer.invoke(...)</span></code> to manually create the invoker context with our input. Now every subsequent time we call <code class="docutils literal notranslate"><span class="pre">.invoke(...)</span></code>, new interventions will only refer to the input in that particular invoke. When exiting the tracing context, the inputs from all of the invokers will be batched together, and they will be executed in one forward pass! So let’s do the ablation experiment, and compute a ‘control’ output to compare to:</p>
<details><summary><p>More on the invoker context</p>
</summary><hr class="docutils" />
<p>Note that when injecting data to only the relevant invoker interventions, <code class="docutils literal notranslate"><span class="pre">nnsight</span></code> tries, but can’t guarantee, that it can narrow the data into the right batch idxs. So there are cases where all invokes will get all of the data. Specifically, if the input or output data is stored as an object that is not an arbitrary collection of tensors, it will be broadcasted to all invokes.</p>
<p>Just like <code class="docutils literal notranslate"><span class="pre">.trace(...)</span></code> created a <code class="docutils literal notranslate"><span class="pre">Tracer</span></code> object, <code class="docutils literal notranslate"><span class="pre">.invoke(...)</span></code> creates an <code class="docutils literal notranslate"><span class="pre">Invoker</span></code> object. For <code class="docutils literal notranslate"><span class="pre">LaguageModel</span></code> models, the <code class="docutils literal notranslate"><span class="pre">Invoker</span></code> prepares the input by running a tokenizer on it. <code class="docutils literal notranslate"><span class="pre">Invoker</span></code> stores pre-processed inputs at <code class="docutils literal notranslate"><span class="pre">invoker.inputs</span></code>, which can be accessed to see information about our inputs. In case when we are passing a single input to <code class="docutils literal notranslate"><span class="pre">.trace(...)</span></code> directly, we can still access the invoker object at <code class="docutils literal notranslate"><span class="pre">tracer.invoker</span></code> without having to call <code class="docutils literal notranslate"><span class="pre">tracer.invoke(...)</span></code>.</p>
<div class="line-block">
<div class="line">Keyword arguments given to <code class="docutils literal notranslate"><span class="pre">.invoke(..)</span></code> make its way to the input pre-processing.</div>
<div class="line"><code class="docutils literal notranslate"><span class="pre">LanguageModel</span></code> has keyword arguments <code class="docutils literal notranslate"><span class="pre">max_length</span></code> and <code class="docutils literal notranslate"><span class="pre">truncation</span></code> used for tokenization, and they can be passed to the invoker. If we are calling a single-input <code class="docutils literal notranslate"><span class="pre">.trace(...)</span></code> and want to pass the keyword arguments, we can do so in the form of <code class="docutils literal notranslate"><span class="pre">invoker_args</span></code> that should be a dictionary of keyword arguments for the invoker.</div>
</div>
<p>Here is an example to demonstrate everything we’ve described:</p>
<p><strong>This snippet</strong></p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>with llm.trace(&quot;hello&quot;, invoker_args={&quot;max_length&quot;:10}) as tracer:
  invoker = tracer.invoker
</pre></div>
</div>
<p><strong>does the same as</strong></p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>with llm.trace() as tracer:
  with tracer.invoke(&quot;hello&quot;, max_length=10) as invoker:
    invoker = invoker
</pre></div>
</div>
<hr class="docutils" />
</details><div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[29]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">llm</span><span class="o">.</span><span class="n">trace</span><span class="p">()</span> <span class="k">as</span> <span class="n">tracer</span><span class="p">:</span>

    <span class="k">with</span> <span class="n">tracer</span><span class="o">.</span><span class="n">invoke</span><span class="p">(</span><span class="s2">&quot;The Eiffel Tower is in the city of&quot;</span><span class="p">):</span>

        <span class="c1"># Ablate the last MLP for only this batch.</span>
        <span class="n">llm</span><span class="o">.</span><span class="n">transformer</span><span class="o">.</span><span class="n">h</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">mlp</span><span class="o">.</span><span class="n">output</span><span class="p">[</span><span class="mi">0</span><span class="p">][:]</span> <span class="o">=</span> <span class="mi">0</span>

        <span class="c1"># Get the output for only the intervened on batch.</span>
        <span class="n">token_ids_intervention</span> <span class="o">=</span> <span class="n">llm</span><span class="o">.</span><span class="n">lm_head</span><span class="o">.</span><span class="n">output</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">save</span><span class="p">()</span>

    <span class="k">with</span> <span class="n">tracer</span><span class="o">.</span><span class="n">invoke</span><span class="p">(</span><span class="s2">&quot;The Eiffel Tower is in the city of&quot;</span><span class="p">):</span>

        <span class="c1"># Get the output for only the original batch.</span>
        <span class="n">token_ids_original</span> <span class="o">=</span> <span class="n">llm</span><span class="o">.</span><span class="n">lm_head</span><span class="o">.</span><span class="n">output</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">save</span><span class="p">()</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Original token IDs:&quot;</span><span class="p">,</span> <span class="n">token_ids_original</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Modified token IDs:&quot;</span><span class="p">,</span> <span class="n">token_ids_intervention</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Original prediction:&quot;</span><span class="p">,</span> <span class="n">llm</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">token_ids_original</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">]))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Modified prediction:&quot;</span><span class="p">,</span> <span class="n">llm</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">token_ids_intervention</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">]))</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Original token IDs: tensor([[ 198,   12,  417, 8765,  318,  257,  262, 3504, 7372, 6342]],
       device=&#39;mps:0&#39;)
Modified token IDs: tensor([[ 262,   12,  417, 8765,   11,  257,  262, 3504,  338, 3576]],
       device=&#39;mps:0&#39;)
Original prediction:  Paris
Modified prediction:  London
</pre></div></div>
</div>
<p>So it did end up affecting what the model predicted. That’s pretty neat!</p>
<p>Another cool thing with multiple invokes is that the Proxies can interact between them. Here we transfer the word token embeddings from a real prompt into another placeholder prompt. Therefore the latter prompt produces the output of the former prompt:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[30]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">llm</span><span class="o">.</span><span class="n">trace</span><span class="p">()</span> <span class="k">as</span> <span class="n">tracer</span><span class="p">:</span>

    <span class="k">with</span> <span class="n">tracer</span><span class="o">.</span><span class="n">invoke</span><span class="p">(</span><span class="s2">&quot;The Eiffel Tower is in the city of&quot;</span><span class="p">):</span>

        <span class="n">embeddings</span> <span class="o">=</span> <span class="n">llm</span><span class="o">.</span><span class="n">transformer</span><span class="o">.</span><span class="n">wte</span><span class="o">.</span><span class="n">output</span>

    <span class="k">with</span> <span class="n">tracer</span><span class="o">.</span><span class="n">invoke</span><span class="p">(</span><span class="s2">&quot;_ _ _ _ _ _ _ _ _ _&quot;</span><span class="p">):</span>

        <span class="n">llm</span><span class="o">.</span><span class="n">transformer</span><span class="o">.</span><span class="n">wte</span><span class="o">.</span><span class="n">output</span> <span class="o">=</span> <span class="n">embeddings</span>

        <span class="n">token_ids_intervention</span> <span class="o">=</span> <span class="n">llm</span><span class="o">.</span><span class="n">lm_head</span><span class="o">.</span><span class="n">output</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">save</span><span class="p">()</span>

    <span class="k">with</span> <span class="n">tracer</span><span class="o">.</span><span class="n">invoke</span><span class="p">(</span><span class="s2">&quot;_ _ _ _ _ _ _ _ _ _&quot;</span><span class="p">):</span>

        <span class="n">token_ids_original</span> <span class="o">=</span> <span class="n">llm</span><span class="o">.</span><span class="n">lm_head</span><span class="o">.</span><span class="n">output</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">save</span><span class="p">()</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Original prediction:&quot;</span><span class="p">,</span> <span class="n">llm</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">token_ids_original</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">]))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Modified prediction:&quot;</span><span class="p">,</span> <span class="n">llm</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">token_ids_intervention</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">]))</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Original prediction:  _
Modified prediction:  Paris
</pre></div></div>
</div>
</section>
<section id=".next()">
<h2>.next()<a class="headerlink" href="#.next()" title="Link to this heading">#</a></h2>
<p>Some HuggingFace models define methods to generate multiple outputs at a time. <code class="docutils literal notranslate"><span class="pre">LanguageModel</span></code> wraps that functionality to provide the same tracing features by using <code class="docutils literal notranslate"><span class="pre">.generate(...)</span></code> instead of <code class="docutils literal notranslate"><span class="pre">.trace(...)</span></code>. This calls the underlying model’s <code class="docutils literal notranslate"><span class="pre">.generate</span></code> method. It passes the output through a <code class="docutils literal notranslate"><span class="pre">.generator</span></code> module that we’ve added onto the model, allowing us to get the generate output at <code class="docutils literal notranslate"><span class="pre">.generator.output</span></code>.</p>
<p>In a case like this, the underlying model is called more than once, so the modules of said model produce more than one output. Which iteration should a given <code class="docutils literal notranslate"><span class="pre">module.output</span></code> refer to? That’s where <code class="docutils literal notranslate"><span class="pre">Module.next()</span></code> comes in.</p>
<p>Each module has a call idx associated with it and <code class="docutils literal notranslate"><span class="pre">.next()</span></code> simply increments that attribute. At the time of execution, data is injected into the intervention graph only at the iteration that matches the call idx.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[31]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">llm</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span><span class="s2">&quot;The Eiffel Tower is in the city of&quot;</span><span class="p">,</span> <span class="n">max_new_tokens</span><span class="o">=</span><span class="mi">3</span><span class="p">):</span>

    <span class="n">token_ids_1</span> <span class="o">=</span> <span class="n">llm</span><span class="o">.</span><span class="n">lm_head</span><span class="o">.</span><span class="n">output</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">save</span><span class="p">()</span>

    <span class="n">token_ids_2</span> <span class="o">=</span> <span class="n">llm</span><span class="o">.</span><span class="n">lm_head</span><span class="o">.</span><span class="n">next</span><span class="p">()</span><span class="o">.</span><span class="n">output</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">save</span><span class="p">()</span>

    <span class="n">token_ids_3</span> <span class="o">=</span> <span class="n">llm</span><span class="o">.</span><span class="n">lm_head</span><span class="o">.</span><span class="n">next</span><span class="p">()</span><span class="o">.</span><span class="n">output</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">save</span><span class="p">()</span>

    <span class="n">output</span> <span class="o">=</span> <span class="n">llm</span><span class="o">.</span><span class="n">generator</span><span class="o">.</span><span class="n">output</span><span class="o">.</span><span class="n">save</span><span class="p">()</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Prediction 1: &quot;</span><span class="p">,</span> <span class="n">llm</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">token_ids_1</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">]))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Prediction 2: &quot;</span><span class="p">,</span> <span class="n">llm</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">token_ids_2</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">]))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Prediction 3: &quot;</span><span class="p">,</span> <span class="n">llm</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">token_ids_3</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">]))</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;All token ids: &quot;</span><span class="p">,</span> <span class="n">output</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Full prediction: &quot;</span><span class="p">,</span> <span class="n">llm</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">batch_decode</span><span class="p">(</span><span class="n">output</span><span class="o">.</span><span class="n">value</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>

Prediction 1:   Paris
Prediction 2:  ,
Prediction 3:   and
All token ids:  tensor([[ 464,  412,  733,  417, 8765,  318,  287,  262, 1748,  286, 6342,   11,
          290]], device=&#39;mps:0&#39;)
Full prediction:  [&#39;The Eiffel Tower is in the city of Paris, and&#39;]
</pre></div></div>
</div>
</section>
<section id="Model-Editing">
<h2>Model Editing<a class="headerlink" href="#Model-Editing" title="Link to this heading">#</a></h2>
<p>NNsight’s model editing feature allows you to create persistently modified versions of a model with a use of <code class="docutils literal notranslate"><span class="pre">.edit()</span></code>. Unlike interventions in a tracing context, which are temporary, the <strong>Editor</strong> context enables you to make lasting changes to a model instance.</p>
<p>This feature is useful for: * Creating modified model variants without altering the original * Applying changes that persist across multiple forward passes * Comparing interventions between original and edited models</p>
<p>Let’s explore how to use the <strong>Editor</strong> context to make a simple persistent change to a model:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[32]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># we take the hidden states with the expected output &quot;Paris&quot;</span>
<span class="k">with</span> <span class="n">llm</span><span class="o">.</span><span class="n">trace</span><span class="p">(</span><span class="s2">&quot;The Eiffel Tower is located in the city of&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">tracer</span><span class="p">:</span>
    <span class="n">hs11</span> <span class="o">=</span> <span class="n">llm</span><span class="o">.</span><span class="n">transformer</span><span class="o">.</span><span class="n">h</span><span class="p">[</span><span class="mi">11</span><span class="p">]</span><span class="o">.</span><span class="n">output</span><span class="p">[</span><span class="mi">0</span><span class="p">][:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="p">:]</span><span class="o">.</span><span class="n">save</span><span class="p">()</span>

<span class="c1"># the edited model will now always predict &quot;Paris&quot; as the next token</span>
<span class="k">with</span> <span class="n">llm</span><span class="o">.</span><span class="n">edit</span><span class="p">()</span> <span class="k">as</span> <span class="n">llm_edited</span><span class="p">:</span>
    <span class="n">llm</span><span class="o">.</span><span class="n">transformer</span><span class="o">.</span><span class="n">h</span><span class="p">[</span><span class="mi">11</span><span class="p">]</span><span class="o">.</span><span class="n">output</span><span class="p">[</span><span class="mi">0</span><span class="p">][:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">hs11</span>

<span class="c1"># we demonstrate this by comparing the output of an unmodified model...</span>
<span class="k">with</span> <span class="n">llm</span><span class="o">.</span><span class="n">trace</span><span class="p">(</span><span class="s2">&quot;Vatican is located in the city of&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">tracer</span><span class="p">:</span>
    <span class="n">original_tokens</span> <span class="o">=</span> <span class="n">llm</span><span class="o">.</span><span class="n">lm_head</span><span class="o">.</span><span class="n">output</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">save</span><span class="p">()</span>

<span class="c1"># ...with the output of the edited model</span>
<span class="k">with</span> <span class="n">llm_edited</span><span class="o">.</span><span class="n">trace</span><span class="p">(</span><span class="s2">&quot;Vatican is located in the city of&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">tracer</span><span class="p">:</span>
    <span class="n">modified_tokens</span> <span class="o">=</span> <span class="n">llm</span><span class="o">.</span><span class="n">lm_head</span><span class="o">.</span><span class="n">output</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">save</span><span class="p">()</span>


<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Original Prediction: &quot;</span><span class="p">,</span> <span class="n">llm</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">original_tokens</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">]))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Modified Prediction: &quot;</span><span class="p">,</span> <span class="n">llm</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">modified_tokens</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">]))</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>

Original Prediction:   Rome
Modified Prediction:   Paris
</pre></div></div>
</div>
<p>Edits defined within an <strong>Editor</strong> context create a new, modified version of the model by default, preserving the original. This allows for safe experimentation with model changes. If you wish to modify the original model directly, you can set <code class="docutils literal notranslate"><span class="pre">inplace=True</span></code> when calling <code class="docutils literal notranslate"><span class="pre">.edit()</span></code>.</p>
<p>Use this option cautiously, as in-place edits alter the base model for all the consequent model calls.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[33]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># we use the hidden state we saved above (hs11)</span>
<span class="k">with</span> <span class="n">llm</span><span class="o">.</span><span class="n">edit</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="k">as</span> <span class="n">llm_edited</span><span class="p">:</span>
    <span class="n">llm</span><span class="o">.</span><span class="n">transformer</span><span class="o">.</span><span class="n">h</span><span class="p">[</span><span class="mi">11</span><span class="p">]</span><span class="o">.</span><span class="n">output</span><span class="p">[</span><span class="mi">0</span><span class="p">][:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">hs11</span>

<span class="c1"># we demonstrate this by comparing the output of an unmodified model...</span>
<span class="k">with</span> <span class="n">llm</span><span class="o">.</span><span class="n">trace</span><span class="p">(</span><span class="s2">&quot;Vatican is located in the city of&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">tracer</span><span class="p">:</span>
    <span class="n">modified_tokens</span> <span class="o">=</span> <span class="n">llm</span><span class="o">.</span><span class="n">lm_head</span><span class="o">.</span><span class="n">output</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">save</span><span class="p">()</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Modified In-place: &quot;</span><span class="p">,</span> <span class="n">llm</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">modified_tokens</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">]))</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Modified In-place:   Paris
</pre></div></div>
</div>
<p>If you’ve made in-place edits to your model and need to revert these changes, <code class="docutils literal notranslate"><span class="pre">.clear_edits()</span></code> can help. This method removes all edits applied to the model, effectively restoring it to its original state.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[34]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">llm</span><span class="o">.</span><span class="n">clear_edits</span><span class="p">()</span>

<span class="k">with</span> <span class="n">llm</span><span class="o">.</span><span class="n">trace</span><span class="p">(</span><span class="s2">&quot;Vatican is located in the city of&quot;</span><span class="p">):</span>
    <span class="n">modified_tokens</span> <span class="o">=</span> <span class="n">llm</span><span class="o">.</span><span class="n">lm_head</span><span class="o">.</span><span class="n">output</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">save</span><span class="p">()</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Edits cleared: &quot;</span><span class="p">,</span> <span class="n">llm</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">modified_tokens</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">]))</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Edits cleared:   Rome
</pre></div></div>
</div>
</section>
</section>
<section id="3️⃣-I-thought-you-said-huge-models?">
<h1>3️⃣ I thought you said huge models?<a class="headerlink" href="#3️⃣-I-thought-you-said-huge-models?" title="Link to this heading">#</a></h1>
<p><code class="docutils literal notranslate"><span class="pre">NNsight</span></code> is only one part of our project to democratize access to AI internals. The other half is <code class="docutils literal notranslate"><span class="pre">NDIF</span></code> (National Deep Inference Fabric).</p>
<p>The interaction between the two is fairly straightforward. The <strong>intervention graph</strong> we create via the tracing context can be encoded into a custom json format and sent via an http request to the <code class="docutils literal notranslate"><span class="pre">NDIF</span></code> servers. <code class="docutils literal notranslate"><span class="pre">NDIF</span></code> then decodes the <strong>intervention graph</strong> and <strong>interleaves</strong> it alongside the specified model.</p>
<p>To see which models are currently being hosted, check out the following status page: <a class="reference external" href="https://nnsight.net/status/">https://nnsight.net/status/</a></p>
<section id="Remote-execution">
<h2>Remote execution<a class="headerlink" href="#Remote-execution" title="Link to this heading">#</a></h2>
<p>In its current state, <code class="docutils literal notranslate"><span class="pre">NDIF</span></code> requires you to receive an API key. Therefore, to run the rest of this colab, you would need one of your own. To get one, simply go to <a class="reference external" href="https://login.ndif.us">https://login.ndif.us</a> and sign up.</p>
<p>With a valid API key, you then can configure <code class="docutils literal notranslate"><span class="pre">nnsight</span></code> by doing the following:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[35]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">nnsight</span> <span class="kn">import</span> <span class="n">CONFIG</span>

<span class="n">CONFIG</span><span class="o">.</span><span class="n">set_default_api_key</span><span class="p">(</span><span class="s2">&quot;YOUR_API_KEY&quot;</span><span class="p">)</span>
<br/></pre></div>
</div>
</div>
<p>This only needs to be run once as it will save this API key as the default in a config file along with the <code class="docutils literal notranslate"><span class="pre">nnsight</span></code> installation.</p>
<p>To amp things up a few levels, let’s demonstrate using <code class="docutils literal notranslate"><span class="pre">nnsight</span></code>’s tracing context with one of the larger open source language models, <code class="docutils literal notranslate"><span class="pre">Llama-3.1-70b</span></code>!</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[36]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">os</span>

<span class="c1"># llama3.1 70b is a gated model and you need access via your huggingface token</span>
<span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s1">&#39;HF_TOKEN&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;YOUR_HUGGING_FACE_TOKEN&quot;</span>
<br/></pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[37]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># We&#39;ll never actually load the parameters so no need to specify a device_map.</span>
<span class="n">llama</span> <span class="o">=</span> <span class="n">LanguageModel</span><span class="p">(</span><span class="s2">&quot;meta-llama/Meta-Llama-3.1-70B&quot;</span><span class="p">)</span>

<span class="c1"># All we need to specify using NDIF vs executing locally is remote=True.</span>
<span class="k">with</span> <span class="n">llama</span><span class="o">.</span><span class="n">trace</span><span class="p">(</span><span class="s2">&quot;The Eiffel Tower is in the city of&quot;</span><span class="p">,</span> <span class="n">remote</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="k">as</span> <span class="n">runner</span><span class="p">:</span>

    <span class="n">hidden_states</span> <span class="o">=</span> <span class="n">llama</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">output</span><span class="o">.</span><span class="n">save</span><span class="p">()</span>

    <span class="n">output</span> <span class="o">=</span> <span class="n">llama</span><span class="o">.</span><span class="n">output</span><span class="o">.</span><span class="n">save</span><span class="p">()</span>

<span class="nb">print</span><span class="p">(</span><span class="n">hidden_states</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="p">[</span><span class="s2">&quot;logits&quot;</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
2024-08-30 07:11:21,150 MainProcess nnsight_remote INFO     36ff46f0-d81a-4586-b7e7-eaf6f97d6c0b - RECEIVED: Your job has been received and is waiting approval.
2024-08-30 07:11:21,184 MainProcess nnsight_remote INFO     36ff46f0-d81a-4586-b7e7-eaf6f97d6c0b - APPROVED: Your job was approved and is waiting to be run.
2024-08-30 07:11:21,206 MainProcess nnsight_remote INFO     36ff46f0-d81a-4586-b7e7-eaf6f97d6c0b - RUNNING: Your job has started running.
2024-08-30 07:11:21,398 MainProcess nnsight_remote INFO     36ff46f0-d81a-4586-b7e7-eaf6f97d6c0b - COMPLETED: Your job has been completed.
Downloading result:   0%|          | 0.00/9.48M [00:00&lt;?, ?B/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
        - Avoid using `tokenizers` before the fork if possible
        - Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
Downloading result: 100%|██████████| 9.48M/9.48M [00:02&lt;00:00, 3.21MB/s]
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
(tensor([[[ 5.4688, -4.9062,  2.2344,  ..., -3.6875,  0.9609,  1.2578],
         [ 1.5469, -0.6172, -1.4531,  ..., -1.1562, -0.1406, -2.1250],
         [ 1.7812, -1.8906, -1.1875,  ...,  0.1680,  0.9609,  0.5625],
         ...,
         [ 0.9453, -0.3711,  1.3516,  ...,  1.3828, -0.7969, -1.9297],
         [-0.8906,  0.3672,  0.2617,  ...,  2.4688, -0.4414, -0.6758],
         [-1.6094,  1.0938,  1.7031,  ...,  1.8672, -1.1328, -0.5000]]],
       dtype=torch.bfloat16), DynamicCache())
tensor([[[ 6.3750,  8.6250, 13.0000,  ..., -4.1562, -4.1562, -4.1562],
         [-2.8594, -2.2344, -3.0938,  ..., -8.6250, -8.6250, -8.6250],
         [ 8.9375,  3.5938,  4.5000,  ..., -3.9375, -3.9375, -3.9375],
         ...,
         [ 3.5781,  3.4531,  0.0796,  ..., -6.5625, -6.5625, -6.5625],
         [10.8750,  6.4062,  4.9375,  ..., -4.0000, -4.0000, -3.9844],
         [ 7.2500,  6.1562,  3.5156,  ..., -4.7188, -4.7188, -4.7188]]])
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>

</pre></div></div>
</div>
<p>It really is as simple as <code class="docutils literal notranslate"><span class="pre">remote=True</span></code>. All of the techniques we went through in earlier sections work just the same when running locally or remotely.</p>
</section>
<section id="Sessions">
<h2>Sessions<a class="headerlink" href="#Sessions" title="Link to this heading">#</a></h2>
<p>NDIF uses a queue to handle concurrent requests from multiple users. To optimize the execution of our experiments we can use the <code class="docutils literal notranslate"><span class="pre">session</span></code> context to efficiently package multiple interventions together as one single request to the server.</p>
<p>This offers the following benefits: 1) All interventions within a session will be executed one after another without additional wait in the queue 2) All intermediate outputs of each intervention are stored on the server and can be accessed by other interventions in the same session without moving the data back and forth between NDIF and the local machine.</p>
<p>Let’s take a look:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[38]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">llama</span><span class="o">.</span><span class="n">session</span><span class="p">(</span><span class="n">remote</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="k">as</span> <span class="n">session</span><span class="p">:</span>

  <span class="k">with</span> <span class="n">llama</span><span class="o">.</span><span class="n">trace</span><span class="p">(</span><span class="s2">&quot;The Eiffel Tower is in the city of&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">t1</span><span class="p">:</span>
    <span class="c1"># capture the hidden state from layer 11 at the last token</span>
    <span class="n">hs_79</span> <span class="o">=</span> <span class="n">llama</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="mi">79</span><span class="p">]</span><span class="o">.</span><span class="n">output</span><span class="p">[</span><span class="mi">0</span><span class="p">][:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="p">:]</span> <span class="c1"># no .save()</span>
    <span class="n">t1_tokens_out</span> <span class="o">=</span> <span class="n">llama</span><span class="o">.</span><span class="n">lm_head</span><span class="o">.</span><span class="n">output</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">save</span><span class="p">()</span>

  <span class="k">with</span> <span class="n">llama</span><span class="o">.</span><span class="n">trace</span><span class="p">(</span><span class="s2">&quot;Buckingham Palace is in the city of&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">t2</span><span class="p">:</span>
    <span class="n">llama</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">output</span><span class="p">[</span><span class="mi">0</span><span class="p">][:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">hs_79</span><span class="p">[:]</span>
    <span class="n">t2_tokens_out</span> <span class="o">=</span> <span class="n">llama</span><span class="o">.</span><span class="n">lm_head</span><span class="o">.</span><span class="n">output</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">save</span><span class="p">()</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">T1 - Original Prediction: &quot;</span><span class="p">,</span> <span class="n">llama</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">t1_tokens_out</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">]))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;T2 - Modified Prediction: &quot;</span><span class="p">,</span> <span class="n">llama</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">t2_tokens_out</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">]))</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
2024-08-30 07:11:28,206 MainProcess nnsight_remote INFO     4a6576dd-b5fd-4f1f-9836-a619f8277057 - RECEIVED: Your job has been received and is waiting approval.
2024-08-30 07:11:28,206 MainProcess nnsight_remote INFO     4a6576dd-b5fd-4f1f-9836-a619f8277057 - APPROVED: Your job was approved and is waiting to be run.
2024-08-30 07:11:28,207 MainProcess nnsight_remote INFO     4a6576dd-b5fd-4f1f-9836-a619f8277057 - RUNNING: Your job has started running.
2024-08-30 07:11:28,207 MainProcess nnsight_remote INFO     4a6576dd-b5fd-4f1f-9836-a619f8277057 - LOG: 80
2024-08-30 07:11:28,416 MainProcess nnsight_remote INFO     4a6576dd-b5fd-4f1f-9836-a619f8277057 - COMPLETED: Your job has been completed.
Downloading result: 100%|██████████| 1.69k/1.69k [00:00&lt;00:00, 6.30MB/s]
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>

T1 - Original Prediction:   Paris
T2 - Modified Prediction:   Paris
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>

</pre></div></div>
</div>
<p>In the example above, we are interested in replacing the hidden state of a later layer with an earlier one. Since we are using a <code class="docutils literal notranslate"><span class="pre">session</span></code>, we don’t have to save the hidden state from Tracer 1 to reference it in Tracer 2.</p>
<p>It is important to note that all the traces defined within the <code class="docutils literal notranslate"><span class="pre">session</span></code> context are executed sequentially, strictly following the order of definition (i.e., <code class="docutils literal notranslate"><span class="pre">t2</span></code> being executed after <code class="docutils literal notranslate"><span class="pre">t1</span></code> and <code class="docutils literal notranslate"><span class="pre">t3</span></code> after <code class="docutils literal notranslate"><span class="pre">t2</span></code> etc.).</p>
<p>The <code class="docutils literal notranslate"><span class="pre">session</span></code> context object has its own methods to log values and be terminated early.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[39]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">llama</span><span class="o">.</span><span class="n">session</span><span class="p">(</span><span class="n">remote</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="k">as</span> <span class="n">session</span><span class="p">:</span>

  <span class="n">session</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="s2">&quot;-- Early Stop --&quot;</span><span class="p">)</span>
  <span class="n">session</span><span class="o">.</span><span class="n">exit</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
2024-08-30 07:11:30,900 MainProcess nnsight_remote INFO     28ac8e47-fa48-45a1-acb0-3e17960e36b8 - RECEIVED: Your job has been received and is waiting approval.
2024-08-30 07:11:30,934 MainProcess nnsight_remote INFO     28ac8e47-fa48-45a1-acb0-3e17960e36b8 - APPROVED: Your job was approved and is waiting to be run.
2024-08-30 07:11:30,935 MainProcess nnsight_remote INFO     28ac8e47-fa48-45a1-acb0-3e17960e36b8 - RUNNING: Your job has started running.
2024-08-30 07:11:30,951 MainProcess nnsight_remote INFO     28ac8e47-fa48-45a1-acb0-3e17960e36b8 - LOG: -- Early Stop --
2024-08-30 07:11:30,953 MainProcess nnsight_remote INFO     28ac8e47-fa48-45a1-acb0-3e17960e36b8 - COMPLETED: Your job has been completed.
Downloading result: 100%|██████████| 928/928 [00:00&lt;00:00, 4.11MB/s]
</pre></div></div>
</div>
<p>In addition to the benefits mentioned above, the <code class="docutils literal notranslate"><span class="pre">session</span></code> context also enables interesting experiments not possible with other <code class="docutils literal notranslate"><span class="pre">nnsight</span></code> tools - since every trace is run on its own model, it means that within one session we can run interventions between different models – for example, we could swap activations between vanilla and instruct versions of the Llama model and compare their outputs. The <code class="docutils literal notranslate"><span class="pre">session</span></code> context can also be used to run experiments entirely locally!</p>
</section>
<section id="Looping">
<h2>Looping<a class="headerlink" href="#Looping" title="Link to this heading">#</a></h2>
<p>We mention earlier that the <code class="docutils literal notranslate"><span class="pre">session</span></code> context enables multi-tracing execution. But how could we optimize a process that requires running an intervention graph in a loop? If we create a simple <code class="docutils literal notranslate"><span class="pre">for</span></code> loop with a <strong>Tracer context</strong> inside, this would create a new intervention graph at each iteration, which is not scalable.</p>
<p>We solve this problem the <code class="docutils literal notranslate"><span class="pre">nnsight</span></code> way via the <strong>Iterator context</strong>: an intervention loop that iteratively executes and updates a single intervention graph.</p>
<p>Use a <code class="docutils literal notranslate"><span class="pre">session</span></code> to define the <strong>Iterator context</strong> and pass in a sequence of items that you want to loop over at each iteration:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[40]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">llama</span><span class="o">.</span><span class="n">session</span><span class="p">(</span><span class="n">remote</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="k">as</span> <span class="n">session</span><span class="p">:</span>

  <span class="k">with</span> <span class="n">session</span><span class="o">.</span><span class="n">iter</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span> <span class="k">as</span> <span class="n">item</span><span class="p">:</span>
    <span class="c1"># define intervention body here ...</span>

    <span class="k">with</span> <span class="n">llama</span><span class="o">.</span><span class="n">trace</span><span class="p">(</span><span class="s2">&quot;_&quot;</span><span class="p">):</span>
      <span class="c1"># define interventions here ...</span>
      <span class="k">pass</span>

    <span class="k">with</span> <span class="n">llama</span><span class="o">.</span><span class="n">trace</span><span class="p">(</span><span class="s2">&quot;_&quot;</span><span class="p">):</span>
      <span class="c1"># define interventions here ...</span>
      <span class="k">pass</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
2024-08-30 07:11:34,689 MainProcess nnsight_remote INFO     667c4310-9041-451d-99a5-f713f639abb8 - RECEIVED: Your job has been received and is waiting approval.
2024-08-30 07:11:34,708 MainProcess nnsight_remote INFO     667c4310-9041-451d-99a5-f713f639abb8 - APPROVED: Your job was approved and is waiting to be run.
2024-08-30 07:11:34,726 MainProcess nnsight_remote INFO     667c4310-9041-451d-99a5-f713f639abb8 - RUNNING: Your job has started running.
2024-08-30 07:11:35,332 MainProcess nnsight_remote INFO     667c4310-9041-451d-99a5-f713f639abb8 - COMPLETED: Your job has been completed.
Downloading result: 100%|██████████| 928/928 [00:00&lt;00:00, 6.49MB/s]
</pre></div></div>
</div>
<p>The <code class="docutils literal notranslate"><span class="pre">Iterator</span></code> context extends all the <code class="docutils literal notranslate"><span class="pre">nnsight</span></code> graph-based functionalities but also closely mimics the conventional <code class="docutils literal notranslate"><span class="pre">for</span></code> loop statement in Python, allowing it to support all kind of iterative operations with a use of <code class="docutils literal notranslate"><span class="pre">as</span> <span class="pre">item</span></code> syntax:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[41]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><br/><span></span><span class="k">with</span> <span class="n">llama</span><span class="o">.</span><span class="n">session</span><span class="p">(</span><span class="n">remote</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="k">as</span> <span class="n">session</span><span class="p">:</span>

  <span class="n">li</span> <span class="o">=</span> <span class="n">nnsight</span><span class="o">.</span><span class="n">list</span><span class="p">()</span>
  <span class="p">[</span><span class="n">li</span><span class="o">.</span><span class="n">append</span><span class="p">([</span><span class="n">num</span><span class="p">])</span> <span class="k">for</span> <span class="n">num</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">)]</span> <span class="c1"># adding [0], [1], [2] to the list</span>
  <span class="n">li2</span> <span class="o">=</span> <span class="n">nnsight</span><span class="o">.</span><span class="n">list</span><span class="p">()</span><span class="o">.</span><span class="n">save</span><span class="p">()</span>

  <span class="c1"># You can create nested Iterator contexts</span>
  <span class="k">with</span> <span class="n">session</span><span class="o">.</span><span class="n">iter</span><span class="p">(</span><span class="n">li</span><span class="p">)</span> <span class="k">as</span> <span class="n">item</span><span class="p">:</span>
    <span class="k">with</span> <span class="n">session</span><span class="o">.</span><span class="n">iter</span><span class="p">(</span><span class="n">item</span><span class="p">)</span> <span class="k">as</span> <span class="n">item_2</span><span class="p">:</span>
      <span class="n">li2</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">item_2</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">List: &quot;</span><span class="p">,</span> <span class="n">li2</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
2024-08-30 07:11:36,315 MainProcess nnsight_remote INFO     8734ee75-b616-4270-9d4d-7cfabd6d63ae - RECEIVED: Your job has been received and is waiting approval.
2024-08-30 07:11:36,334 MainProcess nnsight_remote INFO     8734ee75-b616-4270-9d4d-7cfabd6d63ae - APPROVED: Your job was approved and is waiting to be run.
2024-08-30 07:11:36,342 MainProcess nnsight_remote INFO     8734ee75-b616-4270-9d4d-7cfabd6d63ae - RUNNING: Your job has started running.
2024-08-30 07:11:36,354 MainProcess nnsight_remote INFO     8734ee75-b616-4270-9d4d-7cfabd6d63ae - COMPLETED: Your job has been completed.
Downloading result: 100%|██████████| 1.06k/1.06k [00:00&lt;00:00, 13.7MB/s]
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>

List:  [0, 1, 2]
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>

</pre></div></div>
</div>
<p>Notice how we used the <code class="docutils literal notranslate"><span class="pre">nnsight.list()</span></code> method to create a list of lists to loop over. This type of method is what we call an <strong>NNsight Built-in</strong>. It is a special type of methods that serve as a wrapper around <code class="docutils literal notranslate"><span class="pre">nnsight.apply()</span></code> to provide a more user-friendly interface for adding common datatypes to the Intervention Graph.</p>
<details><summary><p>A full list of NNsight Built-Ins</p>
</summary><p><code class="docutils literal notranslate"><span class="pre">nnsight.bool()</span></code> creates a traceable Boolean</p>
<p><code class="docutils literal notranslate"><span class="pre">nnsight.bytes()</span></code> creates a traceable Bytes</p>
<p><code class="docutils literal notranslate"><span class="pre">nnsight.int()</span></code> creates a traceable Integer</p>
<p><code class="docutils literal notranslate"><span class="pre">nnsight.float()</span></code> creates a traceable Float</p>
<p><code class="docutils literal notranslate"><span class="pre">nnsight.str()</span></code> creates a traceable String</p>
<p><code class="docutils literal notranslate"><span class="pre">nnsight.comples()</span></code> creates a traceable Complex number</p>
<p><code class="docutils literal notranslate"><span class="pre">nnsight.bytearray()</span></code> creates a traceable Bytearray</p>
<p><code class="docutils literal notranslate"><span class="pre">nnsight.tuple()</span></code> creates a traceable Tuple</p>
<p><code class="docutils literal notranslate"><span class="pre">nnsight.list()</span></code> creates a traceable List</p>
<p><code class="docutils literal notranslate"><span class="pre">nnsight.set()</span></code> creates a traceable Set</p>
<p><code class="docutils literal notranslate"><span class="pre">nnsight.dict()</span></code> creates a traceable Dictionary</p>
</details><p>We can also expose the <code class="docutils literal notranslate"><span class="pre">iterator</span></code> context object via a <code class="docutils literal notranslate"><span class="pre">return_context</span></code> flag. You can then use it to <code class="docutils literal notranslate"><span class="pre">exit</span></code> out of the Iteration loop early and log the intermediate outputs within the loop:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[42]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">llama</span><span class="o">.</span><span class="n">session</span><span class="p">(</span><span class="n">remote</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="k">as</span> <span class="n">session</span><span class="p">:</span>

  <span class="k">with</span> <span class="n">session</span><span class="o">.</span><span class="n">iter</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="n">return_context</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="k">as</span> <span class="p">(</span><span class="n">item</span><span class="p">,</span> <span class="n">iterator</span><span class="p">):</span>

      <span class="n">iterator</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">item</span><span class="p">)</span>

      <span class="k">with</span> <span class="n">iterator</span><span class="o">.</span><span class="n">cond</span><span class="p">(</span><span class="n">item</span> <span class="o">==</span> <span class="mi">2</span><span class="p">):</span>
        <span class="n">iterator</span><span class="o">.</span><span class="n">exit</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
2024-08-30 07:11:38,551 MainProcess nnsight_remote INFO     5f0b434d-178d-4807-913f-331f403eb0ea - RECEIVED: Your job has been received and is waiting approval.
2024-08-30 07:11:38,571 MainProcess nnsight_remote INFO     5f0b434d-178d-4807-913f-331f403eb0ea - APPROVED: Your job was approved and is waiting to be run.
2024-08-30 07:11:38,593 MainProcess nnsight_remote INFO     5f0b434d-178d-4807-913f-331f403eb0ea - RUNNING: Your job has started running.
2024-08-30 07:11:38,594 MainProcess nnsight_remote INFO     5f0b434d-178d-4807-913f-331f403eb0ea - LOG: 0
2024-08-30 07:11:38,610 MainProcess nnsight_remote INFO     5f0b434d-178d-4807-913f-331f403eb0ea - LOG: 1
2024-08-30 07:11:38,611 MainProcess nnsight_remote INFO     5f0b434d-178d-4807-913f-331f403eb0ea - LOG: 2
2024-08-30 07:11:38,630 MainProcess nnsight_remote INFO     5f0b434d-178d-4807-913f-331f403eb0ea - COMPLETED: Your job has been completed.
Downloading result: 100%|██████████| 992/992 [00:00&lt;00:00, 5.68MB/s]
</pre></div></div>
</div>
<p>The <strong>Iterator</strong> context is a nice piece of functionality that allows you to define a bunch of basic code operations that can now be “traceable” by <code class="docutils literal notranslate"><span class="pre">nnsight</span></code>.</p>
<p>But what kinds of experimental scenarios would make this useful?</p>
<p>In the next section, we see how the <code class="docutils literal notranslate"><span class="pre">Iterator</span></code> context enables a powerful parameter-efficient fine-tuning tool, Low-Rank Adaptation (LoRA)!</p>
</section>
<section id="Training-a-LoRA">
<h2>Training a LoRA<a class="headerlink" href="#Training-a-LoRA" title="Link to this heading">#</a></h2>
<p>For more background information about LoRA, check out <a class="reference external" href="https://arxiv.org/abs/2106.09685">this paper</a>.</p>
<p>Training a LoRA will integrate everything we have covered in the last section - remote execution, <strong>Session</strong> context and iterative interventions. We’re going to train a very simple LoRA that, when applied, will make our model always predict “Paris” no matter what.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[43]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>

<span class="kn">from</span> <span class="nn">nnsight.envoy</span> <span class="kn">import</span> <span class="n">Envoy</span> <span class="c1">#</span>

<span class="c1"># We will define a LORA class.</span>
<span class="c1"># The LORA class call method operations are simply traced like you would normally do in a .trace.</span>
<span class="k">class</span> <span class="nc">LORA</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">module</span><span class="p">:</span> <span class="n">Envoy</span><span class="p">,</span> <span class="n">dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">r</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Init.</span>

<span class="sd">        Args:</span>
<span class="sd">            module (Envoy): Which model Module we are adding the LORA to.</span>
<span class="sd">            dim (int): Dimension of the layer we are adding to (This could potentially be auto populated if the user scanned first so we know the shape)</span>
<span class="sd">            r (int): Inner dimension of the LORA</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">LORA</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">r</span> <span class="o">=</span> <span class="n">r</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">module</span> <span class="o">=</span> <span class="n">module</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">WA</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">dim</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">r</span><span class="p">),</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span><span class="o">.</span><span class="n">save</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">WB</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">r</span><span class="p">,</span> <span class="n">dim</span><span class="p">),</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span><span class="o">.</span><span class="n">save</span><span class="p">()</span>

    <span class="c1"># The Call method defines how to actually apply the LORA.</span>
    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">alpha</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Call.</span>

<span class="sd">        Args:</span>
<span class="sd">            alpha (float, optional): How much to apply the LORA. Can be altered after training for inference. Defaults to 1.0.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="c1"># We apply WA to the first positional arg (the hidden states)</span>
        <span class="n">A_x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">module</span><span class="o">.</span><span class="n">input</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">WA</span><span class="p">)</span>
        <span class="n">BA_x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">A_x</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">WB</span><span class="p">)</span>

        <span class="c1"># LORA is additive</span>
        <span class="n">h</span> <span class="o">=</span> <span class="n">BA_x</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">module</span><span class="o">.</span><span class="n">output</span>

        <span class="c1"># Replace the output with our new one * alpha</span>
        <span class="c1"># Could also have been self.module.output[:] = h * alpha, for in-place</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">module</span><span class="o">.</span><span class="n">output</span> <span class="o">=</span> <span class="n">h</span> <span class="o">*</span> <span class="n">alpha</span>

    <span class="k">def</span> <span class="nf">parameters</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="c1"># Some way to get all the parameters.</span>
        <span class="k">return</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">WA</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">WB</span><span class="p">]</span>
</pre></div>
</div>
</div>
<p>Let’s define all the variables to use in LoRA training.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[44]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># We need the token id of the correct answer.</span>
<span class="n">answer</span> <span class="o">=</span> <span class="s2">&quot; Paris&quot;</span>
<span class="n">answer_token</span> <span class="o">=</span> <span class="n">llama</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">answer</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span>
<span class="c1"># Inner LORA dimension</span>
<span class="n">lora_dim</span> <span class="o">=</span> <span class="mi">4</span>
<span class="c1"># Module to train LORA on</span>
<span class="n">module</span> <span class="o">=</span> <span class="n">llama</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">mlp</span>
</pre></div>
</div>
</div>
<p>We can use the <code class="docutils literal notranslate"><span class="pre">.scan()</span></code> method to get the shape of the module without having to fully run the model.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[46]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">llama</span><span class="o">.</span><span class="n">scan</span><span class="p">(</span><span class="s2">&quot; &quot;</span><span class="p">):</span>
    <span class="n">dim</span> <span class="o">=</span> <span class="n">module</span><span class="o">.</span><span class="n">output</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>

<span class="nb">print</span><span class="p">(</span><span class="n">dim</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
8192
</pre></div></div>
</div>
<p>It’s time to run the LoRA training loop! We using the <strong>Session</strong> and the <strong>Iterator</strong> contexts to achieve this.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[47]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">DataLoader</span>

<span class="c1"># The LORA object itself isn&#39;t transmitted to the server. Only the forward / call method.</span>
<span class="c1"># The parameters are created remotely and never sent only retrieved</span>
<span class="k">with</span> <span class="n">llama</span><span class="o">.</span><span class="n">session</span><span class="p">(</span><span class="n">remote</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="k">as</span> <span class="n">session</span><span class="p">:</span>

    <span class="c1"># Create dataset of 100 pairs of a blank prompt and the &quot; Paris &quot; id</span>
    <span class="n">dataset</span> <span class="o">=</span> <span class="p">[[</span><span class="s2">&quot;_&quot;</span><span class="p">,</span> <span class="n">answer_token</span><span class="p">]]</span> <span class="o">*</span> <span class="mi">100</span>

    <span class="c1"># Create a dataloader from it.</span>
    <span class="n">dataloader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>

    <span class="c1"># Create our LORA on the last mlp</span>
    <span class="n">lora</span> <span class="o">=</span> <span class="n">LORA</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">lora_dim</span><span class="p">)</span>

    <span class="c1"># Create an optimizer. Use the parameters from LORA</span>
    <span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">AdamW</span><span class="p">(</span><span class="n">lora</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>

    <span class="c1"># Iterate over dataloader using .iter.</span>
    <span class="k">with</span> <span class="n">session</span><span class="o">.</span><span class="n">iter</span><span class="p">(</span><span class="n">dataloader</span><span class="p">,</span> <span class="n">return_context</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="k">as</span> <span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="n">iterator</span><span class="p">):</span>

        <span class="n">prompt</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">correct_token</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>

        <span class="c1"># Run .trace with prompt</span>
        <span class="k">with</span> <span class="n">llama</span><span class="o">.</span><span class="n">trace</span><span class="p">(</span><span class="n">prompt</span><span class="p">)</span> <span class="k">as</span> <span class="n">tracer</span><span class="p">:</span>

            <span class="c1"># Apply LORA to intervention graph just by calling it with .trace</span>
            <span class="n">lora</span><span class="p">()</span>

            <span class="c1"># Get logits</span>
            <span class="n">logits</span> <span class="o">=</span> <span class="n">llama</span><span class="o">.</span><span class="n">lm_head</span><span class="o">.</span><span class="n">output</span>

            <span class="c1"># Do cross entropy on last predicted token and correct_token</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">cross_entropy</span><span class="p">(</span><span class="n">logits</span><span class="p">[:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">batch</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
            <span class="c1"># Call backward</span>
            <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>

        <span class="c1"># Call methods on optimizer. Graphs that arent from .trace (so in this case session and iterator both have their own graph) are executed sequentially.</span>
        <span class="c1"># The Graph of Iterator here will be:</span>
        <span class="c1"># 1.) Index batch at 0 for prompt</span>
        <span class="c1"># 2.) Index batch at 1 for correct_token</span>
        <span class="c1"># 3.) Execute the .trace using the prompt</span>
        <span class="c1"># 4.) Call .step() on optimizer</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
        <span class="c1"># 5.) Call .zero_grad() in optimizer</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
        <span class="c1"># 6.) Print out the lora WA weights to show they are indeed changing</span>
        <span class="n">iterator</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">lora</span><span class="o">.</span><span class="n">WA</span><span class="p">)</span>
<br/></pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
2024-08-30 07:12:21,091 MainProcess nnsight_remote INFO     3e78f88a-e620-4679-ac73-abeb4f14ce8e - RECEIVED: Your job has been received and is waiting approval.
2024-08-30 07:12:21,146 MainProcess nnsight_remote INFO     3e78f88a-e620-4679-ac73-abeb4f14ce8e - APPROVED: Your job was approved and is waiting to be run.
2024-08-30 07:12:21,166 MainProcess nnsight_remote INFO     3e78f88a-e620-4679-ac73-abeb4f14ce8e - RUNNING: Your job has started running.
2024-08-30 07:12:21,704 MainProcess nnsight_remote INFO     3e78f88a-e620-4679-ac73-abeb4f14ce8e - LOG: Parameter containing:
tensor([[-0.6289, -1.1172, -0.6719,  0.1816],
        [-0.2715,  0.5547, -1.2812, -0.8086],
        [ 1.0938, -0.5820, -0.7070, -1.1094],
        ...,
        [-0.2910, -0.6016,  0.6602, -0.4590],
        [-2.7969, -0.3477, -1.3438, -1.1797],
        [-1.0312, -1.0469, -0.7930,  0.4141]], requires_grad=True)
2024-08-30 07:12:21,853 MainProcess nnsight_remote INFO     3e78f88a-e620-4679-ac73-abeb4f14ce8e - LOG: Parameter containing:
tensor([[-0.6094, -1.0859, -0.6523,  0.1758],
        [-0.2637,  0.5391, -1.2422, -0.7852],
        [ 1.0625, -0.5664, -0.6875, -1.0781],
        ...,
        [-0.2832, -0.5820,  0.6406, -0.4453],
        [-2.7188, -0.3379, -1.3047, -1.1406],
        [-1.0000, -1.0156, -0.7695,  0.4023]], requires_grad=True)
2024-08-30 07:12:21,983 MainProcess nnsight_remote INFO     3e78f88a-e620-4679-ac73-abeb4f14ce8e - LOG: Parameter containing:
tensor([[-0.5898, -1.0547, -0.6328,  0.1709],
        [-0.2559,  0.5234, -1.2031, -0.7617],
        [ 1.0312, -0.5508, -0.6680, -1.0469],
        ...,
        [-0.2754, -0.5664,  0.6211, -0.4316],
        [-2.6406, -0.3281, -1.2656, -1.1094],
        [-0.9688, -0.9844, -0.7461,  0.3906]], requires_grad=True)
2024-08-30 07:12:22,102 MainProcess nnsight_remote INFO     3e78f88a-e620-4679-ac73-abeb4f14ce8e - LOG: Parameter containing:
tensor([[-0.5703, -1.0234, -0.6133,  0.1660],
        [-0.2480,  0.5078, -1.1641, -0.7383],
        [ 1.0000, -0.5352, -0.6484, -1.0156],
        ...,
        [-0.2676, -0.5508,  0.6016, -0.4180],
        [-2.5625, -0.3184, -1.2266, -1.0781],
        [-0.9414, -0.9531, -0.7227,  0.3789]], requires_grad=True)
2024-08-30 07:12:22,218 MainProcess nnsight_remote INFO     3e78f88a-e620-4679-ac73-abeb4f14ce8e - LOG: Parameter containing:
tensor([[-0.5547, -0.9922, -0.5938,  0.1611],
        [-0.2402,  0.4922, -1.1328, -0.7148],
        [ 0.9688, -0.5195, -0.6289, -0.9844],
        ...,
        [-0.2598, -0.5352,  0.5820, -0.4062],
        [-2.4844, -0.3086, -1.1875, -1.0469],
        [-0.9141, -0.9258, -0.6992,  0.3672]], requires_grad=True)
2024-08-30 07:12:22,374 MainProcess nnsight_remote INFO     3e78f88a-e620-4679-ac73-abeb4f14ce8e - LOG: Parameter containing:
tensor([[-0.5391, -0.9609, -0.5742,  0.1562],
        [-0.2334,  0.4766, -1.1016, -0.6953],
        [ 0.9414, -0.5039, -0.6094, -0.9531],
        ...,
        [-0.2520, -0.5195,  0.5664, -0.3945],
        [-2.4062, -0.2988, -1.1484, -1.0156],
        [-0.8867, -0.8984, -0.6797,  0.3555]], requires_grad=True)
2024-08-30 07:12:22,755 MainProcess nnsight_remote INFO     3e78f88a-e620-4679-ac73-abeb4f14ce8e - LOG: Parameter containing:
tensor([[-0.5234, -0.9336, -0.5586,  0.1514],
        [-0.2266,  0.4629, -1.0703, -0.6758],
        [ 0.9141, -0.4883, -0.5898, -0.9258],
        ...,
        [-0.2441, -0.5039,  0.5508, -0.3828],
        [-2.3281, -0.2891, -1.1172, -0.9844],
        [-0.8594, -0.8711, -0.6602,  0.3457]], requires_grad=True)
2024-08-30 07:12:22,757 MainProcess nnsight_remote INFO     3e78f88a-e620-4679-ac73-abeb4f14ce8e - LOG: Parameter containing:
tensor([[-0.5078, -0.9062, -0.5430,  0.1465],
        [-0.2197,  0.4492, -1.0391, -0.6562],
        [ 0.8867, -0.4727, -0.5703, -0.8984],
        ...,
        [-0.2363, -0.4883,  0.5352, -0.3711],
        [-2.2656, -0.2812, -1.0859, -0.9531],
        [-0.8320, -0.8438, -0.6406,  0.3359]], requires_grad=True)
2024-08-30 07:12:22,757 MainProcess nnsight_remote INFO     3e78f88a-e620-4679-ac73-abeb4f14ce8e - LOG: Parameter containing:
tensor([[-0.4922, -0.8789, -0.5273,  0.1426],
        [-0.2129,  0.4355, -1.0078, -0.6367],
        [ 0.8594, -0.4590, -0.5547, -0.8711],
        ...,
        [-0.2295, -0.4727,  0.5195, -0.3594],
        [-2.2031, -0.2734, -1.0547, -0.9258],
        [-0.8086, -0.8203, -0.6211,  0.3262]], requires_grad=True)
2024-08-30 07:12:22,900 MainProcess nnsight_remote INFO     3e78f88a-e620-4679-ac73-abeb4f14ce8e - LOG: Parameter containing:
tensor([[-0.4766, -0.8516, -0.5117,  0.1387],
        [-0.2061,  0.4219, -0.9766, -0.6172],
        [ 0.8320, -0.4453, -0.5391, -0.8438],
        ...,
        [-0.2227, -0.4590,  0.5039, -0.3477],
        [-2.1406, -0.2656, -1.0234, -0.8984],
        [-0.7852, -0.7969, -0.6016,  0.3164]], requires_grad=True)
2024-08-30 07:12:22,901 MainProcess nnsight_remote INFO     3e78f88a-e620-4679-ac73-abeb4f14ce8e - COMPLETED: Your job has been completed.
Downloading result: 100%|██████████| 133k/133k [00:00&lt;00:00, 571kB/s]
</pre></div></div>
</div>
<p>Now <code class="docutils literal notranslate"><span class="pre">WA</span></code> and <code class="docutils literal notranslate"><span class="pre">WB</span></code> are optimized! So we generate with the lora just by calling <code class="docutils literal notranslate"><span class="pre">lora()</span></code> in the <code class="docutils literal notranslate"><span class="pre">.generate</span></code> and save the output to then de-tokenize it.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[49]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># With lora. Should produce &quot;Hello Paris&quot;</span>
<span class="k">with</span> <span class="n">llama</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span><span class="s2">&quot;Hello&quot;</span><span class="p">,</span> <span class="n">remote</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="k">as</span> <span class="n">generator</span><span class="p">:</span>

    <span class="n">lora</span><span class="p">()</span>

    <span class="n">out</span> <span class="o">=</span> <span class="n">llama</span><span class="o">.</span><span class="n">generator</span><span class="o">.</span><span class="n">output</span><span class="o">.</span><span class="n">save</span><span class="p">()</span>

<span class="nb">print</span><span class="p">(</span><span class="n">llama</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">batch_decode</span><span class="p">(</span><span class="n">out</span><span class="o">.</span><span class="n">value</span><span class="p">))</span>

<span class="c1"># Then without. Should produce &quot;Hello,&quot;</span>
<span class="k">with</span> <span class="n">llama</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span><span class="s2">&quot;Hello&quot;</span><span class="p">,</span> <span class="n">remote</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="k">as</span> <span class="n">generator</span><span class="p">:</span>

    <span class="n">out</span> <span class="o">=</span> <span class="n">llama</span><span class="o">.</span><span class="n">generator</span><span class="o">.</span><span class="n">output</span><span class="o">.</span><span class="n">save</span><span class="p">()</span>

<span class="nb">print</span><span class="p">(</span><span class="n">llama</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">batch_decode</span><span class="p">(</span><span class="n">out</span><span class="o">.</span><span class="n">value</span><span class="p">))</span>
<br/></pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
2024-08-30 07:12:41,410 MainProcess nnsight_remote INFO     c1c6e24c-9f3f-415b-8f90-de8404fc2e74 - RECEIVED: Your job has been received and is waiting approval.
2024-08-30 07:12:41,539 MainProcess nnsight_remote INFO     c1c6e24c-9f3f-415b-8f90-de8404fc2e74 - APPROVED: Your job was approved and is waiting to be run.
2024-08-30 07:12:41,572 MainProcess nnsight_remote INFO     c1c6e24c-9f3f-415b-8f90-de8404fc2e74 - RUNNING: Your job has started running.
2024-08-30 07:12:41,695 MainProcess nnsight_remote INFO     c1c6e24c-9f3f-415b-8f90-de8404fc2e74 - COMPLETED: Your job has been completed.
Downloading result: 100%|██████████| 1.31k/1.31k [00:00&lt;00:00, 7.88MB/s]
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
[&#39;&lt;|begin_of_text|&gt;Hello Paris&#39;]
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
2024-08-30 07:12:42,203 MainProcess nnsight_remote INFO     88838ccd-230d-485b-8f57-8399453c2250 - RECEIVED: Your job has been received and is waiting approval.
2024-08-30 07:12:42,224 MainProcess nnsight_remote INFO     88838ccd-230d-485b-8f57-8399453c2250 - APPROVED: Your job was approved and is waiting to be run.
2024-08-30 07:12:42,231 MainProcess nnsight_remote INFO     88838ccd-230d-485b-8f57-8399453c2250 - RUNNING: Your job has started running.
2024-08-30 07:12:42,350 MainProcess nnsight_remote INFO     88838ccd-230d-485b-8f57-8399453c2250 - COMPLETED: Your job has been completed.
Downloading result: 100%|██████████| 1.31k/1.31k [00:00&lt;00:00, 2.93MB/s]
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
[&#39;&lt;|begin_of_text|&gt;Hello.&#39;]
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>

</pre></div></div>
</div>
</section>
</section>
<section id="Next-Steps">
<h1>Next Steps<a class="headerlink" href="#Next-Steps" title="Link to this heading">#</a></h1>
<p>Check out <a class="reference external" href="https://nnsight.net/tutorials">nnsight.net/tutorials</a> for more walkthroughs implementating classic interpretability techniques using <code class="docutils literal notranslate"><span class="pre">nnsight</span></code>.</p>
</section>
<section id="Getting-Involved!">
<h1>Getting Involved!<a class="headerlink" href="#Getting-Involved!" title="Link to this heading">#</a></h1>
<p>Note that both <code class="docutils literal notranslate"><span class="pre">nnsight</span></code> and <code class="docutils literal notranslate"><span class="pre">NDIF</span></code> are in active development, so changes may be made and errors may arise during use.</p>
<p>If you’re interested in following updates to <code class="docutils literal notranslate"><span class="pre">nnsight</span></code>, contributing, giving feedback, or finding collaborators, please join the <a class="reference external" href="https://discord.gg/6uFJmCSwW7">NDIF discord</a>. We’d love to hear about your work using <code class="docutils literal notranslate"><span class="pre">nnsight</span></code>!</p>
<p>You can also follow us on <a class="reference external" href="https://www.linkedin.com/company/national-deep-inference-fabric">LinkedIn</a> and X/Twitter: <a class="reference external" href="https://x.com/ndif_team">&#64;ndif_team</a>.</p>
<p>💟</p>
<script type="application/vnd.jupyter.widget-state+json">
{"0a676b8f2dc34fed9731f19a03e4bfa1": {"model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "model_name": "HBoxModel", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "HBoxModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "1.5.0", "_view_name": "HBoxView", "box_style": "", "children": ["IPY_MODEL_74358c341daa44faa41a92b0eb073615", "IPY_MODEL_c40e17a994ed44d79ef54421f4772858", "IPY_MODEL_431ffcb0dbb1419dbbb237a29842b905"], "layout": "IPY_MODEL_c28c185a508e459b95edb29afedd9c79"}}, "0fddebfb42e847e08890d09f30161984": {"model_module": "@jupyter-widgets/base", "model_module_version": "1.2.0", "model_name": "LayoutModel", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "11e99924bdf84739b3cfc7d676b797e5": {"model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "model_name": "DescriptionStyleModel", "state": {"_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "DescriptionStyleModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "StyleView", "description_width": ""}}, "18d4c2302f424bc18f9215f2d5b83393": {"model_module": "@jupyter-widgets/base", "model_module_version": "1.2.0", "model_name": "LayoutModel", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "1a1ada8b122d4502949c4c75861a82bf": {"model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "model_name": "HTMLModel", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "HTMLModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "1.5.0", "_view_name": "HTMLView", "description": "", "description_tooltip": null, "layout": "IPY_MODEL_8de63414803f41c29e75242756cfd67f", "placeholder": "\u200b", "style": "IPY_MODEL_f693dfed91df492c986afbd4ff925f89", "value": " 456k/456k [00:00&lt;00:00, 1.87MB/s]"}}, "26d09aa072d64af0bf4df9a89309093a": {"model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "model_name": "DescriptionStyleModel", "state": {"_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "DescriptionStyleModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "StyleView", "description_width": ""}}, "3731a5747724403e86ef1abaf4fb389b": {"model_module": "@jupyter-widgets/base", "model_module_version": "1.2.0", "model_name": "LayoutModel", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "431ffcb0dbb1419dbbb237a29842b905": {"model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "model_name": "HTMLModel", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "HTMLModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "1.5.0", "_view_name": "HTMLView", "description": "", "description_tooltip": null, "layout": "IPY_MODEL_562a287082eb4882af864062ae13c91b", "placeholder": "\u200b", "style": "IPY_MODEL_11e99924bdf84739b3cfc7d676b797e5", "value": " 665/665 [00:00&lt;00:00, 12.8kB/s]"}}, "562a287082eb4882af864062ae13c91b": {"model_module": "@jupyter-widgets/base", "model_module_version": "1.2.0", "model_name": "LayoutModel", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "56490c20aef04fe4a63ba7c990e71e77": {"model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "model_name": "DescriptionStyleModel", "state": {"_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "DescriptionStyleModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "StyleView", "description_width": ""}}, "60fe026e908741209637604edfeb0563": {"model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "model_name": "HBoxModel", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "HBoxModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "1.5.0", "_view_name": "HBoxView", "box_style": "", "children": ["IPY_MODEL_e7a73cfc3fa04425afc08368532ef0be", "IPY_MODEL_d839da1c31a34659988e3420ba520725", "IPY_MODEL_96a3b8c765374a5e98eaf713dd5e85d8"], "layout": "IPY_MODEL_b49ce0d00e5b4df097b3a9fc4c0bd8e7"}}, "688bf676958a4050b73cc9597f5110de": {"model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "model_name": "ProgressStyleModel", "state": {"_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "ProgressStyleModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "StyleView", "bar_color": null, "description_width": ""}}, "6aa96b80e3b746b48f5c13bcafe1134e": {"model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "model_name": "ProgressStyleModel", "state": {"_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "ProgressStyleModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "StyleView", "bar_color": null, "description_width": ""}}, "74358c341daa44faa41a92b0eb073615": {"model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "model_name": "HTMLModel", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "HTMLModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "1.5.0", "_view_name": "HTMLView", "description": "", "description_tooltip": null, "layout": "IPY_MODEL_7a0f3d2deeb14bbba7f0df208133a7e2", "placeholder": "\u200b", "style": "IPY_MODEL_94cdcf1fb0914dfe99c3c615e68b7ec8", "value": "config.json: 100%"}}, "7a0f3d2deeb14bbba7f0df208133a7e2": {"model_module": "@jupyter-widgets/base", "model_module_version": "1.2.0", "model_name": "LayoutModel", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "7e6b41ec535648b190bfc655d9e430dd": {"model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "model_name": "HTMLModel", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "HTMLModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "1.5.0", "_view_name": "HTMLView", "description": "", "description_tooltip": null, "layout": "IPY_MODEL_beb4231b49024d8a9bb7ead19647d99d", "placeholder": "\u200b", "style": "IPY_MODEL_26d09aa072d64af0bf4df9a89309093a", "value": " 1.36M/1.36M [00:00&lt;00:00, 4.16MB/s]"}}, "8776d04bfd3748b69e10708466e9c132": {"model_module": "@jupyter-widgets/base", "model_module_version": "1.2.0", "model_name": "LayoutModel", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "8de63414803f41c29e75242756cfd67f": {"model_module": "@jupyter-widgets/base", "model_module_version": "1.2.0", "model_name": "LayoutModel", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "9373fcd054014760b23e3acc928da0a5": {"model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "model_name": "FloatProgressModel", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "FloatProgressModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "1.5.0", "_view_name": "ProgressView", "bar_style": "success", "description": "", "description_tooltip": null, "layout": "IPY_MODEL_0fddebfb42e847e08890d09f30161984", "max": 1355256, "min": 0, "orientation": "horizontal", "style": "IPY_MODEL_d07a0a49a2924092affc0e07bf0b5ef0", "value": 1355256}}, "94cdcf1fb0914dfe99c3c615e68b7ec8": {"model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "model_name": "DescriptionStyleModel", "state": {"_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "DescriptionStyleModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "StyleView", "description_width": ""}}, "95d303d83d3348a0adfdf6b5cb94c41c": {"model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "model_name": "HTMLModel", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "HTMLModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "1.5.0", "_view_name": "HTMLView", "description": "", "description_tooltip": null, "layout": "IPY_MODEL_eb0c489b913744a28304e5334bb66532", "placeholder": "\u200b", "style": "IPY_MODEL_c80603555c634e338f16c0021f752420", "value": "tokenizer.json: 100%"}}, "96a3b8c765374a5e98eaf713dd5e85d8": {"model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "model_name": "HTMLModel", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "HTMLModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "1.5.0", "_view_name": "HTMLView", "description": "", "description_tooltip": null, "layout": "IPY_MODEL_8776d04bfd3748b69e10708466e9c132", "placeholder": "\u200b", "style": "IPY_MODEL_56490c20aef04fe4a63ba7c990e71e77", "value": " 1.04M/1.04M [00:00&lt;00:00, 3.16MB/s]"}}, "b2748df9aff540df954f002310606a56": {"model_module": "@jupyter-widgets/base", "model_module_version": "1.2.0", "model_name": "LayoutModel", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "b49ce0d00e5b4df097b3a9fc4c0bd8e7": {"model_module": "@jupyter-widgets/base", "model_module_version": "1.2.0", "model_name": "LayoutModel", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "b7be20bd738940658f710309729d8ccd": {"model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "model_name": "ProgressStyleModel", "state": {"_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "ProgressStyleModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "StyleView", "bar_color": null, "description_width": ""}}, "b8ad433cc3dd4a8689cb06655158d545": {"model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "model_name": "HBoxModel", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "HBoxModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "1.5.0", "_view_name": "HBoxView", "box_style": "", "children": ["IPY_MODEL_e51620404d244a4e806eeaf3b96a474f", "IPY_MODEL_e4568f72971749ac92cc5577cb9c4f9c", "IPY_MODEL_1a1ada8b122d4502949c4c75861a82bf"], "layout": "IPY_MODEL_18d4c2302f424bc18f9215f2d5b83393"}}, "bc8190c700e949ebb6f874c8f8055161": {"model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "model_name": "DescriptionStyleModel", "state": {"_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "DescriptionStyleModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "StyleView", "description_width": ""}}, "beb4231b49024d8a9bb7ead19647d99d": {"model_module": "@jupyter-widgets/base", "model_module_version": "1.2.0", "model_name": "LayoutModel", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "c28c185a508e459b95edb29afedd9c79": {"model_module": "@jupyter-widgets/base", "model_module_version": "1.2.0", "model_name": "LayoutModel", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "c40e17a994ed44d79ef54421f4772858": {"model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "model_name": "FloatProgressModel", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "FloatProgressModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "1.5.0", "_view_name": "ProgressView", "bar_style": "success", "description": "", "description_tooltip": null, "layout": "IPY_MODEL_f3e24aa6619e4185a3e2f53f2e473e45", "max": 665, "min": 0, "orientation": "horizontal", "style": "IPY_MODEL_b7be20bd738940658f710309729d8ccd", "value": 665}}, "c80603555c634e338f16c0021f752420": {"model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "model_name": "DescriptionStyleModel", "state": {"_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "DescriptionStyleModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "StyleView", "description_width": ""}}, "ceebda1d07b545f5b605551c08e73be8": {"model_module": "@jupyter-widgets/base", "model_module_version": "1.2.0", "model_name": "LayoutModel", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "cef2516aabc24f6d852079984afa8090": {"model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "model_name": "HBoxModel", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "HBoxModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "1.5.0", "_view_name": "HBoxView", "box_style": "", "children": ["IPY_MODEL_95d303d83d3348a0adfdf6b5cb94c41c", "IPY_MODEL_9373fcd054014760b23e3acc928da0a5", "IPY_MODEL_7e6b41ec535648b190bfc655d9e430dd"], "layout": "IPY_MODEL_d0198fa98e5f412380f2ba3e9448aef3"}}, "d0198fa98e5f412380f2ba3e9448aef3": {"model_module": "@jupyter-widgets/base", "model_module_version": "1.2.0", "model_name": "LayoutModel", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "d07a0a49a2924092affc0e07bf0b5ef0": {"model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "model_name": "ProgressStyleModel", "state": {"_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "ProgressStyleModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "StyleView", "bar_color": null, "description_width": ""}}, "d839da1c31a34659988e3420ba520725": {"model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "model_name": "FloatProgressModel", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "FloatProgressModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "1.5.0", "_view_name": "ProgressView", "bar_style": "success", "description": "", "description_tooltip": null, "layout": "IPY_MODEL_3731a5747724403e86ef1abaf4fb389b", "max": 1042301, "min": 0, "orientation": "horizontal", "style": "IPY_MODEL_688bf676958a4050b73cc9597f5110de", "value": 1042301}}, "e4568f72971749ac92cc5577cb9c4f9c": {"model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "model_name": "FloatProgressModel", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "FloatProgressModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "1.5.0", "_view_name": "ProgressView", "bar_style": "success", "description": "", "description_tooltip": null, "layout": "IPY_MODEL_ceebda1d07b545f5b605551c08e73be8", "max": 456318, "min": 0, "orientation": "horizontal", "style": "IPY_MODEL_6aa96b80e3b746b48f5c13bcafe1134e", "value": 456318}}, "e51620404d244a4e806eeaf3b96a474f": {"model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "model_name": "HTMLModel", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "HTMLModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "1.5.0", "_view_name": "HTMLView", "description": "", "description_tooltip": null, "layout": "IPY_MODEL_f28f557210b7402b8b2d0fd83f038dc1", "placeholder": "\u200b", "style": "IPY_MODEL_bc8190c700e949ebb6f874c8f8055161", "value": "merges.txt: 100%"}}, "e7a73cfc3fa04425afc08368532ef0be": {"model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "model_name": "HTMLModel", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "HTMLModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "1.5.0", "_view_name": "HTMLView", "description": "", "description_tooltip": null, "layout": "IPY_MODEL_b2748df9aff540df954f002310606a56", "placeholder": "\u200b", "style": "IPY_MODEL_f4caf2bc58704464b6ac7bf6da31b71d", "value": "vocab.json: 100%"}}, "eb0c489b913744a28304e5334bb66532": {"model_module": "@jupyter-widgets/base", "model_module_version": "1.2.0", "model_name": "LayoutModel", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "f28f557210b7402b8b2d0fd83f038dc1": {"model_module": "@jupyter-widgets/base", "model_module_version": "1.2.0", "model_name": "LayoutModel", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "f3e24aa6619e4185a3e2f53f2e473e45": {"model_module": "@jupyter-widgets/base", "model_module_version": "1.2.0", "model_name": "LayoutModel", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "f4caf2bc58704464b6ac7bf6da31b71d": {"model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "model_name": "DescriptionStyleModel", "state": {"_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "DescriptionStyleModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "StyleView", "description_width": ""}}, "f693dfed91df492c986afbd4ff925f89": {"model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "model_name": "DescriptionStyleModel", "state": {"_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "DescriptionStyleModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "StyleView", "description_width": ""}}}
</script></section>


                </article>
              
              
              
              
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
<div
    id="pst-page-navigation-heading-2"
    class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> On this page
  </div>
  <nav class="bd-toc-nav page-toc" aria-labelledby="pst-page-navigation-heading-2">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#">Walkthrough</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#1️⃣-First,-let's-start-small">1️⃣ First, let’s start small</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#Tracing-Context">Tracing Context</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#Getting">Getting</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#Functions,-Methods,-and-Operations">Functions, Methods, and Operations</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#Custom-Functions">Custom Functions</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#Setting">Setting</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#Gradients">Gradients</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#Early-Stopping">Early Stopping</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#Conditional-Interventions">Conditional Interventions</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#2️⃣-Bigger">2️⃣ Bigger</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#LanguageModel">LanguageModel</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#Batching">Batching</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#.next()">.next()</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#Model-Editing">Model Editing</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#3️⃣-I-thought-you-said-huge-models?">3️⃣ I thought you said huge models?</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#Remote-execution">Remote execution</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#Sessions">Sessions</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#Looping">Looping</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#Training-a-LoRA">Training a LoRA</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#Next-Steps">Next Steps</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#Getting-Involved!">Getting Involved!</a></li>
</ul>

  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
          </footer>
        
      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="../../../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
<div class="bd-footer__inner bd-page-width">
  
    <div class="footer-items__start">
      
        <div class="footer-item">

  <p class="copyright">
    
      © Copyright 2024 NDIF.
      <br/>
    
  </p>
</div>
      
    </div>
  
  
  
    <div class="footer-items__end">
      
        <div class="footer-item">
<p class="theme-version">
  Built with the <a href="https://pydata-sphinx-theme.readthedocs.io/en/stable/index.html">PyData Sphinx Theme</a> 0.15.4.
</p></div>
      
    </div>
  
</div>

  </footer>
  </body>
</html>